
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>sleap.nn.config.model &#8212; SLEAP  documentation</title>
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/alabaster.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for sleap.nn.config.model</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Text</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">from</span> <span class="nn">sleap.nn.config.utils</span> <span class="kn">import</span> <span class="n">oneof</span>


<div class="viewcode-block" id="SingleInstanceConfmapsHeadConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.SingleInstanceConfmapsHeadConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">SingleInstanceConfmapsHeadConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configurations for single instance confidence map heads.</span>

<span class="sd">    These heads are used in single instance models that make the assumption that only</span>
<span class="sd">    one of each body part is present in the image. These heads produce confidence maps</span>
<span class="sd">    with a single peak for each part type which can be detected via global peak finding.</span>

<span class="sd">    Do not use this head if there is more than one animal present in the image.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        part_names: Text name of the body parts (nodes) that the head will be configured</span>
<span class="sd">            to produce. The number of parts determines the number of channels in the</span>
<span class="sd">            output. If not specified, all body parts in the skeleton will be used.</span>
<span class="sd">        sigma: Spread of the Gaussian distribution of the confidence maps as a scalar</span>
<span class="sd">            float. Smaller values are more precise but may be difficult to learn as they</span>
<span class="sd">            have a lower density within the image space. Larger values are easier to</span>
<span class="sd">            learn but are less precise with respect to the peak coordinate. This spread</span>
<span class="sd">            is in units of pixels of the model input image, i.e., the image resolution</span>
<span class="sd">            after any input scaling is applied.</span>
<span class="sd">        output_stride: The stride of the output confidence maps relative to the input</span>
<span class="sd">            image. This is the reciprocal of the resolution, e.g., an output stride of 2</span>
<span class="sd">            results in confidence maps that are 0.5x the size of the input. Increasing</span>
<span class="sd">            this value can considerably speed up model performance and decrease memory</span>
<span class="sd">            requirements, at the cost of decreased spatial resolution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">part_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Text</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5.0</span>
    <span class="n">output_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="CentroidsHeadConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.CentroidsHeadConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CentroidsHeadConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configurations for centroid confidence map heads.</span>

<span class="sd">    These heads are used in topdown models that rely on centroid detection to detect</span>
<span class="sd">    instances for cropping before predicting the remaining body parts.</span>

<span class="sd">    Multiple centroids can be present (one per instance), so their coordinates can be</span>
<span class="sd">    recovered in infernece via local peak finding.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        anchor_part: Text name of a body part (node) to use as the anchor point. If</span>
<span class="sd">            None, the midpoint of the bounding box of all visible instance points will</span>
<span class="sd">            be used as the anchor. The bounding box midpoint will also be used if the</span>
<span class="sd">            anchor part is specified but not visible in the instance. Setting a reliable</span>
<span class="sd">            anchor point can significantly improve topdown model accuracy as they</span>
<span class="sd">            benefit from a consistent geometry of the body parts relative to the center</span>
<span class="sd">            of the image.</span>
<span class="sd">        sigma: Spread of the Gaussian distribution of the confidence maps as a scalar</span>
<span class="sd">            float. Smaller values are more precise but may be difficult to learn as they</span>
<span class="sd">            have a lower density within the image space. Larger values are easier to</span>
<span class="sd">            learn but are less precise with respect to the peak coordinate. This spread</span>
<span class="sd">            is in units of pixels of the model input image, i.e., the image resolution</span>
<span class="sd">            after any input scaling is applied.</span>
<span class="sd">        output_stride: The stride of the output confidence maps relative to the input</span>
<span class="sd">            image. This is the reciprocal of the resolution, e.g., an output stride of 2</span>
<span class="sd">            results in confidence maps that are 0.5x the size of the input. Increasing</span>
<span class="sd">            this value can considerably speed up model performance and decrease memory</span>
<span class="sd">            requirements, at the cost of decreased spatial resolution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">anchor_part</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5.0</span>
    <span class="n">output_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="CenteredInstanceConfmapsHeadConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.CenteredInstanceConfmapsHeadConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CenteredInstanceConfmapsHeadConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configurations for centered instance confidence map heads.</span>

<span class="sd">    These heads are used in topdown multi-instance models that make the assumption that</span>
<span class="sd">    there is an instance reliably centered in the cropped input image. These heads are</span>
<span class="sd">    useful when centroids are easy to detect as they learn complex relationships between</span>
<span class="sd">    the geometry of body parts, even when animals are occluded.</span>

<span class="sd">    This comes at the cost of a strong reliance on the accuracy of the instance-centered</span>
<span class="sd">    cropping, i.e., it is heavily limited by the accuracy of the centroid model.</span>

<span class="sd">    Additionally, since one image crop is evaluated per instance, topdown models scale</span>
<span class="sd">    linearly with the number of animals in the frame, which can result in poor</span>
<span class="sd">    performance when many instances are present.</span>

<span class="sd">    Use this head when centroids are easy to detect, preferably using a consistent body</span>
<span class="sd">    part as an anchor, and when there are few animals that cover a small region of the</span>
<span class="sd">    full frame.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        anchor_part: Text name of a body part (node) to use as the anchor point. If</span>
<span class="sd">            None, the midpoint of the bounding box of all visible instance points will</span>
<span class="sd">            be used as the anchor. The bounding box midpoint will also be used if the</span>
<span class="sd">            anchor part is specified but not visible in the instance. Setting a reliable</span>
<span class="sd">            anchor point can significantly improve topdown model accuracy as they</span>
<span class="sd">            benefit from a consistent geometry of the body parts relative to the center</span>
<span class="sd">            of the image.</span>
<span class="sd">        part_names: Text name of the body parts (nodes) that the head will be configured</span>
<span class="sd">            to produce. The number of parts determines the number of channels in the</span>
<span class="sd">            output. If not specified, all body parts in the skeleton will be used.</span>
<span class="sd">        sigma: Spread of the Gaussian distribution of the confidence maps as a scalar</span>
<span class="sd">            float. Smaller values are more precise but may be difficult to learn as they</span>
<span class="sd">            have a lower density within the image space. Larger values are easier to</span>
<span class="sd">            learn but are less precise with respect to the peak coordinate. This spread</span>
<span class="sd">            is in units of pixels of the model input image, i.e., the image resolution</span>
<span class="sd">            after any input scaling is applied.</span>
<span class="sd">        output_stride: The stride of the output confidence maps relative to the input</span>
<span class="sd">            image. This is the reciprocal of the resolution, e.g., an output stride of 2</span>
<span class="sd">            results in confidence maps that are 0.5x the size of the input. Increasing</span>
<span class="sd">            this value can considerably speed up model performance and decrease memory</span>
<span class="sd">            requirements, at the cost of decreased spatial resolution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">anchor_part</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">part_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Text</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5.0</span>
    <span class="n">output_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="MultiInstanceConfmapsHeadConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.MultiInstanceConfmapsHeadConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">MultiInstanceConfmapsHeadConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configurations for multi-instance confidence map heads.</span>

<span class="sd">    These heads are used in bottom-up multi-instance models that do not make any</span>
<span class="sd">    assumption about the connectivity of the body parts. These heads will generate</span>
<span class="sd">    multiple local peaks for each body part type and must be detected using local peak</span>
<span class="sd">    finding.</span>

<span class="sd">    Although this head alone is sufficient to detect multiple copies of each body part</span>
<span class="sd">    type, it provides no information as to which sets of points should be grouped</span>
<span class="sd">    together to the same instance. If this is required, a head that provides</span>
<span class="sd">    connectivity or grouping information is required, e.g., part affinity fields.</span>

<span class="sd">    Use this head when multiple instances of each body part are present and do not need</span>
<span class="sd">    to be grouped or will be grouped using additional information.</span>

<span class="sd">    This head type has the advantage that it only needs to evaluate each frame once to</span>
<span class="sd">    find all peaks, in contrast to topdown models that must be evaluated for each crop.</span>
<span class="sd">    This constant scaling with the number of instances can be especially beneficial when</span>
<span class="sd">    there are many animals present in the frame.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        part_names: Text name of the body parts (nodes) that the head will be configured</span>
<span class="sd">            to produce. The number of parts determines the number of channels in the</span>
<span class="sd">            output. If not specified, all body parts in the skeleton will be used.</span>
<span class="sd">        sigma: Spread of the Gaussian distribution of the confidence maps as a scalar</span>
<span class="sd">            float. Smaller values are more precise but may be difficult to learn as they</span>
<span class="sd">            have a lower density within the image space. Larger values are easier to</span>
<span class="sd">            learn but are less precise with respect to the peak coordinate. This spread</span>
<span class="sd">            is in units of pixels of the model input image, i.e., the image resolution</span>
<span class="sd">            after any input scaling is applied.</span>
<span class="sd">        output_stride: The stride of the output confidence maps relative to the input</span>
<span class="sd">            image. This is the reciprocal of the resolution, e.g., an output stride of 2</span>
<span class="sd">            results in confidence maps that are 0.5x the size of the input. Increasing</span>
<span class="sd">            this value can considerably speed up model performance and decrease memory</span>
<span class="sd">            requirements, at the cost of decreased spatial resolution.</span>
<span class="sd">        loss_weight: Scalar float used to weigh the loss term for this head during</span>
<span class="sd">            training. Increase this to encourage the optimization to focus on improving</span>
<span class="sd">            this specific output in multi-head models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">part_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Text</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5.0</span>
    <span class="n">output_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">loss_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span></div>


<div class="viewcode-block" id="PartAffinityFieldsHeadConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.PartAffinityFieldsHeadConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">PartAffinityFieldsHeadConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configurations for multi-instance part affinity field heads.</span>

<span class="sd">    These heads are used in bottom-up multi-instance models that require information</span>
<span class="sd">    about body part connectivity in order to group multiple detections of each body part</span>
<span class="sd">    type into distinct instances.</span>

<span class="sd">    Part affinity fields are an image-space representation of the directed graph that</span>
<span class="sd">    defines the skeleton. Pixels that are close to the line (directed edge) formed</span>
<span class="sd">    between pairs of nodes of the same instance will contain unit vectors pointing along</span>
<span class="sd">    the direction of the the connection. The similarity between this line and the</span>
<span class="sd">    average of the unit vectors at the pixels underneath the line can be used as a</span>
<span class="sd">    matching score to associate candidate pairs of body part detections.</span>

<span class="sd">    Use this head when multiple instances of each body part are present and need to be</span>
<span class="sd">    grouped to coherent instances.</span>

<span class="sd">    This head type has the advantage that it only needs to evaluate each frame once to</span>
<span class="sd">    find all peaks, in contrast to topdown models that must be evaluated for each crop.</span>
<span class="sd">    This constant scaling with the number of instances can be especially beneficial when</span>
<span class="sd">    there are many animals present in the frame.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        edges: List of 2-tuples of the form `(source_node, destination_node)` that</span>
<span class="sd">            define pairs of text names of the directed edges of the graph. If not set,</span>
<span class="sd">            all edges in the skeleton will be used.</span>
<span class="sd">        sigma: Spread of the Gaussian distribution that weigh the part affinity fields</span>
<span class="sd">            as a function of their distance from the edge they represent. Smaller values</span>
<span class="sd">            are more precise but may be difficult to learn as they have a lower density</span>
<span class="sd">            within the image space. Larger values are easier to learn but are less</span>
<span class="sd">            precise with respect to the edge distance, so can be less useful in</span>
<span class="sd">            disambiguating between edges that are nearby and parallel in direction. This</span>
<span class="sd">            spread is in units of pixels of the model input image, i.e., the image</span>
<span class="sd">            resolution after any input scaling is applied.</span>
<span class="sd">        output_stride: The stride of the output part affinity fields relative to the</span>
<span class="sd">            input image. This is the reciprocal of the resolution, e.g., an output</span>
<span class="sd">            stride of 2 results in PAFs that are 0.5x the size of the input. Increasing</span>
<span class="sd">            this value can considerably speed up model performance and decrease memory</span>
<span class="sd">            requirements, at the cost of decreased spatial resolution.</span>
<span class="sd">        loss_weight: Scalar float used to weigh the loss term for this head during</span>
<span class="sd">            training. Increase this to encourage the optimization to focus on improving</span>
<span class="sd">            this specific output in multi-head models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">edges</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">Text</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">15.0</span>
    <span class="n">output_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">loss_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span></div>


<div class="viewcode-block" id="MultiInstanceConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.MultiInstanceConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">MultiInstanceConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configuration for combined multi-instance confidence map and PAF model heads.</span>

<span class="sd">    This configuration specifies a multi-head model that outputs both multi-instance</span>
<span class="sd">    confidence maps and part affinity fields, which together enable multi-instance pose</span>
<span class="sd">    estimation in a bottom-up fashion, i.e., no instance cropping or centroids are</span>
<span class="sd">    required.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        confmaps: Part confidence map configuration (see the description in</span>
<span class="sd">            `MultiInstanceConfmapsHeadConfig`).</span>
<span class="sd">        pafs: Part affinity fields configuration (see the description in</span>
<span class="sd">            `PartAffinityFieldsHeadConfig`).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">confmaps</span><span class="p">:</span> <span class="n">MultiInstanceConfmapsHeadConfig</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span>
        <span class="n">factory</span><span class="o">=</span><span class="n">MultiInstanceConfmapsHeadConfig</span>
    <span class="p">)</span>
    <span class="n">pafs</span><span class="p">:</span> <span class="n">PartAffinityFieldsHeadConfig</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">factory</span><span class="o">=</span><span class="n">PartAffinityFieldsHeadConfig</span><span class="p">)</span></div>


<div class="viewcode-block" id="HeadsConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.HeadsConfig">[docs]</a><span class="nd">@oneof</span>
<span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">HeadsConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configurations related to the model output head type.</span>

<span class="sd">    Only one attribute of this class can be set, which defines the model output type.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        single_instance: An instance of `SingleInstanceConfmapsHeadConfig`.</span>
<span class="sd">        centroid: An instance of `CentroidsHeadConfig`.</span>
<span class="sd">        centered_instance: An instance of `CenteredInstanceConfmapsHeadConfig`.</span>
<span class="sd">        multi_instance: An instance of `MultiInstanceConfig`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">single_instance</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SingleInstanceConfmapsHeadConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">centroid</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CentroidsHeadConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">centered_instance</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CenteredInstanceConfmapsHeadConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">multi_instance</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultiInstanceConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="LEAPConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.LEAPConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LEAPConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;LEAP backbone configuration.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        max_stride: Determines the number of downsampling blocks in the network,</span>
<span class="sd">            increasing receptive field size at the cost of network size.</span>
<span class="sd">        output_stride: Determines the number of upsampling blocks in the network.</span>
<span class="sd">        filters: Base number of filters in the network.</span>
<span class="sd">        filters_rate: Factor to scale the number of filters by at each block.</span>
<span class="sd">        up_interpolate: If True, use bilinear upsampling instead of transposed</span>
<span class="sd">            convolutions for upsampling. This can save computations but may lower</span>
<span class="sd">            overall accuracy.</span>
<span class="sd">        stacks: Number of repeated stacks of the network (excluding the stem).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">max_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span>  <span class="c1"># determines down blocks</span>
    <span class="n">output_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># determines up blocks</span>
    <span class="n">filters</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">filters_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">up_interpolate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">stacks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="UNetConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.UNetConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">UNetConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;UNet backbone configuration.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        stem_stride: If not None, controls how many stem blocks to use for initial</span>
<span class="sd">            downsampling. These are useful for learned downsampling that is able to</span>
<span class="sd">            retain spatial information while reducing large input image sizes.</span>
<span class="sd">        max_stride: Determines the number of downsampling blocks in the network,</span>
<span class="sd">            increasing receptive field size at the cost of network size.</span>
<span class="sd">        output_stride: Determines the number of upsampling blocks in the network.</span>
<span class="sd">        filters: Base number of filters in the network.</span>
<span class="sd">        filters_rate: Factor to scale the number of filters by at each block.</span>
<span class="sd">        middle_block: If True, add an intermediate block between the downsampling and</span>
<span class="sd">            upsampling branch for additional processing for features at the largest</span>
<span class="sd">            receptive field size. This will not introduce an extra pooling step.</span>
<span class="sd">        up_interpolate: If True, use bilinear upsampling instead of transposed</span>
<span class="sd">            convolutions for upsampling. This can save computations but may lower</span>
<span class="sd">            overall accuracy.</span>
<span class="sd">        stacks: Number of repeated stacks of the network (excluding the stem).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stem_stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">max_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">output_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">filters</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">filters_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">middle_block</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">up_interpolate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">stacks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="HourglassConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.HourglassConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">HourglassConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Hourglass backbone configuration.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        stem_stride: Controls how many stem blocks to use for initial downsampling.</span>
<span class="sd">            These are useful for learned downsampling that is able to retain spatial</span>
<span class="sd">            information while reducing large input image sizes.</span>
<span class="sd">        max_stride: Determines the number of downsampling blocks in the network,</span>
<span class="sd">            increasing receptive field size at the cost of network size.</span>
<span class="sd">        output_stride: Determines the number of upsampling blocks in the network.</span>
<span class="sd">        filters: Base number of filters in the network.</span>
<span class="sd">        filters_increase: Constant to increase the number of filters by at each block.</span>
<span class="sd">        stacks: Number of repeated stacks of the network (excluding the stem).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stem_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">max_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">output_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">stem_filters</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">filters</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">filter_increase</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">stacks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span></div>


<div class="viewcode-block" id="UpsamplingConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.UpsamplingConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">UpsamplingConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Upsampling stack configuration.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        method: If &quot;transposed_conv&quot;, use a strided transposed convolution to perform</span>
<span class="sd">            learnable upsampling. If &quot;interpolation&quot;, bilinear upsampling will be used</span>
<span class="sd">            instead.</span>
<span class="sd">        skip_connections: If &quot;add&quot;, incoming feature tensors form skip connection with</span>
<span class="sd">            upsampled features via element-wise addition. Height/width are matched via</span>
<span class="sd">            stride and a 1x1 linear conv is applied if the channel counts do no match</span>
<span class="sd">            up. If &quot;concatenate&quot;, the skip connection is formed via channel-wise</span>
<span class="sd">            concatenation. If None, skip connections will not be formed.</span>
<span class="sd">        block_stride: The striding of the upsampling *layer* (not tensor). This is</span>
<span class="sd">            typically set to 2, such that the tensor doubles in size with each</span>
<span class="sd">            upsampling step, but can be set higher to upsample to the desired</span>
<span class="sd">            `output_stride` directly in fewer steps.</span>
<span class="sd">        filters: Integer that specifies the base number of filters in each convolution</span>
<span class="sd">            layer. This will be scaled by the `filters_rate` at every upsampling step.</span>
<span class="sd">        filters_rate: Factor to scale the number of filters in the convolution layers</span>
<span class="sd">            after each upsampling step. If set to 1, the number of filters won&#39;t change.</span>
<span class="sd">        refine_convs: If greater than 0, specifies the number of 3x3 convolutions that</span>
<span class="sd">            will be applied after the upsampling step for refinement. These layers can</span>
<span class="sd">            serve the purpose of &quot;mixing&quot; the skip connection fused features, or to</span>
<span class="sd">            refine the current feature map after upsampling, which can help to prevent</span>
<span class="sd">            aliasing and checkerboard effects. If 0, no additional convolutions will be</span>
<span class="sd">            applied.</span>
<span class="sd">        conv_batchnorm: Specifies whether batch norm should be applied after each</span>
<span class="sd">            convolution (and before the ReLU activation).</span>
<span class="sd">        transposed_conv_kernel_size: Size of the kernel for the transposed convolution.</span>
<span class="sd">            No effect if bilinear upsampling is used.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">method</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;interpolation&quot;</span><span class="p">,</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">attr</span><span class="o">.</span><span class="n">validators</span><span class="o">.</span><span class="n">in_</span><span class="p">([</span><span class="s2">&quot;interpolation&quot;</span><span class="p">,</span> <span class="s2">&quot;transposed_conv&quot;</span><span class="p">]),</span>
    <span class="p">)</span>
    <span class="n">skip_connections</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">attr</span><span class="o">.</span><span class="n">validators</span><span class="o">.</span><span class="n">optional</span><span class="p">(</span><span class="n">attr</span><span class="o">.</span><span class="n">validators</span><span class="o">.</span><span class="n">in_</span><span class="p">([</span><span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="s2">&quot;concatenate&quot;</span><span class="p">])),</span>
    <span class="p">)</span>
    <span class="n">block_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">filters</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">filters_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">refine_convs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">batch_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">transposed_conv_kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span></div>


<div class="viewcode-block" id="ResNetConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.ResNetConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ResNetConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;ResNet backbone configuration.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        version: Name of the ResNetV1 variant. Can be one of: &quot;ResNet50&quot;, &quot;ResNet101&quot;,</span>
<span class="sd">            or &quot;ResNet152&quot;.</span>
<span class="sd">        weights: Controls how the network weights are initialized. If &quot;random&quot;, the</span>
<span class="sd">            network is not pretrained. If &quot;frozen&quot;, the network uses pretrained weights</span>
<span class="sd">            and keeps them fixed. If &quot;tunable&quot;, the network uses pretrained weights and</span>
<span class="sd">            allows them to be trainable.</span>
<span class="sd">        upsampling: A `UpsamplingConfig` that defines an upsampling branch if not None.</span>
<span class="sd">        max_stride: Stride of the backbone feature activations. These should be &lt;= 32.</span>
<span class="sd">        output_stride: Stride of the final output. If the upsampling branch is not</span>
<span class="sd">            defined, the output stride is controlled via dilated convolutions or reduced</span>
<span class="sd">            pooling in the backbone.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">version</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;ResNet50&quot;</span><span class="p">,</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">attr</span><span class="o">.</span><span class="n">validators</span><span class="o">.</span><span class="n">in_</span><span class="p">([</span><span class="s2">&quot;ResNet50&quot;</span><span class="p">,</span> <span class="s2">&quot;ResNet101&quot;</span><span class="p">,</span> <span class="s2">&quot;ResNet152&quot;</span><span class="p">]),</span>
    <span class="p">)</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;frozen&quot;</span><span class="p">,</span> <span class="n">validator</span><span class="o">=</span><span class="n">attr</span><span class="o">.</span><span class="n">validators</span><span class="o">.</span><span class="n">in_</span><span class="p">([</span><span class="s2">&quot;random&quot;</span><span class="p">,</span> <span class="s2">&quot;frozen&quot;</span><span class="p">,</span> <span class="s2">&quot;tunable&quot;</span><span class="p">])</span>
    <span class="p">)</span>
    <span class="n">upsampling</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">UpsamplingConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">max_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">output_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span></div>


<div class="viewcode-block" id="PretrainedEncoderConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.PretrainedEncoderConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">PretrainedEncoderConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configuration for UNet backbone with pretrained encoder.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        encoder: Name of the network architecture to use as the encoder.</span>
<span class="sd">        pretrained: If `True`, use initialized with weights pretrained on ImageNet.</span>
<span class="sd">        decoder_filters: Base number of filters for the upsampling blocks in the</span>
<span class="sd">            decoder.</span>
<span class="sd">        decoder_filters_rate: Factor to scale the number of filters by at each</span>
<span class="sd">            consecutive upsampling block in the decoder.</span>
<span class="sd">        output_stride: Stride of the final output.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">encoder</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;efficientnetb0&quot;</span><span class="p">)</span>
    <span class="n">pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">decoder_filters</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">decoder_filters_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">output_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span></div>


<div class="viewcode-block" id="BackboneConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.BackboneConfig">[docs]</a><span class="nd">@oneof</span>
<span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">BackboneConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configurations related to the model backbone.</span>

<span class="sd">    Only one field can be set and will determine which backbone architecture to use.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        leap: A `LEAPConfig` instance.</span>
<span class="sd">        unet: A `UNetConfig` instance.</span>
<span class="sd">        hourglass: A `HourglassConfig` instance.</span>
<span class="sd">        resnet: A `ResNetConfig` instance.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">leap</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LEAPConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">unet</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">UNetConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">hourglass</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">HourglassConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">resnet</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ResNetConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">pretrained_encoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PretrainedEncoderConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="ModelConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.model.html#sleap.nn.config.model.ModelConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ModelConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configurations related to model architecture.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        backbone: Configurations related to the main network architecture.</span>
<span class="sd">        heads: Configurations related to the output heads.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">backbone</span><span class="p">:</span> <span class="n">BackboneConfig</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">factory</span><span class="o">=</span><span class="n">BackboneConfig</span><span class="p">)</span>
    <span class="n">heads</span><span class="p">:</span> <span class="n">HeadsConfig</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">factory</span><span class="o">=</span><span class="n">HeadsConfig</span><span class="p">)</span></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">SLEAP</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../guides/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../guides/index.html">Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../guides/reference.html">Feature Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api.html">API</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019–2020, Murthy Lab @ Princeton.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.4.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>