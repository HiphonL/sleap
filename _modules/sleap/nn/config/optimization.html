
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>sleap.nn.config.optimization &#8212; SLEAP  documentation</title>
    <link rel="stylesheet" href="../../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for sleap.nn.config.optimization</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Text</span>


<div class="viewcode-block" id="AugmentationConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.optimization.html#sleap.nn.config.optimization.AugmentationConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">AugmentationConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Parameters for configuring an augmentation stack.</span>

<span class="sd">    The augmentations will be applied in the the order of the attributes.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        rotate: If True, rotational augmentation will be applied. Rotation is relative</span>
<span class="sd">            to the center of the image. See `imgaug.augmenters.geometric.Affine`.</span>
<span class="sd">        rotation_min_angle: Minimum rotation angle in degrees in [-180, 180].</span>
<span class="sd">        rotation_max_angle: Maximum rotation angle in degrees in [-180, 180].</span>
<span class="sd">        translate: If True, translational augmentation will be applied. The values are</span>
<span class="sd">            sampled independently for x and y coordinates. See</span>
<span class="sd">            `imgaug.augmenters.geometric.Affine`.</span>
<span class="sd">        translate_min: Minimum translation in integer pixel units.</span>
<span class="sd">        translate_max: Maximum translation in integer pixel units.</span>
<span class="sd">        scale: If True, scaling augmentation will be applied. See</span>
<span class="sd">            `imgaug.augmenters.geometric.Affine`.</span>
<span class="sd">        scale_min: Minimum scaling factor.</span>
<span class="sd">        scale_max: Maximum scaling factor.</span>
<span class="sd">        uniform_noise: If True, uniformly distributed noise will be added to the image.</span>
<span class="sd">            This is effectively adding a different random value to each pixel to</span>
<span class="sd">            simulate shot noise. See `imgaug.augmenters.arithmetic.AddElementwise`.</span>
<span class="sd">        uniform_noise_min_val: Minimum value to add.</span>
<span class="sd">        uniform_noise_max_val: Maximum value to add.</span>
<span class="sd">        gaussian_noise: If True, normally distributed noise will be added to the image.</span>
<span class="sd">            This is similar to uniform noise, but can provide a tigher bound around a</span>
<span class="sd">            mean noise magnitude. This is applied independently to each pixel.</span>
<span class="sd">            See `imgaug.augmenters.arithmetic.AdditiveGaussianNoise`.</span>
<span class="sd">        gaussian_noise_mean: Mean of the distribution to sample from.</span>
<span class="sd">        gaussian_noise_stddev: Standard deviation of the distribution to sample from.</span>
<span class="sd">        contrast: If True, gamma constrast adjustment will be applied to the image.</span>
<span class="sd">            This scales all pixel values by `x ** gamma` where `x` is the pixel value in</span>
<span class="sd">            the [0, 1] range. Values in [0, 255] are first scaled to [0, 1]. See</span>
<span class="sd">            `imgaug.augmenters.contrast.GammaContrast`.</span>
<span class="sd">        contrast_min_gamma: Minimum gamma to use for augmentation. Reasonable values are</span>
<span class="sd">            in [0.5, 2.0].</span>
<span class="sd">        contrast_max_gamma: Maximum gamma to use for augmentation. Reasonable values are</span>
<span class="sd">            in [0.5, 2.0].</span>
<span class="sd">        brightness: If True, the image brightness will be augmented. This adjustment</span>
<span class="sd">            simply adds the same value to all pixels in the image to simulate broadfield</span>
<span class="sd">            illumination change. See `imgaug.augmenters.arithmetic.Add`.</span>
<span class="sd">        brightness_min_val: Minimum value to add to all pixels.</span>
<span class="sd">        brightness_max_val: Maximum value to add to all pixels.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">rotate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">rotation_min_angle</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mi">180</span>
    <span class="n">rotation_max_angle</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">180</span>
    <span class="n">translate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">translate_min</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">5</span>
    <span class="n">translate_max</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">scale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">scale_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span>
    <span class="n">scale_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.1</span>
    <span class="n">uniform_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">uniform_noise_min_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">uniform_noise_max_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span>
    <span class="n">gaussian_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">gaussian_noise_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5.0</span>
    <span class="n">gaussian_noise_stddev</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">contrast</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">contrast_min_gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">contrast_max_gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">brightness</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">brightness_min_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">brightness_max_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span></div>


<div class="viewcode-block" id="HardKeypointMiningConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.optimization.html#sleap.nn.config.optimization.HardKeypointMiningConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">HardKeypointMiningConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configuration for online hard keypoint mining.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        online_mining: If True, online hard keypoint mining (OHKM) will be enabled. When</span>
<span class="sd">            this is enabled, the loss is computed per keypoint (or edge for PAFs) and</span>
<span class="sd">            sorted from lowest (easy) to highest (hard). The hard keypoint loss will be</span>
<span class="sd">            scaled to have a higher weight in the total loss, encouraging the training</span>
<span class="sd">            to focus on tricky body parts that are more difficult to learn.</span>
<span class="sd">            If False, no mining will be performed and all keypoints will be weighted</span>
<span class="sd">            equally in the loss.</span>
<span class="sd">        hard_to_easy_ratio: The minimum ratio of the individual keypoint loss with</span>
<span class="sd">            respect to the lowest keypoint loss in order to be considered as &quot;hard&quot;.</span>
<span class="sd">            This helps to switch focus on across groups of keypoints during training.</span>
<span class="sd">        min_hard_keypoints: The minimum number of keypoints that will be considered as</span>
<span class="sd">            &quot;hard&quot;, even if they are not below the `hard_to_easy_ratio`.</span>
<span class="sd">        max_hard_keypoints: The maximum number of hard keypoints to apply scaling to.</span>
<span class="sd">            This can help when there are few very easy keypoints which may skew the</span>
<span class="sd">            ratio and result in loss scaling being applied to most keypoints, which can</span>
<span class="sd">            reduce the impact of hard mining altogether.</span>
<span class="sd">        loss_scale: Factor to scale the hard keypoint losses by.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">online_mining</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">hard_to_easy_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">min_hard_keypoints</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">max_hard_keypoints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">loss_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5.0</span></div>


<div class="viewcode-block" id="LearningRateScheduleConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.optimization.html#sleap.nn.config.optimization.LearningRateScheduleConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LearningRateScheduleConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configuration for learning rate scheduling.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        reduce_on_plateau: If True, learning rate will be reduced when the validation</span>
<span class="sd">            set loss plateaus. This improves training at later epochs when finer weight</span>
<span class="sd">            updates are required for fine-tuning the optimization, balancing out an</span>
<span class="sd">            initially high learning rate required for practical initial optimization.</span>
<span class="sd">        reduction_factor: Factor by which the learning rate will be scaled when a</span>
<span class="sd">            plateau is detected.</span>
<span class="sd">        plateau_min_delta: Minimum absolute decrease in the loss in order to consider an</span>
<span class="sd">            epoch as not in a plateau.</span>
<span class="sd">        plateau_patience: Number of epochs without an improvement of at least</span>
<span class="sd">            `plateau_min_delta` in order for a plateau to be detected.</span>
<span class="sd">        plateau_cooldown: Number of epochs after a reduction step before epochs without</span>
<span class="sd">            improvement will begin to be counted again.</span>
<span class="sd">        min_learning_rate: The minimum absolute value that the learning rate can be</span>
<span class="sd">            reduced to.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">reduce_on_plateau</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">reduction_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">plateau_min_delta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span>
    <span class="n">plateau_patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">plateau_cooldown</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">min_learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span></div>


<div class="viewcode-block" id="EarlyStoppingConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.optimization.html#sleap.nn.config.optimization.EarlyStoppingConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">EarlyStoppingConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configuration for early stopping.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        stop_training_on_plateau: If True, the training will terminate automatically</span>
<span class="sd">            when the validation set loss plateaus. This can save time and compute</span>
<span class="sd">            resources when there are minimal improvements to be gained from further</span>
<span class="sd">            training, as well as to prevent training into the overfitting regime.</span>
<span class="sd">        plateau_min_delta: Minimum absolute decrease in the loss in order to consider an</span>
<span class="sd">            epoch as not in a plateau.</span>
<span class="sd">        plateau_patience: Number of epochs without an improvement of at least</span>
<span class="sd">            `plateau_min_delta` in order for a plateau to be detected.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stop_training_on_plateau</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">plateau_min_delta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span>
    <span class="n">plateau_patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span></div>


<div class="viewcode-block" id="OptimizationConfig"><a class="viewcode-back" href="../../../../_autosummary/sleap.nn.config.optimization.html#sleap.nn.config.optimization.OptimizationConfig">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">OptimizationConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Optimization configuration.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        preload_data: If True, the data from the training/validation/test labels will be</span>
<span class="sd">            loaded into memory at the beginning of training. If False, the data will be</span>
<span class="sd">            loaded every time it is accessed. Preloading can considerably speed up the</span>
<span class="sd">            performance of data generation at the cost of memory as all the images will</span>
<span class="sd">            be loaded into memory. This is especially beneficial for datasets with few</span>
<span class="sd">            examples or when the raw data is on (slow) network storage.</span>
<span class="sd">        augmentation_config: Configuration options related to data augmentation.</span>
<span class="sd">        online_shuffling: If True, data will be shuffled online by maintaining a buffer</span>
<span class="sd">            of examples that are sampled from at each step. This allows for</span>
<span class="sd">            randomization of data ordering, resulting in more varied mini-batch</span>
<span class="sd">            composition, which in turn can promote generalization. Note that the data</span>
<span class="sd">            are shuffled at the start of training regardless.</span>
<span class="sd">        shuffle_buffer_size: Number of examples to keep in a buffer to sample uniformly</span>
<span class="sd">            from. This should be set to relatively low number as it requires an</span>
<span class="sd">            additional copy of each data example to be stored in memory. If set to -1,</span>
<span class="sd">            the entire dataset will be used, which results in perfect randomization at</span>
<span class="sd">            the cost of increased memory usage.</span>
<span class="sd">        prefetch: If True, data will generated in parallel to training to minimize the</span>
<span class="sd">            bottleneck of the preprocessing pipeline.</span>
<span class="sd">        batch_size: Number of examples per minibatch, i.e., a single step of training.</span>
<span class="sd">            Higher numbers can increase generalization performance by averaging model</span>
<span class="sd">            gradient updates over a larger number of examples at the cost of</span>
<span class="sd">            considerably more GPU memory, especially for larger sized images. Lower</span>
<span class="sd">            numbers may lead to overfitting, but may be beneficial to the optimization</span>
<span class="sd">            process when few but varied examples are available.</span>
<span class="sd">        batches_per_epoch: Number of minibatches (steps) to train for in an epoch. If</span>
<span class="sd">            set to None, this is set to the number of batches in the training data or</span>
<span class="sd">            `min_batches_per_epoch`, whichever is largest. At the end of each epoch, the</span>
<span class="sd">            validation and test sets are evaluated, the model is saved if its</span>
<span class="sd">            performance improved, visualizations are generated, learning rate may be</span>
<span class="sd">            tuned, and several other non-optimization procedures executed.</span>
<span class="sd">            If this is set too low, training may be slowed down as these end-of-epoch</span>
<span class="sd">            procedures can take longer than the optimization itself, especially if</span>
<span class="sd">            model saving is enabled, which can take a while for larger models. If set</span>
<span class="sd">            too high, the training procedure may take longer, especially since several</span>
<span class="sd">            hyperparameter tuning heuristics only consider epoch-to-epoch performance.</span>
<span class="sd">        min_batches_per_epoch: The minimum number of batches per epoch if</span>
<span class="sd">            `batches_per_epoch` is set to None. No effect if the batches per epoch is</span>
<span class="sd">            explicitly specified. This should be set to 200-400 to compensate for short</span>
<span class="sd">            loops through the data when there are few examples.</span>
<span class="sd">        val_batches_per_epoch: Same as `batches_per_epoch`, but for the validation set.</span>
<span class="sd">        min_val_batches_per_epoch: Same as `min_batches_per_epoch`, but for the</span>
<span class="sd">            validation set.</span>
<span class="sd">        epochs: Maximum number of epochs to train for. Training can be stopped manually</span>
<span class="sd">            or automatically if early stopping is enabled and a plateau is detected.</span>
<span class="sd">        optimizer: Name of the optimizer to use for training. This is typically &quot;adam&quot;</span>
<span class="sd">            but the name of any class from `tf.keras.optimizers` may be used. If &quot;adam&quot;</span>
<span class="sd">            is specified, the Adam optimizer will have AMSGrad enabled.</span>
<span class="sd">        initial_learning_rate: The initial learning rate to use for the optimizer. This</span>
<span class="sd">            is typically set to 1e-3 or 1e-4, and can be decreased automatically if</span>
<span class="sd">            learning rate reduction on plateau is enabled. If this is too high or too</span>
<span class="sd">            low, the training may fail to find good initial local minima to descend.</span>
<span class="sd">        learning_rate_schedule: Configuration options related to learning rate</span>
<span class="sd">            scheduling.</span>
<span class="sd">        hard_keypoint_mining: Configuration options related to online hard keypoint</span>
<span class="sd">            mining.</span>
<span class="sd">        early_stopping: Configuration options related to early stopping of training on</span>
<span class="sd">            plateau/convergence is detected.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">preload_data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">augmentation_config</span><span class="p">:</span> <span class="n">AugmentationConfig</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">factory</span><span class="o">=</span><span class="n">AugmentationConfig</span><span class="p">)</span>
    <span class="n">online_shuffling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">shuffle_buffer_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">prefetch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">batches_per_epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">min_batches_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">val_batches_per_epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">min_val_batches_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="s2">&quot;adam&quot;</span>
    <span class="n">initial_learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="n">learning_rate_schedule</span><span class="p">:</span> <span class="n">LearningRateScheduleConfig</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span>
        <span class="n">factory</span><span class="o">=</span><span class="n">LearningRateScheduleConfig</span>
    <span class="p">)</span>
    <span class="n">hard_keypoint_mining</span><span class="p">:</span> <span class="n">HardKeypointMiningConfig</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span>
        <span class="n">factory</span><span class="o">=</span><span class="n">HardKeypointMiningConfig</span>
    <span class="p">)</span>
    <span class="n">early_stopping</span><span class="p">:</span> <span class="n">EarlyStoppingConfig</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">factory</span><span class="o">=</span><span class="n">EarlyStoppingConfig</span><span class="p">)</span></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">SLEAP</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../guides/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../guides/index.html">Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../guides/reference.html">Feature Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api.html">API</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019–2020, Murthy Lab @ Princeton.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>