

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>sleap.nn.inference &mdash; SLEAP  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> SLEAP
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">SLEAP Package</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../skeleton.html">Skeleton</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../video.html">Video</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../instance.html">Instance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dataset.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gui.html">GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../misc.html">Misc</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">SLEAP</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>sleap.nn.inference</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for sleap.nn.inference</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">attr</span>

<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="k">import</span> <span class="n">Process</span><span class="p">,</span> <span class="n">Pool</span>
<span class="kn">from</span> <span class="nn">multiprocessing.pool</span> <span class="k">import</span> <span class="n">AsyncResult</span><span class="p">,</span> <span class="n">ThreadPool</span>

<span class="kn">from</span> <span class="nn">time</span> <span class="k">import</span> <span class="n">time</span><span class="p">,</span> <span class="n">clock</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="k">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Text</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">from</span> <span class="nn">sleap.instance</span> <span class="k">import</span> <span class="n">LabeledFrame</span>
<span class="kn">from</span> <span class="nn">sleap.io.dataset</span> <span class="k">import</span> <span class="n">Labels</span>
<span class="kn">from</span> <span class="nn">sleap.io.video</span> <span class="k">import</span> <span class="n">Video</span>
<span class="kn">from</span> <span class="nn">sleap.skeleton</span> <span class="k">import</span> <span class="n">Skeleton</span>
<span class="kn">from</span> <span class="nn">sleap.util</span> <span class="k">import</span> <span class="n">usable_cpu_count</span>

<span class="kn">from</span> <span class="nn">sleap.nn.model</span> <span class="k">import</span> <span class="n">ModelOutputType</span>
<span class="kn">from</span> <span class="nn">sleap.nn.training</span> <span class="k">import</span> <span class="n">TrainingJob</span>
<span class="kn">from</span> <span class="nn">sleap.nn.tracking</span> <span class="k">import</span> <span class="n">FlowShiftTracker</span><span class="p">,</span> <span class="n">Track</span>
<span class="kn">from</span> <span class="nn">sleap.nn.transform</span> <span class="k">import</span> <span class="n">DataTransform</span>

<span class="kn">from</span> <span class="nn">sleap.nn.datagen</span> <span class="k">import</span> <span class="n">merge_boxes_with_overlap_and_padding</span>
<span class="kn">from</span> <span class="nn">sleap.nn.peakfinding</span> <span class="k">import</span> <span class="n">find_all_peaks</span><span class="p">,</span> <span class="n">find_all_single_peaks</span>
<span class="kn">from</span> <span class="nn">sleap.nn.peakfinding_tf</span> <span class="k">import</span> <span class="n">peak_tf_inference</span>
<span class="kn">from</span> <span class="nn">sleap.nn.peakmatching</span> <span class="k">import</span> <span class="p">(</span>
    <span class="n">match_single_peaks_all</span><span class="p">,</span>
    <span class="n">match_peaks_paf</span><span class="p">,</span>
    <span class="n">match_peaks_paf_par</span><span class="p">,</span>
    <span class="n">instances_nms</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sleap.nn.util</span> <span class="k">import</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_count</span><span class="p">,</span> <span class="n">save_visual_outputs</span>


<div class="viewcode-block" id="InferenceModel"><a class="viewcode-back" href="../../../inference.html#sleap.nn.inference.InferenceModel">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">InferenceModel</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;This class provides convenience metadata and methods for running inference from a TrainingJob.&quot;&quot;&quot;</span>

    <span class="n">job</span><span class="p">:</span> <span class="n">TrainingJob</span>
    <span class="n">_keras_model</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_model_path</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_trained_input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_output_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">skeleton</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Skeleton</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the skeleton associated with this model.&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">skeletons</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOutputType</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the output type of this model.&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">output_type</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the scale of the images that the model was trained on.&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">scale</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the scale of the outputs of the model relative to the original data.</span>
<span class="sd">        </span>
<span class="sd">        For a model trained on inputs with scale = 0.5 that outputs predictions that</span>
<span class="sd">        are half of the size of the inputs, the output scale is 0.25.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">output_scale</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output_relative_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the scale of the outputs relative to the scaled inputs.</span>

<span class="sd">        This differs from output_scale in that it is the scaling factor after</span>
<span class="sd">        applying the input scaling.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">output_scale</span>

<div class="viewcode-block" id="InferenceModel.compute_output_shape"><a class="viewcode-back" href="../../../inference.html#sleap.nn.inference.InferenceModel.compute_output_shape">[docs]</a>    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">relative</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns the output tensor shape for a given input shape.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_shape: Shape of input images in the form (height, width).</span>
<span class="sd">            relative: If True, input_shape specifies the shape after input scaling.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tuple of (height, width, channels) of the output of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># TODO: Support multi-input/multi-output models.</span>

        <span class="n">scaling_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_scale</span>
        <span class="k">if</span> <span class="n">relative</span><span class="p">:</span>
            <span class="n">scaling_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_relative_scale</span>

        <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">scaling_factor</span><span class="p">),</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">scaling_factor</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">output_shape</span></div>

<div class="viewcode-block" id="InferenceModel.load_model"><a class="viewcode-back" href="../../../inference.html#sleap.nn.inference.InferenceModel.load_model">[docs]</a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Loads a saved model from disk and caches it.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_path: If not provided, uses the model</span>
<span class="sd">                paths in the training job.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The loaded Keras model. This model can accept any size</span>
<span class="sd">            of inputs that are valid.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">model_path</span><span class="p">:</span>
            <span class="c1"># Try the best model first.</span>
            <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">best_model_filename</span><span class="p">)</span>

            <span class="c1"># Try the final model if that didn&#39;t exist.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
                <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">final_model_filename</span>
                <span class="p">)</span>

        <span class="c1"># Load from disk.</span>
        <span class="n">keras_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">tf</span><span class="p">})</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loaded model: &quot;</span> <span class="o">+</span> <span class="n">model_path</span><span class="p">)</span>

        <span class="c1"># Store the loaded model path for reference.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_path</span> <span class="o">=</span> <span class="n">model_path</span>

        <span class="c1"># TODO: Multi-input/output support</span>
        <span class="c1"># Find the original data shape from the input shape of the first input node.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trained_input_shape</span> <span class="o">=</span> <span class="n">keras_model</span><span class="o">.</span><span class="n">get_input_shape_at</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Save output channels since that should be static.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span> <span class="o">=</span> <span class="n">keras_model</span><span class="o">.</span><span class="n">get_output_shape_at</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Create input node with undetermined height/width.</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span><span class="p">))</span>
        <span class="n">keras_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">keras_model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Save the modified and loaded model.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_keras_model</span> <span class="o">=</span> <span class="n">keras_model</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">keras_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the underlying Keras model, loading it if necessary.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_keras_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_keras_model</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the path to the loaded model.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_path</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="s2">&quot;No model loaded. Call inference_model.load_model() first.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_path</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">trained_input_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns the shape of the model when it was loaded.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trained_input_shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="s2">&quot;No model loaded. Call inference_model.load_model() first.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trained_input_shape</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of output channels of the model.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trained_input_shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="s2">&quot;No model loaded. Call inference_model.load_model() first.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of channels expected for the input data.&quot;&quot;&quot;</span>

        <span class="c1"># TODO: Multi-output support</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained_input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_grayscale</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns True if the model expects grayscale images.&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span> <span class="o">==</span> <span class="mi">1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">down_blocks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of pooling steps applied during the model.</span>

<span class="sd">        Data needs to be of a shape divisible by the number of pooling steps.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># TODO: Replace this with an explicit calculation that takes stride sizes into account.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">job</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">down_blocks</span>

<div class="viewcode-block" id="InferenceModel.predict"><a class="viewcode-back" href="../../../inference.html#sleap.nn.inference.InferenceModel.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]],</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Runs inference on the input data.</span>

<span class="sd">        This is a simple wrapper around the keras model predict function.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: The inputs to provide to the model. Can be different height/width as</span>
<span class="sd">                the data it was trained on.</span>
<span class="sd">            batch_size: Batch size to perform inference on at a time.</span>
<span class="sd">            normalize: Applies normalization to the input data if needed</span>
<span class="sd">                (e.g., if casting or range normalization is required).</span>

<span class="sd">        Returns:</span>
<span class="sd">            The outputs of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="c1"># TODO: Store normalization scheme in the model metadata.</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s2">&quot;uint8&quot;</span><span class="p">):</span>
                    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s2">&quot;uint8&quot;</span><span class="p">):</span>
                        <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Predictor"><a class="viewcode-back" href="../../../inference.html#sleap.nn.inference.Predictor">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Predictor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Predictor class takes a set of trained sLEAP models and runs</span>
<span class="sd">    the full inference pipeline via the predict or predict_async method.</span>

<span class="sd">    Pipeline:</span>

<span class="sd">    * Pre-processing to load, crop and scale images</span>
<span class="sd">    * Inference to predict confidence maps and part affinity fields,</span>
<span class="sd">      and use these to generate PredictedInstances in LabeledFrames</span>
<span class="sd">    * Post-processing to collate data from all frames, track instances</span>
<span class="sd">      across frames, and save the results</span>

<span class="sd">    Args:</span>
<span class="sd">        sleap_models: Dict with a TrainingJob for each required</span>
<span class="sd">            ModelOutputType; can be used to construct keras model.</span>
<span class="sd">        skeleton: The skeleton(s) to use for prediction.</span>
<span class="sd">        inference_batch_size: Frames per inference batch</span>
<span class="sd">            (GPU memory limited)</span>
<span class="sd">        read_chunk_size: How many frames to read into CPU memory at a</span>
<span class="sd">            time (CPU memory limited)</span>
<span class="sd">        nms_min_thresh: A threshold of non-max suppression peak finding</span>
<span class="sd">            in confidence maps. All values below this minimum threshold</span>
<span class="sd">            will be set to zero before peak finding algorithm is run.</span>
<span class="sd">        nms_kernel_size: Gaussian blur is applied to confidence maps before</span>
<span class="sd">            non-max supression peak finding occurs. This is size of the</span>
<span class="sd">            kernel applied to the image.</span>
<span class="sd">        nms_sigma: For Gassian blur applied to confidence maps, this</span>
<span class="sd">            is the standard deviation of the kernel.</span>
<span class="sd">        min_score_to_node_ratio: FIXME</span>
<span class="sd">        min_score_midpts: FIXME</span>
<span class="sd">        min_score_integral: FIXME</span>
<span class="sd">        add_last_edge: FIXME</span>
<span class="sd">        with_tracking: whether to run tracking after inference</span>
<span class="sd">        flow_window: The number of frames that tracking should look back</span>
<span class="sd">            when trying to identify instances.</span>
<span class="sd">        single_per_crop: FIXME</span>
<span class="sd">        output_path: the output path to save the results</span>
<span class="sd">        save_confmaps_pafs: whether to save confmaps/pafs</span>
<span class="sd">        resize_hack: whether to resize images to power of 2</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">training_jobs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">ModelOutputType</span><span class="p">,</span> <span class="n">TrainingJob</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">inference_models</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">ModelOutputType</span><span class="p">,</span> <span class="n">InferenceModel</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">attr</span><span class="o">.</span><span class="n">Factory</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">skeleton</span><span class="p">:</span> <span class="n">Skeleton</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">inference_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">read_chunk_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">save_frequency</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># chunks</span>
    <span class="n">nms_min_thresh</span> <span class="o">=</span> <span class="mf">0.3</span>
    <span class="n">nms_kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">9</span>
    <span class="n">nms_sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">3.0</span>
    <span class="n">min_score_to_node_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span>
    <span class="n">min_score_midpts</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span>
    <span class="n">min_score_integral</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.6</span>
    <span class="n">add_last_edge</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">with_tracking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">flow_window</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">15</span>
    <span class="n">single_per_crop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">crop_padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">40</span>
    <span class="n">crop_growth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>

    <span class="n">output_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">save_confmaps_pafs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">resize_hack</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">pool</span><span class="p">:</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Pool</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">gpu_peak_finding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">supersample_window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">7</span>  <span class="c1"># must be odd</span>
    <span class="n">supersample_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># factor to upsample cropped windows by</span>
    <span class="n">overlapping_instances_nms</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># suppress overlapping instances</span>

    <span class="k">def</span> <span class="nf">__attrs_post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="c1"># Create inference models from the TrainingJob metadata.</span>
        <span class="k">for</span> <span class="n">model_output_type</span><span class="p">,</span> <span class="n">training_job</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_jobs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inference_models</span><span class="p">[</span><span class="n">model_output_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">InferenceModel</span><span class="p">(</span><span class="n">job</span><span class="o">=</span><span class="n">training_job</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inference_models</span><span class="p">[</span><span class="n">model_output_type</span><span class="p">]</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>

<div class="viewcode-block" id="Predictor.predict"><a class="viewcode-back" href="../../../inference.html#sleap.nn.inference.Predictor.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_video</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">Video</span><span class="p">],</span>
        <span class="n">frames</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">is_async</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">LabeledFrame</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Run the entire inference pipeline on an input video.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_video: Either a `Video` object or dict that can be</span>
<span class="sd">                converted back to a `Video` object.</span>
<span class="sd">            frames (optional): List of frames to predict.</span>
<span class="sd">                If None, run entire video.</span>
<span class="sd">            is_async (optional): Whether running function from separate</span>
<span class="sd">                process. Default is False. If True, we won&#39;t spawn</span>
<span class="sd">                children.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of LabeledFrames with predicted instances.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Check if we have models.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_models</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Predictor has no model.&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Predictor has no model.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">is_async</span> <span class="o">=</span> <span class="n">is_async</span>

        <span class="c1"># Initialize parallel pool if needed.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_async</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">usable_cpu_count</span><span class="p">())</span>

        <span class="c1"># Fix the number of threads for OpenCV, not that we are using</span>
        <span class="c1"># anything in OpenCV that is actually multi-threaded but maybe</span>
        <span class="c1"># we will down the line.</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">setNumThreads</span><span class="p">(</span><span class="n">usable_cpu_count</span><span class="p">())</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Predict is async: </span><span class="si">{is_async}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Find out if the images should be grayscale from the first model.</span>
        <span class="c1"># TODO: Unify this with input data normalization.</span>
        <span class="n">grayscale</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_models</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_grayscale</span>

        <span class="c1"># Open the video object if needed.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_video</span><span class="p">,</span> <span class="n">Video</span><span class="p">):</span>
            <span class="n">vid</span> <span class="o">=</span> <span class="n">input_video</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_video</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">vid</span> <span class="o">=</span> <span class="n">Video</span><span class="o">.</span><span class="n">cattr</span><span class="p">()</span><span class="o">.</span><span class="n">structure</span><span class="p">(</span><span class="n">input_video</span><span class="p">,</span> <span class="n">Video</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_video</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">vid</span> <span class="o">=</span> <span class="n">Video</span><span class="o">.</span><span class="n">from_filename</span><span class="p">(</span><span class="n">input_video</span><span class="p">,</span> <span class="n">grayscale</span><span class="o">=</span><span class="n">grayscale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Unable to load input video: </span><span class="si">{input_video}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># List of frames to process (or entire video if not specified)</span>
        <span class="n">frames</span> <span class="o">=</span> <span class="n">frames</span> <span class="ow">or</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">vid</span><span class="o">.</span><span class="n">num_frames</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Opened video:&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Source: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">vid</span><span class="o">.</span><span class="n">backend</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Frames: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Frame shape (H x W): </span><span class="si">%d</span><span class="s2"> x </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">vid</span><span class="o">.</span><span class="n">height</span><span class="p">,</span> <span class="n">vid</span><span class="o">.</span><span class="n">width</span><span class="p">))</span>

        <span class="c1"># Initialize tracking</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_tracking</span><span class="p">:</span>
            <span class="n">tracker</span> <span class="o">=</span> <span class="n">FlowShiftTracker</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">flow_window</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">:</span>
            <span class="c1"># Delete the output file if it exists already</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">unlink</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Deleted existing output: &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">)</span>

            <span class="c1"># Create output directory if it doesn&#39;t exist</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Output path: &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">)</span>

        <span class="c1"># Process chunk-by-chunk!</span>
        <span class="n">t0_start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
        <span class="n">predicted_frames</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">num_chunks</span> <span class="o">=</span> <span class="n">batch_count</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">read_chunk_size</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Number of chunks for process: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_chunks</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">chunk_start</span><span class="p">,</span> <span class="n">frames_idx</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">read_chunk_size</span><span class="p">):</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Processing chunk </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2">:&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">chunk</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_chunks</span><span class="p">))</span>
            <span class="n">t0_chunk</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Step 1: Pre-processing</span>

<span class="sd">            Prepare the data we need for inference:</span>
<span class="sd">            * load images</span>
<span class="sd">            * crop and scale as appropriate</span>

<span class="sd">            Results: a list of (images, transform) tuples.</span>

<span class="sd">            For instance, if we have different sized crops, we&#39;ll need a</span>
<span class="sd">            distinct images matrix and transform for each size.</span>
<span class="sd">            &quot;&quot;&quot;</span>

            <span class="c1"># Read the next batch of images</span>
            <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
            <span class="n">imgs_full</span> <span class="o">=</span> <span class="n">vid</span><span class="p">[</span><span class="n">frames_idx</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Read </span><span class="si">%d</span><span class="s2"> frames [</span><span class="si">%.1f</span><span class="s2">s]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">imgs_full</span><span class="p">),</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>

            <span class="c1"># Transform images (crop or scale)</span>
            <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">ModelOutputType</span><span class="o">.</span><span class="n">CENTROIDS</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_models</span><span class="p">:</span>

                <span class="c1"># Use centroid predictions to get subchunks of crops.</span>
                <span class="n">subchunks_to_process</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">centroid_crop_inference</span><span class="p">(</span>
                    <span class="n">imgs_full</span><span class="p">,</span> <span class="n">frames_idx</span>
                <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Create transform object</span>
                <span class="n">transform</span> <span class="o">=</span> <span class="n">DataTransform</span><span class="p">(</span><span class="n">frame_idxs</span><span class="o">=</span><span class="n">frames_idx</span><span class="p">)</span>
                <span class="n">subchunks_to_process</span> <span class="o">=</span> <span class="p">[(</span><span class="n">imgs_full</span><span class="p">,</span> <span class="n">transform</span><span class="p">)]</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Transformed images [</span><span class="si">%.1f</span><span class="s2">s]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>

            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Step 2: Inference</span>

<span class="sd">            This is where we predict using the trained models, and then</span>
<span class="sd">            convert the outputs of these models to *instances* in *frames*.</span>

<span class="sd">            Input: the list of (images, transform) from pre-processing</span>

<span class="sd">            Output: a list of LabeledFrames for each (images, transform)</span>
<span class="sd">                each of these is a &quot;subchunk&quot;</span>
<span class="sd">            &quot;&quot;&quot;</span>

            <span class="n">subchunk_results</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">subchunk_imgs_full</span><span class="p">,</span> <span class="n">subchunk_transform</span> <span class="ow">in</span> <span class="n">subchunks_to_process</span><span class="p">:</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;  Running inference for subchunk:&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;    Shape: </span><span class="si">{subchunk_imgs_full.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;    Scale: </span><span class="si">{subchunk_transform.scale}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">ModelOutputType</span><span class="o">.</span><span class="n">PART_AFFINITY_FIELD</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_models</span><span class="p">:</span>
                    <span class="c1"># Pipeline for predicting a single animal in a frame</span>
                    <span class="c1"># This uses only confidence maps</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No PAF model! Running in SINGLE INSTANCE mode.&quot;</span><span class="p">)</span>

                    <span class="n">subchunk_lfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">single_instance_inference</span><span class="p">(</span>
                        <span class="n">subchunk_imgs_full</span><span class="p">,</span> <span class="n">subchunk_transform</span><span class="p">,</span> <span class="n">vid</span>
                    <span class="p">)</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Pipeline for predicting multiple animals in a frame</span>
                    <span class="c1"># This uses confidence maps and part affinity fields</span>
                    <span class="n">subchunk_lfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_instance_inference</span><span class="p">(</span>
                        <span class="n">subchunk_imgs_full</span><span class="p">,</span> <span class="n">subchunk_transform</span><span class="p">,</span> <span class="n">vid</span>
                    <span class="p">)</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="n">f</span><span class="s2">&quot;    Subchunk frames with instances found: {len(subchunk_lfs)}&quot;</span>
                <span class="p">)</span>

                <span class="n">subchunk_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">subchunk_lfs</span><span class="p">)</span>

            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Step 3: Post-processing</span>

<span class="sd">            Here we do steps that potentially involve multiple frames:</span>

<span class="sd">            * merge data from separate subchunks</span>
<span class="sd">            * track instances across frames</span>
<span class="sd">            * save predictions</span>

<span class="sd">            Inputs: the lists of lists of LabeledFrames</span>

<span class="sd">            Outputs: a single list of LabeledFrames</span>
<span class="sd">            &quot;&quot;&quot;</span>

            <span class="c1"># Merge frames from multiple processing subchunks</span>
            <span class="n">predicted_frames_chunk</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">subchunk_frames</span> <span class="ow">in</span> <span class="n">subchunk_results</span><span class="p">:</span>
                <span class="n">predicted_frames_chunk</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">subchunk_frames</span><span class="p">)</span>
            <span class="n">predicted_frames_chunk</span> <span class="o">=</span> <span class="n">LabeledFrame</span><span class="o">.</span><span class="n">merge_frames</span><span class="p">(</span>
                <span class="n">predicted_frames_chunk</span><span class="p">,</span> <span class="n">video</span><span class="o">=</span><span class="n">vid</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="n">f</span><span class="s2">&quot;  Instances found on {len(predicted_frames_chunk)} out of {len(imgs_full)} frames.&quot;</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_frames_chunk</span><span class="p">):</span>

                <span class="c1"># Sort by frame index</span>
                <span class="n">predicted_frames_chunk</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">lf</span><span class="p">:</span> <span class="n">lf</span><span class="o">.</span><span class="n">frame_idx</span><span class="p">)</span>

                <span class="c1"># Track</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_tracking</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_frames_chunk</span><span class="p">):</span>
                    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
                    <span class="n">tracker</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">imgs_full</span><span class="p">,</span> <span class="n">predicted_frames_chunk</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Tracked IDs via flow shift [</span><span class="si">%.1f</span><span class="s2">s]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>

                <span class="c1"># Save</span>
                <span class="n">predicted_frames</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">predicted_frames_chunk</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">chunk</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_frequency</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">chunk</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_chunks</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

                    <span class="c1"># TODO: We are re-writing the whole output each time, this is dumb.</span>
                    <span class="c1">#  We should save in chunks then combine at the end.</span>
                    <span class="n">labels</span> <span class="o">=</span> <span class="n">Labels</span><span class="p">(</span><span class="n">labeled_frames</span><span class="o">=</span><span class="n">predicted_frames</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">):</span>
                            <span class="n">Labels</span><span class="o">.</span><span class="n">save_json</span><span class="p">(</span>
                                <span class="n">labels</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="kc">True</span>
                            <span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">Labels</span><span class="o">.</span><span class="n">save_hdf5</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">)</span>

                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="s2">&quot;  Saved to: </span><span class="si">%s</span><span class="s2"> [</span><span class="si">%.1f</span><span class="s2">s]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span>
                        <span class="p">)</span>

            <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0_chunk</span>
            <span class="n">total_elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0_start</span>
            <span class="n">fps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_frames</span><span class="p">)</span> <span class="o">/</span> <span class="n">total_elapsed</span>
            <span class="n">frames_left</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_frames</span><span class="p">)</span>
            <span class="n">eta</span> <span class="o">=</span> <span class="p">(</span><span class="n">frames_left</span> <span class="o">/</span> <span class="n">fps</span><span class="p">)</span> <span class="k">if</span> <span class="n">fps</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;  Finished chunk [</span><span class="si">%.1f</span><span class="s2">s / </span><span class="si">%.1f</span><span class="s2"> FPS / ETA: </span><span class="si">%.1f</span><span class="s2"> min]&quot;</span>
                <span class="o">%</span> <span class="p">(</span><span class="n">elapsed</span><span class="p">,</span> <span class="n">fps</span><span class="p">,</span> <span class="n">eta</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Total: </span><span class="si">%.1f</span><span class="s2"> min&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">total_elapsed</span> <span class="o">/</span> <span class="mi">60</span><span class="p">))</span>

        <span class="c1"># Generate Labels object from predicted frames</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">Labels</span><span class="p">(</span><span class="n">labeled_frames</span><span class="o">=</span><span class="n">predicted_frames</span><span class="p">)</span>

        <span class="c1"># Make sure we only have a single LabeledFrame for each frame idx</span>
        <span class="n">labels</span><span class="o">.</span><span class="n">merge_matching_frames</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_async</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">labels</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">labels</span></div>

<div class="viewcode-block" id="Predictor.predict_async"><a class="viewcode-back" href="../../../inference.html#sleap.nn.inference.Predictor.predict_async">[docs]</a>    <span class="k">def</span> <span class="nf">predict_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Pool</span><span class="p">,</span> <span class="n">AsyncResult</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run the entire inference pipeline on an input file,</span>
<span class="sd">        using a background process.</span>

<span class="sd">        Args:</span>
<span class="sd">            See Predictor.predict().</span>
<span class="sd">            Note that video must be string rather than `Video`</span>
<span class="sd">            (which doesn&#39;t pickle).</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tuple containing the multiprocessing.Process that is</span>
<span class="sd">            running predict, start() has been called. The AysncResult</span>
<span class="sd">            object that will contain the result when the job finishes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;is_async&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;input_video&quot;</span><span class="p">],</span> <span class="n">Video</span><span class="p">):</span>
            <span class="c1"># unstructure input_video since it won&#39;t pickle</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;input_video&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Video</span><span class="o">.</span><span class="n">cattr</span><span class="p">()</span><span class="o">.</span><span class="n">unstructure</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;input_video&quot;</span><span class="p">])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="o">.</span><span class="n">apply_async</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">kwds</span><span class="o">=</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Tell the pool to accept no new tasks</span>
        <span class="c1"># pool.close()</span>

        <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="Predictor.centroid_crop_inference"><a class="viewcode-back" href="../../../inference.html#sleap.nn.inference.Predictor.centroid_crop_inference">[docs]</a>    <span class="k">def</span> <span class="nf">centroid_crop_inference</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">imgs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">frames_idx</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">box_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_merge</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">DataTransform</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Takes stack of images and runs centroid inference to get crops.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            imgs: stack of images in a numpy matrix</span>

<span class="sd">        Returns:</span>
<span class="sd">            list of &quot;subchunks&quot;, each an (images, transform)-tuple</span>

<span class="sd">        Different subchunks can thus have different images sizes,</span>
<span class="sd">        which allows us to merge overlapping crops into larger crops.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Get inference models with metadata.</span>
        <span class="n">centroid_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_models</span><span class="p">[</span><span class="n">ModelOutputType</span><span class="o">.</span><span class="n">CENTROIDS</span><span class="p">]</span>
        <span class="n">cm_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_models</span><span class="p">[</span><span class="n">ModelOutputType</span><span class="o">.</span><span class="n">CONFIDENCE_MAP</span><span class="p">]</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Performing centroid cropping.&quot;</span><span class="p">)</span>

        <span class="c1"># TODO: Replace this calculation when model-specific divisibility calculation implemented.</span>
        <span class="n">divisor</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">centroid_model</span><span class="o">.</span><span class="n">down_blocks</span>
        <span class="n">crop_within</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="n">divisor</span><span class="p">)</span> <span class="o">*</span> <span class="n">divisor</span><span class="p">,</span>
            <span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="n">divisor</span><span class="p">)</span> <span class="o">*</span> <span class="n">divisor</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;    crop_within: </span><span class="si">{crop_within}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Create transform</span>
        <span class="c1"># This lets us scale the images before we predict centroids,</span>
        <span class="c1"># and will also let us map the points on the scaled image to</span>
        <span class="c1"># points on the original images so we can crop original images.</span>
        <span class="n">centroid_transform</span> <span class="o">=</span> <span class="n">DataTransform</span><span class="p">()</span>
        <span class="n">target_shape</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">centroid_model</span><span class="o">.</span><span class="n">input_scale</span><span class="p">),</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">centroid_model</span><span class="o">.</span><span class="n">input_scale</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Scale to match input size of trained centroid model.</span>
        <span class="n">centroid_imgs_scaled</span> <span class="o">=</span> <span class="n">centroid_transform</span><span class="o">.</span><span class="n">scale_to</span><span class="p">(</span>
            <span class="n">imgs</span><span class="o">=</span><span class="n">imgs</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="n">target_shape</span>
        <span class="p">)</span>

        <span class="c1"># Predict centroid confidence maps, then find peaks.</span>
        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
        <span class="n">centroid_confmaps</span> <span class="o">=</span> <span class="n">centroid_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">centroid_imgs_scaled</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_batch_size</span>
        <span class="p">)</span>

        <span class="n">peaks</span><span class="p">,</span> <span class="n">peak_vals</span> <span class="o">=</span> <span class="n">find_all_peaks</span><span class="p">(</span>
            <span class="n">centroid_confmaps</span><span class="p">,</span> <span class="n">min_thresh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nms_min_thresh</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nms_sigma</span>
        <span class="p">)</span>

        <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
        <span class="n">total_peaks</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">frame_peaks</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">frame_peaks</span> <span class="ow">in</span> <span class="n">peaks</span><span class="p">])</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="n">f</span><span class="s2">&quot;    Found </span><span class="si">{total_peaks}</span><span class="s2"> centroid peaks ({total_peaks / len(peaks):.2f} centroids/frame) [</span><span class="si">{elapsed:.2f}</span><span class="s2">s].&quot;</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">box_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Get training bounding box size to determine (min) centroid crop size.</span>
            <span class="c1"># TODO: fix this to use a stored value or move this logic elsewhere</span>
            <span class="n">crop_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
                <span class="nb">max</span><span class="p">(</span><span class="n">cm_model</span><span class="o">.</span><span class="n">trained_input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span> <span class="o">//</span> <span class="n">cm_model</span><span class="o">.</span><span class="n">input_scale</span>
            <span class="p">)</span>
            <span class="n">bb_half</span> <span class="o">=</span> <span class="n">crop_size</span> <span class="o">//</span> <span class="mi">2</span>
            <span class="c1"># bb_half = (crop_size + self.crop_padding) // 2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bb_half</span> <span class="o">=</span> <span class="n">box_size</span> <span class="o">//</span> <span class="mi">2</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;    Crop box size: {bb_half * 2}&quot;</span><span class="p">)</span>

        <span class="c1"># Iterate over each frame to filter bounding boxes</span>
        <span class="n">all_boxes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">frame_i</span><span class="p">,</span> <span class="p">(</span><span class="n">frame_peaks</span><span class="p">,</span> <span class="n">frame_peak_vals</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">peaks</span><span class="p">,</span> <span class="n">peak_vals</span><span class="p">)):</span>

            <span class="c1"># If we found centroids on this frame...</span>
            <span class="k">if</span> <span class="n">frame_peaks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>

                <span class="c1"># Pad each centroid into a bounding box</span>
                <span class="c1"># (We&#39;re not using the pad function because it shifts</span>
                <span class="c1"># boxes to fit within image.)</span>

                <span class="n">boxes</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">peak_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">frame_peaks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>

                    <span class="c1"># Rescale peak back onto full-sized image</span>
                    <span class="n">peak_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
                        <span class="n">frame_peaks</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">peak_i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">centroid_model</span><span class="o">.</span><span class="n">output_scale</span>
                    <span class="p">)</span>
                    <span class="n">peak_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
                        <span class="n">frame_peaks</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">peak_i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">centroid_model</span><span class="o">.</span><span class="n">output_scale</span>
                    <span class="p">)</span>

                    <span class="n">boxes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">(</span>
                            <span class="n">peak_x</span> <span class="o">-</span> <span class="n">bb_half</span><span class="p">,</span>
                            <span class="n">peak_y</span> <span class="o">-</span> <span class="n">bb_half</span><span class="p">,</span>
                            <span class="n">peak_x</span> <span class="o">+</span> <span class="n">bb_half</span><span class="p">,</span>
                            <span class="n">peak_y</span> <span class="o">+</span> <span class="n">bb_half</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>

                <span class="k">if</span> <span class="n">do_merge</span><span class="p">:</span>
                    <span class="c1"># Merge overlapping boxes and pad to multiple of crop size</span>
                    <span class="n">merged_boxes</span> <span class="o">=</span> <span class="n">merge_boxes_with_overlap_and_padding</span><span class="p">(</span>
                        <span class="n">boxes</span><span class="o">=</span><span class="n">boxes</span><span class="p">,</span>
                        <span class="n">pad_factor_box</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">crop_growth</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_growth</span><span class="p">),</span>
                        <span class="n">within</span><span class="o">=</span><span class="n">crop_within</span><span class="p">,</span>
                    <span class="p">)</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Just return the boxes centered around each centroid.</span>
                    <span class="c1"># Note that these aren&#39;t guaranteed to be within the</span>
                    <span class="c1"># image bounds, so take care if using these to crop.</span>
                    <span class="n">merged_boxes</span> <span class="o">=</span> <span class="n">boxes</span>

                <span class="c1"># Keep track of all boxes, grouped by size and frame idx</span>
                <span class="k">for</span> <span class="n">box</span> <span class="ow">in</span> <span class="n">merged_boxes</span><span class="p">:</span>

                    <span class="n">merged_box_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">box</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">box</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">box</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

                    <span class="k">if</span> <span class="n">merged_box_size</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">all_boxes</span><span class="p">:</span>
                        <span class="n">all_boxes</span><span class="p">[</span><span class="n">merged_box_size</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;    Found box size: </span><span class="si">{merged_box_size}</span><span class="s2">&quot;</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">frame_i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">all_boxes</span><span class="p">[</span><span class="n">merged_box_size</span><span class="p">]:</span>
                        <span class="n">all_boxes</span><span class="p">[</span><span class="n">merged_box_size</span><span class="p">][</span><span class="n">frame_i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

                    <span class="n">all_boxes</span><span class="p">[</span><span class="n">merged_box_size</span><span class="p">][</span><span class="n">frame_i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">box</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;    Found {len(all_boxes)} box sizes after merging.&quot;</span><span class="p">)</span>

        <span class="n">subchunks</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Check if we found any boxes for this chunk of frames</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_boxes</span><span class="p">):</span>

            <span class="c1"># We&#39;ll make a &quot;subchunk&quot; for each crop size</span>
            <span class="k">for</span> <span class="n">crop_size</span> <span class="ow">in</span> <span class="n">all_boxes</span><span class="p">:</span>

                <span class="c1"># TODO: Look into this edge case?</span>
                <span class="c1"># if crop_size[0] &gt;= 1024:</span>
                <span class="c1">#     logger.info(f&quot;  Skipping subchunk for size {crop_size}, would have {len(all_boxes[crop_size])} crops.&quot;)</span>
                <span class="c1">#     for debug_frame_idx in all_boxes[crop_size].keys():</span>
                <span class="c1">#         print(f&quot;    frame {frames_idx[debug_frame_idx]}: {all_boxes[crop_size][debug_frame_idx]}&quot;)</span>
                <span class="c1">#     continue</span>

                <span class="c1"># Make list of all boxes and corresponding img index.</span>
                <span class="n">subchunk_idxs</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">subchunk_boxes</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="k">for</span> <span class="n">frame_i</span><span class="p">,</span> <span class="n">frame_boxes</span> <span class="ow">in</span> <span class="n">all_boxes</span><span class="p">[</span><span class="n">crop_size</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">subchunk_boxes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">frame_boxes</span><span class="p">)</span>
                    <span class="n">subchunk_idxs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">frame_i</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">frame_boxes</span><span class="p">))</span>

                <span class="c1"># TODO: This should probably be in the main loop</span>
                <span class="c1"># Create transform object</span>
                <span class="c1"># transform = DataTransform(frame_idxs=frames_idx, scale=cm_model.output_relative_scale)</span>
                <span class="n">transform</span> <span class="o">=</span> <span class="n">DataTransform</span><span class="p">(</span><span class="n">frame_idxs</span><span class="o">=</span><span class="n">frames_idx</span><span class="p">)</span>

                <span class="c1"># Do the cropping</span>
                <span class="n">imgs_cropped</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">subchunk_boxes</span><span class="p">,</span> <span class="n">subchunk_idxs</span><span class="p">)</span>

                <span class="c1"># Add subchunk</span>
                <span class="n">subchunks</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">imgs_cropped</span><span class="p">,</span> <span class="n">transform</span><span class="p">))</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="n">f</span><span class="s2">&quot;  Subchunk for size </span><span class="si">{crop_size}</span><span class="s2"> has {len(imgs_cropped)} crops.&quot;</span>
                <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  No centroids found so done with this chunk.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">subchunks</span></div>

<div class="viewcode-block" id="Predictor.single_instance_inference"><a class="viewcode-back" href="../../../inference.html#sleap.nn.inference.Predictor.single_instance_inference">[docs]</a>    <span class="k">def</span> <span class="nf">single_instance_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">transform</span><span class="p">,</span> <span class="n">video</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">LabeledFrame</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Run the single instance pipeline for a stack of images.</span>

<span class="sd">        Args:</span>
<span class="sd">            imgs: Subchunk of images to process.</span>
<span class="sd">            transform: DataTransform object tracking input transformations.</span>
<span class="sd">            video: Video object for building LabeledFrames with correct reference to source.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of LabeledFrames with predicted points.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Get confmap inference model.</span>
        <span class="n">cm_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_models</span><span class="p">[</span><span class="n">ModelOutputType</span><span class="o">.</span><span class="n">CONFIDENCE_MAP</span><span class="p">]</span>

        <span class="c1"># Scale to match input size of trained model.</span>
        <span class="c1"># Images are expected to be at full resolution, but may be cropped.</span>
        <span class="k">assert</span> <span class="n">transform</span><span class="o">.</span><span class="n">scale</span> <span class="o">==</span> <span class="mf">1.0</span>
        <span class="n">target_shape</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">cm_model</span><span class="o">.</span><span class="n">input_scale</span><span class="p">),</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">cm_model</span><span class="o">.</span><span class="n">input_scale</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">imgs_scaled</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">scale_to</span><span class="p">(</span><span class="n">imgs</span><span class="o">=</span><span class="n">imgs</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="n">target_shape</span><span class="p">)</span>

        <span class="c1"># TODO: Adjust for divisibility</span>
        <span class="c1"># divisor = 2 ** cm_model.down_blocks</span>
        <span class="c1"># crop_within = ((imgs.shape[1] // divisor) * divisor, (imgs.shape[2] // divisor) * divisor)</span>

        <span class="c1"># Run inference.</span>
        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
        <span class="n">confmaps</span> <span class="o">=</span> <span class="n">cm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">imgs_scaled</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_batch_size</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Inferred confmaps [</span><span class="si">%.1f</span><span class="s2">s]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;    confmaps: shape=</span><span class="si">{confmaps.shape}</span><span class="s2">, ptp={np.ptp(confmaps)}&quot;</span><span class="p">)</span>

        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

        <span class="c1"># TODO: Move this to GPU and add subpixel refinement.</span>
        <span class="c1"># Use single highest peak in channel corresponding node</span>
        <span class="n">points_arrays</span> <span class="o">=</span> <span class="n">find_all_single_peaks</span><span class="p">(</span><span class="n">confmaps</span><span class="p">,</span> <span class="n">min_thresh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nms_min_thresh</span><span class="p">)</span>

        <span class="c1"># Adjust for multi-scale such that the points are at the scale of the transform.</span>
        <span class="n">points_arrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">pts</span> <span class="o">/</span> <span class="n">cm_model</span><span class="o">.</span><span class="n">output_relative_scale</span> <span class="k">for</span> <span class="n">pts</span> <span class="ow">in</span> <span class="n">points_arrays</span><span class="p">]</span>

        <span class="c1"># Create labeled frames and predicted instances from the points.</span>
        <span class="n">predicted_frames_chunk</span> <span class="o">=</span> <span class="n">match_single_peaks_all</span><span class="p">(</span>
            <span class="n">points_arrays</span><span class="o">=</span><span class="n">points_arrays</span><span class="p">,</span>
            <span class="n">skeleton</span><span class="o">=</span><span class="n">cm_model</span><span class="o">.</span><span class="n">skeleton</span><span class="p">,</span>
            <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span>
            <span class="n">video</span><span class="o">=</span><span class="n">video</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Used highest peaks to create instances [</span><span class="si">%.1f</span><span class="s2">s]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>

        <span class="c1"># Save confmaps</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_confmaps_pafs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Not saving confmaps/pafs because feature currently not working.&quot;</span>
            <span class="p">)</span>
            <span class="c1"># Disable save_confmaps_pafs since not currently working.</span>
            <span class="c1"># The problem is that we can&#39;t put data for different crop sizes</span>
            <span class="c1"># all into a single h5 datasource. It&#39;s now possible to view live</span>
            <span class="c1"># predicted confmap and paf in the gui, so this isn&#39;t high priority.</span>
            <span class="c1"># save_visual_outputs(</span>
            <span class="c1">#         output_path = self.output_path,</span>
            <span class="c1">#         data = dict(confmaps=confmaps, box=imgs))</span>

        <span class="k">return</span> <span class="n">predicted_frames_chunk</span></div>

<div class="viewcode-block" id="Predictor.multi_instance_inference"><a class="viewcode-back" href="../../../inference.html#sleap.nn.inference.Predictor.multi_instance_inference">[docs]</a>    <span class="k">def</span> <span class="nf">multi_instance_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">transform</span><span class="p">,</span> <span class="n">video</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">LabeledFrame</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Run the multi-instance inference pipeline for a stack of images.</span>

<span class="sd">        Args:</span>
<span class="sd">            imgs: Subchunk of images to process.</span>
<span class="sd">            transform: DataTransform object tracking input transformations.</span>
<span class="sd">            video: Video object for building LabeledFrames with correct reference to source.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of LabeledFrames with predicted points.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Load appropriate models as needed</span>
        <span class="n">cm_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_models</span><span class="p">[</span><span class="n">ModelOutputType</span><span class="o">.</span><span class="n">CONFIDENCE_MAP</span><span class="p">]</span>
        <span class="n">paf_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_models</span><span class="p">[</span><span class="n">ModelOutputType</span><span class="o">.</span><span class="n">PART_AFFINITY_FIELD</span><span class="p">]</span>

        <span class="c1"># Find peaks</span>
        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

        <span class="c1"># Scale to match input resolution of model.</span>
        <span class="c1"># Images are expected to be at full resolution, but may be cropped.</span>
        <span class="k">assert</span> <span class="n">transform</span><span class="o">.</span><span class="n">scale</span> <span class="o">==</span> <span class="mf">1.0</span>
        <span class="n">cm_target_shape</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">cm_model</span><span class="o">.</span><span class="n">input_scale</span><span class="p">),</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">cm_model</span><span class="o">.</span><span class="n">input_scale</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">imgs_scaled</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">scale_to</span><span class="p">(</span><span class="n">imgs</span><span class="o">=</span><span class="n">imgs</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="n">cm_target_shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">imgs_scaled</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s2">&quot;uint8&quot;</span><span class="p">):</span>  <span class="c1"># TODO: Unify normalization.</span>
            <span class="n">imgs_scaled</span> <span class="o">=</span> <span class="n">imgs_scaled</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>

        <span class="c1"># TODO: Unfuck this whole workflow</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gpu_peak_finding</span><span class="p">:</span>
            <span class="n">confmaps_shape</span> <span class="o">=</span> <span class="n">cm_model</span><span class="o">.</span><span class="n">compute_output_shape</span><span class="p">(</span>
                <span class="p">(</span><span class="n">imgs_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">imgs_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="p">)</span>
            <span class="n">peaks</span><span class="p">,</span> <span class="n">peak_vals</span><span class="p">,</span> <span class="n">confmaps</span> <span class="o">=</span> <span class="n">peak_tf_inference</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">cm_model</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span>
                <span class="n">confmaps_shape</span><span class="o">=</span><span class="n">confmaps_shape</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">imgs_scaled</span><span class="p">,</span>
                <span class="n">min_thresh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nms_min_thresh</span><span class="p">,</span>
                <span class="n">gaussian_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nms_kernel_size</span><span class="p">,</span>
                <span class="n">gaussian_sigma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nms_sigma</span><span class="p">,</span>
                <span class="n">upsample_factor</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">supersample_factor</span> <span class="o">/</span> <span class="n">cm_model</span><span class="o">.</span><span class="n">output_scale</span><span class="p">),</span>
                <span class="n">win_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">supersample_window_size</span><span class="p">,</span>
                <span class="n">return_confmaps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">save_confmaps_pafs</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_batch_size</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">confmaps</span> <span class="o">=</span> <span class="n">cm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                <span class="n">imgs_scaled</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_batch_size</span>
            <span class="p">)</span>
            <span class="n">peaks</span><span class="p">,</span> <span class="n">peak_vals</span> <span class="o">=</span> <span class="n">find_all_peaks</span><span class="p">(</span>
                <span class="n">confmaps</span><span class="p">,</span> <span class="n">min_thresh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nms_min_thresh</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nms_sigma</span>
            <span class="p">)</span>

        <span class="c1"># # Undo just the scaling so we&#39;re back to full resolution, but possibly cropped.</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">peaks</span><span class="p">)):</span>  <span class="c1"># frames</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">peaks</span><span class="p">[</span><span class="n">t</span><span class="p">])):</span>  <span class="c1"># channels</span>
                <span class="n">peaks</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">c</span><span class="p">]</span> <span class="o">/=</span> <span class="n">cm_model</span><span class="o">.</span><span class="n">output_scale</span>

        <span class="c1"># Peaks should be at (refined) full resolution now.</span>
        <span class="c1"># Keep track of scale adjustment.</span>
        <span class="n">transform</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span>

        <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
        <span class="n">total_peaks</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">channel_peaks</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">frame_peaks</span> <span class="ow">in</span> <span class="n">peaks</span>
                <span class="k">for</span> <span class="n">channel_peaks</span> <span class="ow">in</span> <span class="n">frame_peaks</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="n">f</span><span class="s2">&quot;    Found </span><span class="si">{total_peaks}</span><span class="s2"> peaks ({total_peaks / len(imgs):.2f} peaks/frame) [</span><span class="si">{elapsed:.2f}</span><span class="s2">s].&quot;</span>
        <span class="p">)</span>
        <span class="c1"># logger.info(f&quot;    peaks: {peaks}&quot;)</span>

        <span class="c1"># Scale to match input resolution of model.</span>
        <span class="c1"># Images are expected to be at full resolution, but may be cropped.</span>
        <span class="n">paf_target_shape</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">paf_model</span><span class="o">.</span><span class="n">input_scale</span><span class="p">),</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">paf_model</span><span class="o">.</span><span class="n">input_scale</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">imgs_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">paf_target_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">imgs_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">paf_target_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">):</span>
            <span class="c1"># No need to scale again if we&#39;re already there, so just adjust the stored scale</span>
            <span class="n">transform</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">paf_model</span><span class="o">.</span><span class="n">input_scale</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Adjust scale from full resolution images (avoiding possible resizing up from confmaps input scale)</span>
            <span class="n">imgs_scaled</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">scale_to</span><span class="p">(</span><span class="n">imgs</span><span class="o">=</span><span class="n">imgs</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="n">paf_target_shape</span><span class="p">)</span>

        <span class="c1"># Infer pafs</span>
        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
        <span class="n">pafs</span> <span class="o">=</span> <span class="n">paf_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">imgs_scaled</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_batch_size</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Inferred PAFs [</span><span class="si">%.1f</span><span class="s2">s]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;    pafs: shape=</span><span class="si">{pafs.shape}</span><span class="s2">, ptp={np.ptp(pafs)}&quot;</span><span class="p">)</span>

        <span class="c1"># Adjust points to the paf output scale so we can invert later (should not incur loss of precision)</span>
        <span class="c1"># TODO: Check precision</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">peaks</span><span class="p">)):</span>  <span class="c1"># frames</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">peaks</span><span class="p">[</span><span class="n">t</span><span class="p">])):</span>  <span class="c1"># channels</span>
                <span class="n">peaks</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">c</span><span class="p">]</span> <span class="o">*=</span> <span class="n">paf_model</span><span class="o">.</span><span class="n">output_scale</span>
        <span class="n">transform</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">paf_model</span><span class="o">.</span><span class="n">output_scale</span>

        <span class="c1"># Determine whether to use serial or parallel version of peak-finding</span>
        <span class="c1"># Use the serial version is we&#39;re already running in a thread pool</span>
        <span class="n">match_peaks_function</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">match_peaks_paf_par</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_async</span> <span class="k">else</span> <span class="n">match_peaks_paf</span>
        <span class="p">)</span>

        <span class="c1"># Match peaks via PAFs</span>
        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
        <span class="n">predicted_frames_chunk</span> <span class="o">=</span> <span class="n">match_peaks_function</span><span class="p">(</span>
            <span class="n">peaks</span><span class="p">,</span>
            <span class="n">peak_vals</span><span class="p">,</span>
            <span class="n">pafs</span><span class="p">,</span>
            <span class="n">paf_model</span><span class="o">.</span><span class="n">skeleton</span><span class="p">,</span>
            <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span>
            <span class="n">video</span><span class="o">=</span><span class="n">video</span><span class="p">,</span>
            <span class="n">min_score_to_node_ratio</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_score_to_node_ratio</span><span class="p">,</span>
            <span class="n">min_score_midpts</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_score_midpts</span><span class="p">,</span>
            <span class="n">min_score_integral</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_score_integral</span><span class="p">,</span>
            <span class="n">add_last_edge</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">add_last_edge</span><span class="p">,</span>
            <span class="n">single_per_crop</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">single_per_crop</span><span class="p">,</span>
            <span class="n">pool</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">total_instances</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">labeled_frame</span><span class="p">)</span> <span class="k">for</span> <span class="n">labeled_frame</span> <span class="ow">in</span> <span class="n">predicted_frames_chunk</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Matched peaks via PAFs [</span><span class="si">%.1f</span><span class="s2">s]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="n">f</span><span class="s2">&quot;    Found </span><span class="si">{total_instances}</span><span class="s2"> instances ({total_instances / len(imgs):.2f} instances/frame)&quot;</span>
        <span class="p">)</span>

        <span class="c1"># Remove overlapping predicted instances</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">overlapping_instances_nms</span><span class="p">:</span>
            <span class="n">t0</span> <span class="o">=</span> <span class="n">clock</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">lf</span> <span class="ow">in</span> <span class="n">predicted_frames_chunk</span><span class="p">:</span>
                <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lf</span><span class="o">.</span><span class="n">instances</span><span class="p">)</span>
                <span class="n">instances_nms</span><span class="p">(</span><span class="n">lf</span><span class="o">.</span><span class="n">instances</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lf</span><span class="o">.</span><span class="n">instances</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="n">f</span><span class="s2">&quot;    Removed {n-len(lf.instances)} overlapping instance(s) from frame </span><span class="si">{lf.frame_idx}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;    Instance NMS [</span><span class="si">%.1f</span><span class="s2">s]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">clock</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>

        <span class="c1"># Save confmaps and pafs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_confmaps_pafs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Not saving confmaps/pafs because feature currently not working.&quot;</span>
            <span class="p">)</span>
            <span class="c1"># Disable save_confmaps_pafs since not currently working.</span>
            <span class="c1"># The problem is that we can&#39;t put data for different crop sizes</span>
            <span class="c1"># all into a single h5 datasource. It&#39;s now possible to view live</span>
            <span class="c1"># predicted confmap and paf in the gui, so this isn&#39;t high priority.</span>
            <span class="c1"># save_visual_outputs(</span>
            <span class="c1">#         output_path = self.output_path,</span>
            <span class="c1">#         data = dict(confmaps=confmaps, pafs=pafs,</span>
            <span class="c1">#             frame_idxs=transform.frame_idxs, bounds=transform.bounding_boxes))</span>

        <span class="k">return</span> <span class="n">predicted_frames_chunk</span></div></div>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">frame_list</span><span class="p">(</span><span class="n">frame_str</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>

        <span class="c1"># Handle ranges of frames. Must be of the form &quot;1-200&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;-&quot;</span> <span class="ow">in</span> <span class="n">frame_str</span><span class="p">:</span>
            <span class="n">min_max</span> <span class="o">=</span> <span class="n">frame_str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
            <span class="n">min_frame</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">min_max</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">max_frame</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">min_max</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">min_frame</span><span class="p">,</span> <span class="n">max_frame</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">frame_str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">frame_str</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;data_path&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to video file&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;-m&quot;</span><span class="p">,</span>
        <span class="s2">&quot;--model&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;append&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to saved model (confmaps, pafs, ...) JSON. &quot;</span>
        <span class="s2">&quot;Multiple models can be specified, each preceded by &quot;</span>
        <span class="s2">&quot;--model. Confmap and PAF models are required.&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--resize-input&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;resize_input&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_const&quot;</span><span class="p">,</span>
        <span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;resize the input layer to image size (default False)&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--with-tracking&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;with_tracking&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_const&quot;</span><span class="p">,</span>
        <span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;just visualize predicted confmaps/pafs (default False)&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--frames&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">frame_list</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;list of frames to predict. Either comma separated list (e.g. 1,2,3) or &quot;</span>
        <span class="s2">&quot;a range separated by hyphen (e.g. 1-3). (default is entire video)&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;-o&quot;</span><span class="p">,</span>
        <span class="s2">&quot;--output&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The output filename to use for the predicted data.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--out_format&quot;</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;hdf5&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The format to use for&quot;</span>
        <span class="s2">&quot; the output file. Either hdf5 or json. hdf5 is the default.&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;hdf5&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--save-confmaps-pafs&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;save_confmaps_pafs&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_const&quot;</span><span class="p">,</span>
        <span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Whether to save the confidence maps or pafs&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;-v&quot;</span><span class="p">,</span>
        <span class="s2">&quot;--verbose&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Increase logging output verbosity.&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">out_format</span> <span class="o">==</span> <span class="s2">&quot;json&quot;</span><span class="p">:</span>
        <span class="n">output_suffix</span> <span class="o">=</span> <span class="s2">&quot;.predictions.json&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">output_suffix</span> <span class="o">=</span> <span class="s2">&quot;.predictions.h5&quot;</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output_suffix</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;.frames{min(args.frames)}_{max(args.frames)}&quot;</span> <span class="o">+</span> <span class="n">output_suffix</span>

    <span class="n">data_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">data_path</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">output</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">output</span> <span class="k">else</span> <span class="n">data_path</span> <span class="o">+</span> <span class="n">output_suffix</span>
    <span class="n">frames</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">frames</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">()</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>

    <span class="c1"># Load each model JSON</span>
    <span class="n">jobs</span> <span class="o">=</span> <span class="p">[</span><span class="n">TrainingJob</span><span class="o">.</span><span class="n">load_json</span><span class="p">(</span><span class="n">model_filename</span><span class="p">)</span> <span class="k">for</span> <span class="n">model_filename</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">models</span><span class="p">]</span>
    <span class="n">sleap_models</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">([</span><span class="n">j</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">output_type</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">jobs</span><span class="p">],</span> <span class="n">jobs</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">ModelOutputType</span><span class="o">.</span><span class="n">CONFIDENCE_MAP</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sleap_models</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No confidence map model found in specified models!&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">resize_input</span><span class="p">:</span>
        <span class="c1"># Load video</span>
        <span class="n">vid</span> <span class="o">=</span> <span class="n">Video</span><span class="o">.</span><span class="n">from_filename</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>
        <span class="n">img_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">vid</span><span class="o">.</span><span class="n">height</span><span class="p">,</span> <span class="n">vid</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">vid</span><span class="o">.</span><span class="n">channels</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">img_shape</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Create a predictor to do the work.</span>
    <span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">(</span>
        <span class="n">training_jobs</span><span class="o">=</span><span class="n">sleap_models</span><span class="p">,</span>
        <span class="n">output_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span>
        <span class="n">save_confmaps_pafs</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_confmaps_pafs</span><span class="p">,</span>
        <span class="n">with_tracking</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">with_tracking</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Run the inference pipeline</span>
    <span class="k">return</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_video</span><span class="o">=</span><span class="n">data_path</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="n">frames</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Murthy Lab @ Princeton

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>