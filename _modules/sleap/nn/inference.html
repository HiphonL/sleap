
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>sleap.nn.inference &#8212; SLEAP  documentation</title>
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/alabaster.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for sleap.nn.inference</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Inference pipelines and utilities.</span>

<span class="sd">This module contains the classes and high level APIs for predicting instances on new</span>
<span class="sd">data using trained models.</span>

<span class="sd">The inference logic is implemented at two levels:</span>

<span class="sd">- Low-level `InferenceModel`s which subclass `tf.keras.Model` and implement the core</span>
<span class="sd">  TensorFlow operations surrounding inference. These should only be used when</span>
<span class="sd">  implementing custom inference routines, such as real-time or performance-critical</span>
<span class="sd">  applications. They do not implement tracking (identity association).</span>

<span class="sd">- High-level `Predictor`s which handle data loading, preprocessing, inference, tracking</span>
<span class="sd">  and postprocessing, including converting raw array results into SLEAP-specific data</span>
<span class="sd">  structures. These should be used for general-purpose prediction, including interactive</span>
<span class="sd">  inference and applications that require tracking (identity association).</span>

<span class="sd">For more information on tracking, see the `sleap.nn.tracking` module.</span>

<span class="sd">The recommended high-level API for loading saved models is the `sleap.load_models`</span>
<span class="sd">function which provides a simplified interface for creating `Predictor`s.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">atexit</span>
<span class="kn">import</span> <span class="nn">rich.progress</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Text</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">sleap</span>
<span class="kn">from</span> <span class="nn">sleap.nn.config</span> <span class="kn">import</span> <span class="n">TrainingJobConfig</span>
<span class="kn">from</span> <span class="nn">sleap.nn.model</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">sleap.nn.tracking</span> <span class="kn">import</span> <span class="n">Tracker</span>
<span class="kn">from</span> <span class="nn">sleap.nn.paf_grouping</span> <span class="kn">import</span> <span class="n">PAFScorer</span>
<span class="kn">from</span> <span class="nn">sleap.nn.data.pipelines</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Provider</span><span class="p">,</span>
    <span class="n">Pipeline</span><span class="p">,</span>
    <span class="n">LabelsReader</span><span class="p">,</span>
    <span class="n">VideoReader</span><span class="p">,</span>
    <span class="n">Normalizer</span><span class="p">,</span>
    <span class="n">Resizer</span><span class="p">,</span>
    <span class="n">Prefetcher</span><span class="p">,</span>
    <span class="n">KerasModelPredictor</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="get_keras_model_path"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.get_keras_model_path">[docs]</a><span class="k">def</span> <span class="nf">get_keras_model_path</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="n">Text</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Utility method for finding the path to a saved Keras model.</span>

<span class="sd">    Args:</span>
<span class="sd">        path: Path to a model run folder or job file.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Path to `best_model.h5` in the run folder.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Move this to TrainingJobConfig or Model?</span>
    <span class="k">if</span> <span class="n">path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.json&quot;</span><span class="p">):</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;best_model.h5&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="RateColumn"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.RateColumn">[docs]</a><span class="k">class</span> <span class="nc">RateColumn</span><span class="p">(</span><span class="n">rich</span><span class="o">.</span><span class="n">progress</span><span class="o">.</span><span class="n">ProgressColumn</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Renders the progress rate.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="RateColumn.render"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.RateColumn.render">[docs]</a>    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task</span><span class="p">:</span> <span class="s2">&quot;Task&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">rich</span><span class="o">.</span><span class="n">progress</span><span class="o">.</span><span class="n">Text</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Show progress rate.&quot;&quot;&quot;</span>
        <span class="n">speed</span> <span class="o">=</span> <span class="n">task</span><span class="o">.</span><span class="n">speed</span>
        <span class="k">if</span> <span class="n">speed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">rich</span><span class="o">.</span><span class="n">progress</span><span class="o">.</span><span class="n">Text</span><span class="p">(</span><span class="s2">&quot;?&quot;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;progress.data.speed&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">rich</span><span class="o">.</span><span class="n">progress</span><span class="o">.</span><span class="n">Text</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">speed</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> FPS&quot;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;progress.data.speed&quot;</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Predictor"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.Predictor">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Predictor</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base interface class for predictors.&quot;&quot;&quot;</span>

    <span class="n">verbosity</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">attr</span><span class="o">.</span><span class="n">validators</span><span class="o">.</span><span class="n">in_</span><span class="p">([</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="s2">&quot;rich&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">]),</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;rich&quot;</span><span class="p">,</span>
        <span class="n">kw_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">report_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">kw_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">model_paths</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">factory</span><span class="o">=</span><span class="nb">list</span><span class="p">,</span> <span class="n">kw_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">report_period</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Time between progress reports in seconds.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">report_rate</span>

<div class="viewcode-block" id="Predictor.from_model_paths"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.Predictor.from_model_paths">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_model_paths</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">model_paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">integral_refinement</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">integral_patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Predictor&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create the appropriate `Predictor` subclass from a list of model paths.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_paths: A single or list of trained model paths.</span>
<span class="sd">            peak_threshold: Minimum confidence map value to consider a peak as valid.</span>
<span class="sd">            integral_refinement: If `True`, peaks will be refined with integral</span>
<span class="sd">                regression. If `False`, `&quot;local&quot;`, peaks will be refined with quarter</span>
<span class="sd">                pixel local gradient offset. This has no effect if the model has an</span>
<span class="sd">                offset regression head.</span>
<span class="sd">            integral_patch_size: Size of patches to crop around each rough peak for</span>
<span class="sd">                integral refinement as an integer scalar.</span>
<span class="sd">            batch_size: The default batch size to use when loading data for inference.</span>
<span class="sd">                Higher values increase inference speed at the cost of higher memory</span>
<span class="sd">                usage.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A subclass of `Predictor`.</span>

<span class="sd">        See also: `SingleInstancePredictor`, `TopDownPredictor`, `BottomUpPredictor`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Read configs and find model types.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_paths</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">model_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_paths</span><span class="p">]</span>
        <span class="n">model_configs</span> <span class="o">=</span> <span class="p">[</span><span class="n">sleap</span><span class="o">.</span><span class="n">load_config</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span> <span class="k">for</span> <span class="n">model_path</span> <span class="ow">in</span> <span class="n">model_paths</span><span class="p">]</span>
        <span class="n">model_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">cfg</span><span class="o">.</span><span class="n">filename</span> <span class="k">for</span> <span class="n">cfg</span> <span class="ow">in</span> <span class="n">model_configs</span><span class="p">]</span>
        <span class="n">model_types</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">cfg</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">heads</span><span class="o">.</span><span class="n">which_oneof_attrib_name</span><span class="p">()</span> <span class="k">for</span> <span class="n">cfg</span> <span class="ow">in</span> <span class="n">model_configs</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;single_instance&quot;</span> <span class="ow">in</span> <span class="n">model_types</span><span class="p">:</span>
            <span class="n">predictor</span> <span class="o">=</span> <span class="n">SingleInstancePredictor</span><span class="o">.</span><span class="n">from_trained_models</span><span class="p">(</span>
                <span class="n">model_path</span><span class="o">=</span><span class="n">model_paths</span><span class="p">[</span><span class="n">model_types</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;single_instance&quot;</span><span class="p">)],</span>
                <span class="n">peak_threshold</span><span class="o">=</span><span class="n">peak_threshold</span><span class="p">,</span>
                <span class="n">integral_refinement</span><span class="o">=</span><span class="n">integral_refinement</span><span class="p">,</span>
                <span class="n">integral_patch_size</span><span class="o">=</span><span class="n">integral_patch_size</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">elif</span> <span class="s2">&quot;centroid&quot;</span> <span class="ow">in</span> <span class="n">model_types</span> <span class="ow">or</span> <span class="s2">&quot;centered_instance&quot;</span> <span class="ow">in</span> <span class="n">model_types</span><span class="p">:</span>
            <span class="n">centroid_model_path</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="s2">&quot;centroid&quot;</span> <span class="ow">in</span> <span class="n">model_types</span><span class="p">:</span>
                <span class="n">centroid_model_path</span> <span class="o">=</span> <span class="n">model_paths</span><span class="p">[</span><span class="n">model_types</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;centroid&quot;</span><span class="p">)]</span>

            <span class="n">confmap_model_path</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="s2">&quot;centered_instance&quot;</span> <span class="ow">in</span> <span class="n">model_types</span><span class="p">:</span>
                <span class="n">confmap_model_path</span> <span class="o">=</span> <span class="n">model_paths</span><span class="p">[</span><span class="n">model_types</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;centered_instance&quot;</span><span class="p">)]</span>

            <span class="n">predictor</span> <span class="o">=</span> <span class="n">TopDownPredictor</span><span class="o">.</span><span class="n">from_trained_models</span><span class="p">(</span>
                <span class="n">centroid_model_path</span><span class="o">=</span><span class="n">centroid_model_path</span><span class="p">,</span>
                <span class="n">confmap_model_path</span><span class="o">=</span><span class="n">confmap_model_path</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">peak_threshold</span><span class="o">=</span><span class="n">peak_threshold</span><span class="p">,</span>
                <span class="n">integral_refinement</span><span class="o">=</span><span class="n">integral_refinement</span><span class="p">,</span>
                <span class="n">integral_patch_size</span><span class="o">=</span><span class="n">integral_patch_size</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">elif</span> <span class="s2">&quot;multi_instance&quot;</span> <span class="ow">in</span> <span class="n">model_types</span><span class="p">:</span>
            <span class="n">predictor</span> <span class="o">=</span> <span class="n">BottomUpPredictor</span><span class="o">.</span><span class="n">from_trained_models</span><span class="p">(</span>
                <span class="n">model_path</span><span class="o">=</span><span class="n">model_paths</span><span class="p">[</span><span class="n">model_types</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;multi_instance&quot;</span><span class="p">)],</span>
                <span class="n">peak_threshold</span><span class="o">=</span><span class="n">peak_threshold</span><span class="p">,</span>
                <span class="n">integral_refinement</span><span class="o">=</span><span class="n">integral_refinement</span><span class="p">,</span>
                <span class="n">integral_patch_size</span><span class="o">=</span><span class="n">integral_patch_size</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Could not create predictor from model paths:&quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_paths</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">predictor</span><span class="o">.</span><span class="n">model_paths</span> <span class="o">=</span> <span class="n">model_paths</span>
        <span class="k">return</span> <span class="n">predictor</span></div>

    <span class="nd">@classmethod</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">from_trained_models</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="Predictor.make_pipeline"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.Predictor.make_pipeline">[docs]</a>    <span class="k">def</span> <span class="nf">make_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Provider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Pipeline</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Make a data loading pipeline.</span>

<span class="sd">        Args:</span>
<span class="sd">            data_provider: If not `None`, the pipeline will be created with an instance</span>
<span class="sd">                of a `sleap.pipelines.Provider`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The created `sleap.pipelines.Pipeline` with batching and prefetching.</span>

<span class="sd">        Notes:</span>
<span class="sd">            This method also updates the class attribute for the pipeline and will be</span>
<span class="sd">            called automatically when predicting on data from a new source.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">data_provider</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pipeline</span><span class="o">.</span><span class="n">providers</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_provider</span><span class="p">]</span>

        <span class="n">pipeline</span> <span class="o">+=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">Batcher</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">unrag</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">pipeline</span> <span class="o">+=</span> <span class="n">Prefetcher</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">pipeline</span>

        <span class="k">return</span> <span class="n">pipeline</span></div>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_initialize_inference_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">_predict_generator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">data_provider</span><span class="p">:</span> <span class="n">Provider</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Create a generator that yields batches of inference results.</span>

<span class="sd">        This method handles creating or updating the input `sleap.pipelines.Pipeline`</span>
<span class="sd">        for loading the data, as well as looping over the batches and running inference.</span>

<span class="sd">        Args:</span>
<span class="sd">            data_provider: The `sleap.pipelines.Provider` that contains data that should</span>
<span class="sd">                be used for inference.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A generator yielding batches predicted results as dictionaries of numpy</span>
<span class="sd">            arrays.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialize data pipeline and inference model if needed.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_pipeline</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_inference_model</span><span class="p">()</span>

        <span class="c1"># Update the data provider source.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">providers</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_provider</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">process_batch</span><span class="p">(</span><span class="n">ex</span><span class="p">):</span>
            <span class="c1"># Run inference on current batch.</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_model</span><span class="o">.</span><span class="n">predict_on_batch</span><span class="p">(</span><span class="n">ex</span><span class="p">)</span>

            <span class="c1"># Add model outputs to the input data example.</span>
            <span class="n">ex</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>

            <span class="c1"># Convert to numpy arrays if not already.</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s2">&quot;video_ind&quot;</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;video_ind&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;video_ind&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s2">&quot;frame_ind&quot;</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;frame_ind&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;frame_ind&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

            <span class="k">return</span> <span class="n">ex</span>

        <span class="c1"># Loop over data batches with optional progress reporting.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbosity</span> <span class="o">==</span> <span class="s2">&quot;rich&quot;</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">rich</span><span class="o">.</span><span class="n">progress</span><span class="o">.</span><span class="n">Progress</span><span class="p">(</span>
                <span class="s2">&quot;</span><span class="si">{task.description}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">rich</span><span class="o">.</span><span class="n">progress</span><span class="o">.</span><span class="n">BarColumn</span><span class="p">(),</span>
                <span class="s2">&quot;[progress.percentage]</span><span class="si">{task.percentage:&gt;3.0f}</span><span class="s2">%&quot;</span><span class="p">,</span>
                <span class="s2">&quot;ETA:&quot;</span><span class="p">,</span>
                <span class="n">rich</span><span class="o">.</span><span class="n">progress</span><span class="o">.</span><span class="n">TimeRemainingColumn</span><span class="p">(),</span>
                <span class="n">RateColumn</span><span class="p">(),</span>
                <span class="n">auto_refresh</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">refresh_per_second</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">report_rate</span><span class="p">,</span>
                <span class="n">speed_estimate_period</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="p">)</span> <span class="k">as</span> <span class="n">progress</span><span class="p">:</span>
                <span class="n">task</span> <span class="o">=</span> <span class="n">progress</span><span class="o">.</span><span class="n">add_task</span><span class="p">(</span><span class="s2">&quot;Predicting...&quot;</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data_provider</span><span class="p">))</span>
                <span class="n">last_report</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">make_dataset</span><span class="p">():</span>
                    <span class="n">ex</span> <span class="o">=</span> <span class="n">process_batch</span><span class="p">(</span><span class="n">ex</span><span class="p">)</span>
                    <span class="n">progress</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">advance</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s2">&quot;frame_ind&quot;</span><span class="p">]))</span>

                    <span class="c1"># Handle refreshing manually to support notebooks.</span>
                    <span class="n">elapsed_since_last_report</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">last_report</span>
                    <span class="k">if</span> <span class="n">elapsed_since_last_report</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">report_period</span><span class="p">:</span>
                        <span class="n">progress</span><span class="o">.</span><span class="n">refresh</span><span class="p">()</span>

                    <span class="c1"># Return results.</span>
                    <span class="k">yield</span> <span class="n">ex</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbosity</span> <span class="o">==</span> <span class="s2">&quot;json&quot;</span><span class="p">:</span>
            <span class="n">n_processed</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">n_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_provider</span><span class="p">)</span>
            <span class="n">n_recent</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
            <span class="n">elapsed_recent</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
            <span class="n">last_report</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
            <span class="n">t0_all</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
            <span class="n">t0_batch</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">make_dataset</span><span class="p">():</span>
                <span class="c1"># Process batch of examples.</span>
                <span class="n">ex</span> <span class="o">=</span> <span class="n">process_batch</span><span class="p">(</span><span class="n">ex</span><span class="p">)</span>

                <span class="c1"># Track timing and progress.</span>
                <span class="n">elapsed_batch</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0_batch</span>
                <span class="n">t0_batch</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
                <span class="n">n_batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s2">&quot;frame_ind&quot;</span><span class="p">])</span>
                <span class="n">n_processed</span> <span class="o">+=</span> <span class="n">n_batch</span>
                <span class="n">elapsed_all</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0_all</span>

                <span class="c1"># Compute recent rate.</span>
                <span class="n">n_recent</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_batch</span><span class="p">)</span>
                <span class="n">elapsed_recent</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">elapsed_batch</span><span class="p">)</span>
                <span class="n">rate</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">n_recent</span><span class="p">)</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">elapsed_recent</span><span class="p">)</span>
                <span class="n">eta</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_total</span> <span class="o">-</span> <span class="n">n_processed</span><span class="p">)</span> <span class="o">/</span> <span class="n">rate</span>

                <span class="c1"># Report.</span>
                <span class="n">elapsed_since_last_report</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">last_report</span>
                <span class="k">if</span> <span class="n">elapsed_since_last_report</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">report_period</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
                            <span class="p">{</span>
                                <span class="s2">&quot;n_processed&quot;</span><span class="p">:</span> <span class="n">n_processed</span><span class="p">,</span>
                                <span class="s2">&quot;n_total&quot;</span><span class="p">:</span> <span class="n">n_total</span><span class="p">,</span>
                                <span class="s2">&quot;elapsed&quot;</span><span class="p">:</span> <span class="n">elapsed_all</span><span class="p">,</span>
                                <span class="s2">&quot;rate&quot;</span><span class="p">:</span> <span class="n">rate</span><span class="p">,</span>
                                <span class="s2">&quot;eta&quot;</span><span class="p">:</span> <span class="n">eta</span><span class="p">,</span>
                            <span class="p">}</span>
                        <span class="p">),</span>
                        <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">last_report</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

                <span class="c1"># Return results.</span>
                <span class="k">yield</span> <span class="n">ex</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">make_dataset</span><span class="p">():</span>
                <span class="k">yield</span> <span class="n">process_batch</span><span class="p">(</span><span class="n">ex</span><span class="p">)</span>

<div class="viewcode-block" id="Predictor.predict"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.Predictor.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Provider</span><span class="p">,</span> <span class="n">sleap</span><span class="o">.</span><span class="n">Labels</span><span class="p">,</span> <span class="n">sleap</span><span class="o">.</span><span class="n">Video</span><span class="p">],</span> <span class="n">make_labels</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]],</span> <span class="n">sleap</span><span class="o">.</span><span class="n">Labels</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Run inference on a data source.</span>

<span class="sd">        Args:</span>
<span class="sd">            data: A `sleap.pipelines.Provider`, `sleap.Labels` or `sleap.Video` to</span>
<span class="sd">                run inference over.</span>
<span class="sd">            make_labels: If `True` (the default), returns a `sleap.Labels` instance with</span>
<span class="sd">                `sleap.PredictedInstance`s. If `False`, just return a list of</span>
<span class="sd">                dictionaries containing the raw arrays returned by the inference model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sleap.Labels` with `sleap.PredictedInstance`s if `make_labels` is `True`,</span>
<span class="sd">            otherwise a list of dictionaries containing batches of numpy arrays with the</span>
<span class="sd">            raw results.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create provider if necessary.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">Video</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="n">sleap</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">video</span><span class="o">.</span><span class="n">NumpyVideo</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sleap</span><span class="o">.</span><span class="n">Labels</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">LabelsReader</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sleap</span><span class="o">.</span><span class="n">Video</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">VideoReader</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Initialize inference loop generator.</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_generator</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">make_labels</span><span class="p">:</span>
            <span class="c1"># Create SLEAP data structures while consuming results.</span>
            <span class="k">return</span> <span class="n">sleap</span><span class="o">.</span><span class="n">Labels</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_make_labeled_frames_from_generator</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Just return the raw results.</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span></div></div>


<span class="c1"># TODO: Rewrite this class.</span>
<div class="viewcode-block" id="VisualPredictor"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.VisualPredictor">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">VisualPredictor</span><span class="p">(</span><span class="n">Predictor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predictor class for generating the visual output of model.&quot;&quot;&quot;</span>

    <span class="n">config</span><span class="p">:</span> <span class="n">TrainingJobConfig</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span>
    <span class="n">pipeline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_trained_models</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="n">Text</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;VisualPredictor&quot;</span><span class="p">:</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">TrainingJobConfig</span><span class="o">.</span><span class="n">load_json</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        <span class="n">keras_model_path</span> <span class="o">=</span> <span class="n">get_keras_model_path</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">keras_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">keras_model_path</span><span class="p">,</span> <span class="nb">compile</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">head_specific_output_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Text</span><span class="p">]:</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">confidence_maps_key_name</span>
        <span class="k">if</span> <span class="n">key</span><span class="p">:</span>
            <span class="n">keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">part_affinity_fields_key_name</span>
        <span class="k">if</span> <span class="n">key</span><span class="p">:</span>
            <span class="n">keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">keys</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">confidence_maps_key_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]:</span>
        <span class="n">head_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">heads</span><span class="o">.</span><span class="n">which_oneof_attrib_name</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">head_key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;multi_instance&quot;</span><span class="p">,</span> <span class="s2">&quot;single_instance&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;predicted_confidence_maps&quot;</span>

        <span class="k">if</span> <span class="n">head_key</span> <span class="o">==</span> <span class="s2">&quot;centroid&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;predicted_centroid_confidence_maps&quot;</span>

        <span class="c1"># todo: centered_instance</span>

        <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">part_affinity_fields_key_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]:</span>
        <span class="n">head_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">heads</span><span class="o">.</span><span class="n">which_oneof_attrib_name</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">head_key</span> <span class="o">==</span> <span class="s2">&quot;multi_instance&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;predicted_part_affinity_fields&quot;</span>

        <span class="k">return</span> <span class="kc">None</span>

<div class="viewcode-block" id="VisualPredictor.make_pipeline"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.VisualPredictor.make_pipeline">[docs]</a>    <span class="k">def</span> <span class="nf">make_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span>

        <span class="n">pipeline</span> <span class="o">+=</span> <span class="n">Normalizer</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">)</span>
        <span class="n">pipeline</span> <span class="o">+=</span> <span class="n">Resizer</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">,</span> <span class="n">keep_full_image</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">points_key</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>

        <span class="n">pipeline</span> <span class="o">+=</span> <span class="n">KerasModelPredictor</span><span class="p">(</span>
            <span class="n">keras_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span>
            <span class="n">model_input_keys</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
            <span class="n">model_output_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">head_specific_output_keys</span><span class="p">(),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">pipeline</span></div>

<div class="viewcode-block" id="VisualPredictor.safely_generate"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.VisualPredictor.safely_generate">[docs]</a>    <span class="k">def</span> <span class="nf">safely_generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ds</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Yields examples from dataset, catching and logging exceptions.&quot;&quot;&quot;</span>
        <span class="c1"># Unsafe generating:</span>
        <span class="c1"># for example in ds:</span>
        <span class="c1">#     yield example</span>

        <span class="n">ds_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>

        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">wall_t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
        <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">next_val</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">ds_iter</span><span class="p">)</span>
                <span class="k">yield</span> <span class="n">next_val</span>
            <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
                <span class="n">done</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ERROR in sample index </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># Show the current progress (frames, time, fps)</span>
                <span class="k">if</span> <span class="n">progress</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="n">done</span><span class="p">:</span>
                        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">wall_t0</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Finished </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> examples in </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds &quot;</span>
                            <span class="s2">&quot;(inference + postprocessing)&quot;</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="n">elapsed_time</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;examples/s = </span><span class="si">{</span><span class="n">i</span><span class="o">/</span><span class="n">elapsed_time</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">predict_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_provider</span><span class="p">:</span> <span class="n">Provider</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Pass in data provider when mocking one of the models.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_pipeline</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">providers</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_provider</span><span class="p">]</span>

        <span class="c1"># Yield each example from dataset, catching and logging exceptions</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">safely_generate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">make_dataset</span><span class="p">())</span>

<div class="viewcode-block" id="VisualPredictor.predict"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.VisualPredictor.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_provider</span><span class="p">:</span> <span class="n">Provider</span><span class="p">):</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_generator</span><span class="p">(</span><span class="n">data_provider</span><span class="p">)</span>
        <span class="n">examples</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">examples</span></div></div>


<div class="viewcode-block" id="CentroidCropGroundTruth"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.CentroidCropGroundTruth">[docs]</a><span class="k">class</span> <span class="nc">CentroidCropGroundTruth</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Keras layer that simulates a centroid cropping model using ground truth.</span>

<span class="sd">    This layer is useful for testing and evaluating centered instance models.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        crop_size: The length of the square box to extract around each centroid.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">crop_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span> <span class="o">=</span> <span class="n">crop_size</span>

<div class="viewcode-block" id="CentroidCropGroundTruth.call"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.CentroidCropGroundTruth.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">example_gt</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return the ground truth instance crops.</span>

<span class="sd">        Args:</span>
<span class="sd">            example_gt: Dictionary generated from a labels pipeline with the keys:</span>
<span class="sd">                `&quot;image&quot;: (batch_size, height, width, channels)`</span>
<span class="sd">                `&quot;centroids&quot;: (batch_size, n_centroids, 2)`: The input centroids.</span>
<span class="sd">                    Axis 1 is expected to be ragged.</span>
<span class="sd">                These can be generated by the `InstanceCentroidFinder` transformer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary containing the output of the instance cropping layer with keys:</span>
<span class="sd">            `&quot;crops&quot;: (batch_size, n_centroids, crop_size, crop_size, channels)`</span>
<span class="sd">            `&quot;crop_offsets&quot;: (batch_size, n_centroids, crop_size, crop_size, channels)`</span>
<span class="sd">                These contain the top-left coordinates of each crop in the full images.</span>
<span class="sd">            `&quot;centroids&quot;: (batch_size, n_centroids, 2)`</span>
<span class="sd">            `&quot;centroid_vals&quot;: (batch_size, n_centroids)`</span>

<span class="sd">            Axis 1 of all keys are expected to be ragged.</span>

<span class="sd">            `&quot;centroids&quot;` are from the input example and `&quot;centroid_vals&quot;` will be</span>
<span class="sd">            filled with ones.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Pull out data from example.</span>
        <span class="n">full_imgs</span> <span class="o">=</span> <span class="n">example_gt</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
        <span class="n">crop_sample_inds</span> <span class="o">=</span> <span class="n">example_gt</span><span class="p">[</span><span class="s2">&quot;centroids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_rowids</span><span class="p">()</span>  <span class="c1"># (n_peaks,)</span>
        <span class="n">n_peaks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">crop_sample_inds</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># total number of peaks in the batch</span>
        <span class="n">centroid_points</span> <span class="o">=</span> <span class="n">example_gt</span><span class="p">[</span><span class="s2">&quot;centroids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">flat_values</span>  <span class="c1"># (n_peaks, 2)</span>
        <span class="n">centroid_vals</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">centroid_points</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># (n_peaks,)</span>

        <span class="c1"># Store crop offsets.</span>
        <span class="n">crop_offsets</span> <span class="o">=</span> <span class="n">centroid_points</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Crop instances around centroids.</span>
        <span class="n">bboxes</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">instance_cropping</span><span class="o">.</span><span class="n">make_centered_bboxes</span><span class="p">(</span>
            <span class="n">centroid_points</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span>
        <span class="p">)</span>
        <span class="n">crops</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">peak_finding</span><span class="o">.</span><span class="n">crop_bboxes</span><span class="p">(</span><span class="n">full_imgs</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">)</span>

        <span class="c1"># Reshape to (n_peaks, crop_height, crop_width, channels)</span>
        <span class="n">img_channels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">full_imgs</span><span class="p">)[</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">crops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">crops</span><span class="p">,</span> <span class="p">[</span><span class="n">n_peaks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">,</span> <span class="n">img_channels</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># Group crops by sample.</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">full_imgs</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">crops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">crops</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">samples</span>
        <span class="p">)</span>
        <span class="n">crop_offsets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">crop_offsets</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">samples</span>
        <span class="p">)</span>
        <span class="n">centroid_vals</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">centroid_vals</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">samples</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">crops</span><span class="o">=</span><span class="n">crops</span><span class="p">,</span>
            <span class="n">crop_offsets</span><span class="o">=</span><span class="n">crop_offsets</span><span class="p">,</span>
            <span class="n">centroids</span><span class="o">=</span><span class="n">example_gt</span><span class="p">[</span><span class="s2">&quot;centroids&quot;</span><span class="p">],</span>
            <span class="n">centroid_vals</span><span class="o">=</span><span class="n">centroid_vals</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="FindInstancePeaksGroundTruth"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.FindInstancePeaksGroundTruth">[docs]</a><span class="k">class</span> <span class="nc">FindInstancePeaksGroundTruth</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Keras layer that simulates a centered instance peaks model.</span>

<span class="sd">    This layer is useful for testing and evaluating centroid models.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="FindInstancePeaksGroundTruth.call"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.FindInstancePeaksGroundTruth.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">example_gt</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">crop_output</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return the ground truth instance peaks given a set of crops.</span>

<span class="sd">        Args:</span>
<span class="sd">            example_gt: Dictionary generated from a labels pipeline with the key:</span>
<span class="sd">                `&quot;instances&quot;: (batch_size, n_instances_gt, n_nodes, 2)`</span>
<span class="sd">                    Axes 1 and 2 are expected to be ragged dimensions.</span>
<span class="sd">            crop_output: Dictionary containing the output of the instance cropping layer</span>
<span class="sd">                with keys:</span>
<span class="sd">                `&quot;centroids&quot;: (batch_size, n_centroids, 2)`,</span>
<span class="sd">                `&quot;centroid_vals&quot;: (batch_size, n_centroids)`</span>
<span class="sd">                    Axis 1 of both keys are expected to be ragged.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary with the instance peaks for each frame. The peaks are just the</span>
<span class="sd">            ground truth instances matched to the crop output centroids via greedy</span>
<span class="sd">            matching of the closest node point to each centroid.</span>

<span class="sd">            The output will have keys:</span>
<span class="sd">                `&quot;centroids&quot;: (batch_size, n_centroids, 2)`: The input centroids.</span>
<span class="sd">                `&quot;centroid_vals&quot;: (batch_size, n_centroids)`: The input centroid</span>
<span class="sd">                    confidence values.</span>
<span class="sd">                `&quot;instance_peaks&quot;: (batch_size, n_centroids, n_nodes, 2)`: The matched</span>
<span class="sd">                    instances.</span>
<span class="sd">                `&quot;instance_peak_vals&quot;: (batch_size, n_centroids, n_nodes)`: Peak</span>
<span class="sd">                    confidence values (all 1.0).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Compute pairwise distances between centroids and all instance points within</span>
        <span class="c1"># each sample.</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">example_gt</span><span class="p">[</span><span class="s2">&quot;instances&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">with_row_splits_dtype</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>  <span class="c1"># (batch_size, 1, n_insts, n_nodes, 2)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">default_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">NaN</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">crop_output</span><span class="p">[</span><span class="s2">&quot;centroids&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span><span class="o">.</span><span class="n">with_row_splits_dtype</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">int64</span>
        <span class="p">)</span>  <span class="c1"># (batch_size, n_centroids, 1, 1, 2)</span>
        <span class="n">dists</span> <span class="o">=</span> <span class="n">a</span> <span class="o">-</span> <span class="n">b</span>  <span class="c1"># (batch_size, n_centroids, n_insts, n_nodes, 2)</span>
        <span class="n">dists</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">dists</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># reduce over xy</span>
        <span class="n">dists</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">dists</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># reduce over nodes</span>
        <span class="n">dists</span> <span class="o">=</span> <span class="n">dists</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">NaN</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># (batch_size, n_centroids, n_insts)</span>

        <span class="c1"># Find nearest GT instance to each centroid.</span>
        <span class="n">matches</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dists</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch_size, n_centroids)</span>

        <span class="c1"># Argmin will return indices for NaNs as well, so we must filter the matches.</span>
        <span class="n">subs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">is_nan</span><span class="p">(</span><span class="n">dists</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">valid_matches</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">matches</span><span class="p">,</span> <span class="n">subs</span><span class="p">)</span>
        <span class="n">match_sample_inds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">subs</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Get the matched instances.</span>
        <span class="n">instance_peaks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span>
            <span class="n">example_gt</span><span class="p">[</span><span class="s2">&quot;instances&quot;</span><span class="p">],</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">match_sample_inds</span><span class="p">,</span> <span class="n">valid_matches</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">instance_peaks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">instance_peaks</span><span class="p">,</span> <span class="n">match_sample_inds</span>
        <span class="p">)</span>  <span class="c1"># (batch_size, n_centroids, n_nodes, 2)</span>

        <span class="c1"># Set all peak values to 1.</span>
        <span class="n">instance_peak_vals</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">instance_peaks</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>  <span class="c1"># (batch_size, n_centroids, n_nodes)</span>

        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">centroids</span><span class="o">=</span><span class="n">crop_output</span><span class="p">[</span><span class="s2">&quot;centroids&quot;</span><span class="p">],</span>
            <span class="n">centroid_vals</span><span class="o">=</span><span class="n">crop_output</span><span class="p">[</span><span class="s2">&quot;centroid_vals&quot;</span><span class="p">],</span>
            <span class="n">instance_peaks</span><span class="o">=</span><span class="n">instance_peaks</span><span class="p">,</span>
            <span class="n">instance_peak_vals</span><span class="o">=</span><span class="n">instance_peak_vals</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="InferenceLayer"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.InferenceLayer">[docs]</a><span class="k">class</span> <span class="nc">InferenceLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base layer for wrapping a Keras model into a layer with preprocessing.</span>

<span class="sd">    This layer is useful for wrapping input preprocessing operations that would</span>
<span class="sd">    otherwise be handled by a separate pipeline.</span>

<span class="sd">    This layer expects the same input as the model (rank-4 image) and automatically</span>
<span class="sd">    converts the input to a float if it is in integer form. This can help improve</span>
<span class="sd">    performance by enabling inference directly on `uint8` inputs.</span>

<span class="sd">    The `call()` method can be overloaded to create custom inference routines that</span>
<span class="sd">    take advantage of the `preprocess()` method.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        keras_model: A `tf.keras.Model` that will be called on the input to this layer.</span>
<span class="sd">        input_scale: If not 1.0, input image will be resized by this factor.</span>
<span class="sd">        pad_to_stride: If not 1, input image will be paded to ensure that it is</span>
<span class="sd">            divisible by this value (after scaling).</span>
<span class="sd">        ensure_grayscale: If `True`, converts inputs to grayscale if not already. If</span>
<span class="sd">            `False`, converts inputs to RGB if not already. If `None` (default), infer</span>
<span class="sd">            from the shape of the input layer of the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">keras_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
        <span class="n">input_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">pad_to_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">ensure_grayscale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span> <span class="o">=</span> <span class="n">keras_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span> <span class="o">=</span> <span class="n">input_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_to_stride</span> <span class="o">=</span> <span class="n">pad_to_stride</span>
        <span class="k">if</span> <span class="n">ensure_grayscale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ensure_grayscale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ensure_grayscale</span> <span class="o">=</span> <span class="n">ensure_grayscale</span>

<div class="viewcode-block" id="InferenceLayer.preprocess"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.InferenceLayer.preprocess">[docs]</a>    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">imgs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Apply all preprocessing operations configured for this layer.</span>

<span class="sd">        Args:</span>
<span class="sd">            imgs: A batch of images as a tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The input tensor after applying preprocessing operations. The tensor will</span>
<span class="sd">            always be a `tf.float32`, which will be adjusted to the range `[0, 1]` if it</span>
<span class="sd">            was previously an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensure_grayscale</span><span class="p">:</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normalization</span><span class="o">.</span><span class="n">ensure_grayscale</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normalization</span><span class="o">.</span><span class="n">ensure_rgb</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>

        <span class="n">imgs</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normalization</span><span class="o">.</span><span class="n">ensure_float</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">resizing</span><span class="o">.</span><span class="n">resize_image</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_to_stride</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">resizing</span><span class="o">.</span><span class="n">pad_to_stride</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_to_stride</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">imgs</span></div>

<div class="viewcode-block" id="InferenceLayer.call"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.InferenceLayer.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Call the model with preprocessed data.</span>

<span class="sd">        Args:</span>
<span class="sd">            data: Inputs to the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Output of the model after being called with preprocessing.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">data</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="InferenceModel"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.InferenceModel">[docs]</a><span class="k">class</span> <span class="nc">InferenceModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;SLEAP inference model base class.</span>

<span class="sd">    This class wraps the `tf.keras.Model` class to provide SLEAP-specific inference</span>
<span class="sd">    utilities such as handling different input data types, preprocessing and variable</span>
<span class="sd">    output shapes.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="InferenceModel.predict"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.InferenceModel.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
            <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span>
            <span class="n">Pipeline</span><span class="p">,</span>
            <span class="n">sleap</span><span class="o">.</span><span class="n">Video</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">]]]:</span>
        <span class="sd">&quot;&quot;&quot;Predict instances in the data.</span>

<span class="sd">        Args:</span>
<span class="sd">            data: Input data in any form. Possible types:</span>
<span class="sd">                - `np.ndarray`, `tf.Tensor`: Images of shape</span>
<span class="sd">                    `(samples, height, width, channels)`</span>
<span class="sd">                - `dict` with key `&quot;image&quot;` as a tensor</span>
<span class="sd">                - `tf.data.Dataset` that generates examples in one of the above formats.</span>
<span class="sd">                - `sleap.Pipeline` that generates examples in one of the above formats.</span>
<span class="sd">                - `sleap.Video` which will be converted into a pipeline that generates</span>
<span class="sd">                    batches of `batch_size` frames.</span>
<span class="sd">            numpy: If `True` (default), returned values will be converted to</span>
<span class="sd">                `np.ndarray`s or Python primitives if scalars.</span>
<span class="sd">            batch_size: Batch size to use for inference. No effect if using a dataset or</span>
<span class="sd">                pipeline as input since those are expected to generate batches.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The model outputs as a dictionary of (potentially ragged) tensors or numpy</span>
<span class="sd">            arrays if `numpy` is `True`.</span>

<span class="sd">            If `numpy` is `False`, values of the dictionary may be `tf.RaggedTensor`s</span>
<span class="sd">            with the same length for axis 0 (samples), but variable length axis 1</span>
<span class="sd">            (instances).</span>

<span class="sd">            If `numpy` is `True` and the output contained ragged tensors, they will be</span>
<span class="sd">            NaN-padded to the bounding shape and an additional key `&quot;n_valid&quot;` will be</span>
<span class="sd">            included to indicate the number of valid elements (before padding) in axis</span>
<span class="sd">            1 of the tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">sleap</span><span class="o">.</span><span class="n">Video</span><span class="p">,</span> <span class="n">sleap</span><span class="o">.</span><span class="n">Labels</span><span class="p">)):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to_pipeline</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">make_dataset</span><span class="p">()</span>

        <span class="n">outs</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">numpy</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outs</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">):</span>
                    <span class="n">outs</span><span class="p">[</span><span class="s2">&quot;n_valid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">row_lengths</span><span class="p">()</span>
                    <span class="k">break</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unrag_example</span><span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="n">numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outs</span></div></div>


<div class="viewcode-block" id="get_model_output_stride"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.get_model_output_stride">[docs]</a><span class="k">def</span> <span class="nf">get_model_output_stride</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">input_ind</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">output_ind</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Return the stride (1/scale) of the model outputs relative to the input.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: A `tf.keras.Model`.</span>
<span class="sd">        input_ind: The index of the input to use as reference. Defaults to 0, indicating</span>
<span class="sd">            the first input for multi-output models.</span>
<span class="sd">        output_ind: The index of the output to compute the stride for. Defaults to -1,</span>
<span class="sd">            indicating the last output for multi-output models.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The output stride of the model computed as the integer ratio of the input&#39;s</span>
<span class="sd">        height relative to the output&#39;s height, e.g., for a single input/output model:</span>

<span class="sd">            `model.input.shape[1] // model.output.shape[1]`</span>

<span class="sd">        Raises a warning if the shapes do not divide evenly.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">size_in</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">input_ind</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">size_out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">output_ind</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">size_in</span> <span class="o">%</span> <span class="n">size_out</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Model input of shape </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">input_ind</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> does not divide &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;evenly with output of shape </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">output_ind</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">size_in</span> <span class="o">//</span> <span class="n">size_out</span></div>


<div class="viewcode-block" id="find_head"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.find_head">[docs]</a><span class="k">def</span> <span class="nf">find_head</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Return the index of a head in a model&#39;s outputs.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: A `tf.keras.Model` trained by SLEAP.</span>
<span class="sd">        name: A string that is contained in the model output tensor name.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The index of the first output with a matched name or `None` if none were found.</span>

<span class="sd">    Notes:</span>
<span class="sd">        SLEAP model heads are named:</span>
<span class="sd">        - `&quot;SingleInstanceConfmapsHead&quot;`</span>
<span class="sd">        - `&quot;CentroidConfmapsHead&quot;`</span>
<span class="sd">        - `&quot;CenteredInstanceConfmapsHead&quot;`</span>
<span class="sd">        - `&quot;MultiInstanceConfmapsHead&quot;`</span>
<span class="sd">        - `&quot;PartAffinityFieldsHead&quot;`</span>
<span class="sd">        - `&quot;OffsetRefinementHead&quot;`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">head_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">output_names</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">head_name</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">i</span>
    <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="SingleInstanceInferenceLayer"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.SingleInstanceInferenceLayer">[docs]</a><span class="k">class</span> <span class="nc">SingleInstanceInferenceLayer</span><span class="p">(</span><span class="n">InferenceLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Inference layer for applying single instance models.</span>

<span class="sd">    This layer encapsulates all of the inference operations requires for generating</span>
<span class="sd">    predictions from a single instance confidence map model. This includes</span>
<span class="sd">    preprocessing, model forward pass, peak finding and coordinate adjustment.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        keras_model: A `tf.keras.Model` that accepts rank-4 images as input and predicts</span>
<span class="sd">            rank-4 confidence maps as output. This should be a model that is trained on</span>
<span class="sd">            single instance confidence maps.</span>
<span class="sd">        input_scale: Float indicating if the images should be resized before being</span>
<span class="sd">            passed to the model.</span>
<span class="sd">        pad_to_stride: If not 1, input image will be paded to ensure that it is</span>
<span class="sd">            divisible by this value (after scaling). This should be set to the max</span>
<span class="sd">            stride of the model.</span>
<span class="sd">        output_stride: Output stride of the model, denoting the scale of the output</span>
<span class="sd">            confidence maps relative to the images (after input scaling). This is used</span>
<span class="sd">            for adjusting the peak coordinates to the image grid. This will be inferred</span>
<span class="sd">            from the model shapes if not provided.</span>
<span class="sd">        peak_threshold: Minimum confidence map value to consider a global peak as valid.</span>
<span class="sd">        refinement: If `None`, returns the grid-aligned peaks with no refinement. If</span>
<span class="sd">            `&quot;integral&quot;`, peaks will be refined with integral regression. If `&quot;local&quot;`,</span>
<span class="sd">            peaks will be refined with quarter pixel local gradient offset. This has no</span>
<span class="sd">            effect if the model has an offset regression head.</span>
<span class="sd">        integral_patch_size: Size of patches to crop around each rough peak for integral</span>
<span class="sd">            refinement as an integer scalar.</span>
<span class="sd">        return_confmaps: If `True`, the confidence maps will be returned together with</span>
<span class="sd">            the predicted peaks. This will result in slower inference times since the</span>
<span class="sd">            data must be copied off of the GPU, but is useful for visualizing the raw</span>
<span class="sd">            output of the model.</span>
<span class="sd">        confmaps_ind: Index of the output tensor of the model corresponding to</span>
<span class="sd">            confidence maps. If `None` (the default), this will be detected</span>
<span class="sd">            automatically by searching for the first tensor that contains</span>
<span class="sd">            `&quot;SingleInstanceConfmapsHead&quot;` in its name.</span>
<span class="sd">        offsets_ind: Index of the output tensor of the model corresponding to</span>
<span class="sd">            offset regression maps. If `None` (the default), this will be detected</span>
<span class="sd">            automatically by searching for the first tensor that contains</span>
<span class="sd">            `&quot;OffsetRefinementHead&quot;` in its name. If the head is not present, the method</span>
<span class="sd">            specified in the `refinement` attribute will be used.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">keras_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
        <span class="n">input_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">pad_to_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">output_stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">refinement</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span>
        <span class="n">integral_patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">return_confmaps</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">confmaps_ind</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">offsets_ind</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">keras_model</span><span class="o">=</span><span class="n">keras_model</span><span class="p">,</span>
            <span class="n">input_scale</span><span class="o">=</span><span class="n">input_scale</span><span class="p">,</span>
            <span class="n">pad_to_stride</span><span class="o">=</span><span class="n">pad_to_stride</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="o">=</span> <span class="n">confmaps_ind</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="o">=</span> <span class="n">offsets_ind</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span> <span class="o">=</span> <span class="n">peak_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refinement</span> <span class="o">=</span> <span class="n">refinement</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_stride</span> <span class="o">=</span> <span class="n">output_stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span> <span class="o">=</span> <span class="n">integral_patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_confmaps</span> <span class="o">=</span> <span class="n">return_confmaps</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="o">=</span> <span class="n">find_head</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="s2">&quot;SingleInstanceConfmapsHead&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Index of the confidence maps output tensor must be specified if not &quot;</span>
                <span class="s2">&quot;named &#39;SingleInstanceConfmapsHead&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="o">=</span> <span class="n">find_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="s2">&quot;OffsetRefinementHead&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_stride</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Attempt to automatically infer the output stride.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_stride</span> <span class="o">=</span> <span class="n">get_model_output_stride</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="n">output_ind</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span>
            <span class="p">)</span>

<div class="viewcode-block" id="SingleInstanceInferenceLayer.call"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.SingleInstanceInferenceLayer.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict instance confidence maps and find peaks.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: Full frame images as a `tf.Tensor` of shape</span>
<span class="sd">                `(samples, height, width, channels)` or a dictionary with key:</span>
<span class="sd">                `&quot;image&quot;`: Full frame images in the same format as above.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary of outputs grouped by sample with keys:</span>

<span class="sd">            `&quot;peaks&quot;`: The predicted peaks of shape `(samples, nodes, 2)`.</span>
<span class="sd">            `&quot;peak_vals&quot;: The peak confidence values of shape `(samples, nodes)`.</span>

<span class="sd">            If the `return_confmaps` attribute is set to `True`, the output will also</span>
<span class="sd">            contain a key named `&quot;confmaps&quot;` containing a `tf.Tensor` of shape</span>
<span class="sd">            `(samples, output_height, output_width, 1)` containing the confidence maps</span>
<span class="sd">            predicted by the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
        <span class="n">offsets</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">cms</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">offsets</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cms</span> <span class="o">=</span> <span class="n">preds</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">peaks</span><span class="p">,</span> <span class="n">peak_vals</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">peak_finding</span><span class="o">.</span><span class="n">find_global_peaks</span><span class="p">(</span>
                <span class="n">cms</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span><span class="p">,</span>
                <span class="n">refinement</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">refinement</span><span class="p">,</span>
                <span class="n">integral_patch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">peaks</span><span class="p">,</span> <span class="n">peak_vals</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">peak_finding</span><span class="o">.</span><span class="n">find_global_peaks_with_offsets</span><span class="p">(</span>
                <span class="n">cms</span><span class="p">,</span>
                <span class="n">offsets</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Adjust for stride and scale.</span>
        <span class="n">peaks</span> <span class="o">=</span> <span class="n">peaks</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_stride</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="c1"># Note: We add 0.5 here to offset TensorFlow&#39;s weird image resizing. This</span>
            <span class="c1"># may not always(?) be the most correct approach.</span>
            <span class="c1"># See: https://github.com/tensorflow/tensorflow/issues/6720</span>
            <span class="n">peaks</span> <span class="o">=</span> <span class="p">(</span><span class="n">peaks</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span>

        <span class="n">out</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;peaks&quot;</span><span class="p">:</span> <span class="n">peaks</span><span class="p">,</span> <span class="s2">&quot;peak_vals&quot;</span><span class="p">:</span> <span class="n">peak_vals</span><span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_confmaps</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s2">&quot;confmaps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cms</span>
        <span class="k">return</span> <span class="n">out</span></div></div>


<div class="viewcode-block" id="SingleInstanceInferenceModel"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.SingleInstanceInferenceModel">[docs]</a><span class="k">class</span> <span class="nc">SingleInstanceInferenceModel</span><span class="p">(</span><span class="n">InferenceModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Single instance prediction model.</span>

<span class="sd">    This model encapsulates the basic single instance approach where it is assumed that</span>
<span class="sd">    there is only one instance in the frame. The images are passed to a peak detector</span>
<span class="sd">    which is trained to detect all body parts for the instance assuming a single peak</span>
<span class="sd">    per body part.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        single_instance_layer: A single instance instance peak detection layer. This</span>
<span class="sd">            layer takes as input full images and outputs the detected peaks.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">single_instance_layer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">single_instance_layer</span> <span class="o">=</span> <span class="n">single_instance_layer</span>

<div class="viewcode-block" id="SingleInstanceInferenceModel.call"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.SingleInstanceInferenceModel.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">example</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict instances for one batch of images.</span>

<span class="sd">        Args:</span>
<span class="sd">            example: This may be either a single batch of images as a 4-D tensor of</span>
<span class="sd">                shape `(batch_size, height, width, channels)`, or a dictionary</span>
<span class="sd">                containing the image batch in the `&quot;images&quot;` key.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The predicted instances as a dictionary of tensors with keys:</span>

<span class="sd">            `&quot;peaks&quot;: (batch_size, n_nodes, 2)`: Instance skeleton points.</span>
<span class="sd">            `&quot;peak_vals&quot;: (batch_size, n_instances, n_nodes)`: Confidence values for the</span>
<span class="sd">                instance skeleton points.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">single_instance_layer</span><span class="p">(</span><span class="n">example</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="SingleInstancePredictor"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.SingleInstancePredictor">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">SingleInstancePredictor</span><span class="p">(</span><span class="n">Predictor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Single instance predictor.</span>

<span class="sd">    This high-level class handles initialization, preprocessing and tracking using a</span>
<span class="sd">    trained single instance SLEAP model.</span>

<span class="sd">    This should be initialized using the `from_trained_models()` constructor or the</span>
<span class="sd">    high-level API (`sleap.load_model`).</span>

<span class="sd">    Attributes:</span>
<span class="sd">        confmap_config: The `sleap.nn.config.TrainingJobConfig` containing the metadata</span>
<span class="sd">            for the trained model.</span>
<span class="sd">        confmap_model: A `sleap.nn.model.Model` instance created from the trained model.</span>
<span class="sd">        inference_model: A `sleap.nn.inference.SingleInstanceInferenceModel` that wraps</span>
<span class="sd">            a trained `tf.keras.Model` to implement preprocessing and peak finding.</span>
<span class="sd">        pipeline: A `sleap.nn.data.Pipeline` that loads the data and batches input data.</span>
<span class="sd">            This will be updated dynamically if new data sources are used.</span>
<span class="sd">        peak_threshold: Minimum confidence map value to consider a global peak as valid.</span>
<span class="sd">        integral_refinement: If `True`, peaks will be refined with integral regression.</span>
<span class="sd">            If `False`, `&quot;local&quot;`, peaks will be refined with quarter pixel local</span>
<span class="sd">            gradient offset. This has no effect if the model has an offset regression</span>
<span class="sd">            head.</span>
<span class="sd">        integral_patch_size: Size of patches to crop around each rough peak for integral</span>
<span class="sd">            refinement as an integer scalar.</span>
<span class="sd">        batch_size: The default batch size to use when loading data for inference.</span>
<span class="sd">            Higher values increase inference speed at the cost of higher memory usage.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">confmap_config</span><span class="p">:</span> <span class="n">TrainingJobConfig</span>
    <span class="n">confmap_model</span><span class="p">:</span> <span class="n">Model</span>
    <span class="n">inference_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SingleInstanceInferenceModel</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">pipeline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span>
    <span class="n">integral_refinement</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">integral_patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="k">def</span> <span class="nf">_initialize_inference_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the inference model from the trained model and configuration.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_model</span> <span class="o">=</span> <span class="n">SingleInstanceInferenceModel</span><span class="p">(</span>
            <span class="n">SingleInstanceInferenceLayer</span><span class="p">(</span>
                <span class="n">keras_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">confmap_model</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span>
                <span class="n">input_scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">confmap_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">input_scaling</span><span class="p">,</span>
                <span class="n">pad_to_stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">confmap_model</span><span class="o">.</span><span class="n">maximum_stride</span><span class="p">,</span>
                <span class="n">refinement</span><span class="o">=</span><span class="s2">&quot;integral&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">integral_refinement</span> <span class="k">else</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span>
                <span class="n">integral_patch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

<div class="viewcode-block" id="SingleInstancePredictor.from_trained_models"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.SingleInstancePredictor.from_trained_models">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_trained_models</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">model_path</span><span class="p">:</span> <span class="n">Text</span><span class="p">,</span>
        <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">integral_refinement</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">integral_patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SingleInstancePredictor&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create the predictor from a saved model.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_path: Path to a model folder or training job JSON file inside a model</span>
<span class="sd">                folder. This folder should contain `training_config.json` and</span>
<span class="sd">                `best_model.h5` files for a trained model.</span>
<span class="sd">            peak_threshold: Minimum confidence map value to consider a global peak as</span>
<span class="sd">                valid.</span>
<span class="sd">            integral_refinement: If `True`, peaks will be refined with integral</span>
<span class="sd">                regression. If `False`, `&quot;local&quot;`, peaks will be refined with quarter</span>
<span class="sd">                pixel local gradient offset. This has no effect if the model has an</span>
<span class="sd">                offset regression head.</span>
<span class="sd">            integral_patch_size: Size of patches to crop around each rough peak for</span>
<span class="sd">                integral refinement as an integer scalar.</span>
<span class="sd">            batch_size: The default batch size to use when loading data for inference.</span>
<span class="sd">                Higher values increase inference speed at the cost of higher memory</span>
<span class="sd">                usage.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An instance of`SingleInstancePredictor` with the models loaded.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Load confmap model.</span>
        <span class="n">confmap_config</span> <span class="o">=</span> <span class="n">TrainingJobConfig</span><span class="o">.</span><span class="n">load_json</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        <span class="n">confmap_keras_model_path</span> <span class="o">=</span> <span class="n">get_keras_model_path</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        <span class="n">confmap_model</span> <span class="o">=</span> <span class="n">Model</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">confmap_config</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">confmap_model</span><span class="o">.</span><span class="n">keras_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span>
            <span class="n">confmap_keras_model_path</span><span class="p">,</span> <span class="nb">compile</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">confmap_config</span><span class="o">=</span><span class="n">confmap_config</span><span class="p">,</span>
            <span class="n">confmap_model</span><span class="o">=</span><span class="n">confmap_model</span><span class="p">,</span>
            <span class="n">peak_threshold</span><span class="o">=</span><span class="n">peak_threshold</span><span class="p">,</span>
            <span class="n">integral_refinement</span><span class="o">=</span><span class="n">integral_refinement</span><span class="p">,</span>
            <span class="n">integral_patch_size</span><span class="o">=</span><span class="n">integral_patch_size</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">obj</span><span class="o">.</span><span class="n">_initialize_inference_model</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">obj</span></div>

    <span class="k">def</span> <span class="nf">_make_labeled_frames_from_generator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]],</span> <span class="n">data_provider</span><span class="p">:</span> <span class="n">Provider</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">sleap</span><span class="o">.</span><span class="n">LabeledFrame</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Create labeled frames from a generator that yields inference results.</span>

<span class="sd">        This method converts pure arrays into SLEAP-specific data structures.</span>

<span class="sd">        Args:</span>
<span class="sd">            generator: A generator that returns dictionaries with inference results.</span>
<span class="sd">                This should return dictionaries with keys `&quot;video_ind&quot;`, `&quot;frame_ind&quot;`,</span>
<span class="sd">                `&quot;peaks&quot;`, and `&quot;peak_vals&quot;`. This can be created using the</span>
<span class="sd">                `_predict_generator()` method.</span>
<span class="sd">            data_provider: The `sleap.pipelines.Provider` that the predictions are being</span>
<span class="sd">                created from. This is used to retrieve the `sleap.Video` instance</span>
<span class="sd">                associated with each inference result.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of `sleap.LabeledFrame`s with `sleap.PredictedInstance`s created from</span>
<span class="sd">            arrays returned from the inference result generator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">skeleton</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmap_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">skeletons</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Loop over batches.</span>
        <span class="n">predicted_frames</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>

            <span class="c1"># Loop over frames.</span>
            <span class="k">for</span> <span class="n">video_ind</span><span class="p">,</span> <span class="n">frame_ind</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">confidences</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;video_ind&quot;</span><span class="p">],</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;frame_ind&quot;</span><span class="p">],</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;peaks&quot;</span><span class="p">],</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;peak_vals&quot;</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="c1"># Loop over instances.</span>
                <span class="n">predicted_instances</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">sleap</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">PredictedInstance</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span>
                        <span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">,</span>
                        <span class="n">point_confidences</span><span class="o">=</span><span class="n">confidences</span><span class="p">,</span>
                        <span class="n">instance_score</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nansum</span><span class="p">(</span><span class="n">confidences</span><span class="p">),</span>
                        <span class="n">skeleton</span><span class="o">=</span><span class="n">skeleton</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">]</span>

                <span class="n">predicted_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">sleap</span><span class="o">.</span><span class="n">LabeledFrame</span><span class="p">(</span>
                        <span class="n">video</span><span class="o">=</span><span class="n">data_provider</span><span class="o">.</span><span class="n">videos</span><span class="p">[</span><span class="n">video_ind</span><span class="p">],</span>
                        <span class="n">frame_idx</span><span class="o">=</span><span class="n">frame_ind</span><span class="p">,</span>
                        <span class="n">instances</span><span class="o">=</span><span class="n">predicted_instances</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">predicted_frames</span></div>


<div class="viewcode-block" id="CentroidCrop"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.CentroidCrop">[docs]</a><span class="k">class</span> <span class="nc">CentroidCrop</span><span class="p">(</span><span class="n">InferenceLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Inference layer for applying centroid crop-based models.</span>

<span class="sd">    This layer encapsulates all of the inference operations requires for generating</span>
<span class="sd">    predictions from a centroid confidence map model. This includes preprocessing,</span>
<span class="sd">    model forward pass, peak finding, coordinate adjustment and cropping.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        keras_model: A `tf.keras.Model` that accepts rank-4 images as input and predicts</span>
<span class="sd">            rank-4 confidence maps as output. This should be a model that is trained on</span>
<span class="sd">            centroid/anchor confidence maps.</span>
<span class="sd">        crop_size: Integer scalar specifying the height/width of the centered crops.</span>
<span class="sd">        input_scale: Float indicating if the images should be resized before being</span>
<span class="sd">            passed to the model.</span>
<span class="sd">        pad_to_stride: If not 1, input image will be paded to ensure that it is</span>
<span class="sd">            divisible by this value (after scaling). This should be set to the max</span>
<span class="sd">            stride of the model.</span>
<span class="sd">        output_stride: Output stride of the model, denoting the scale of the output</span>
<span class="sd">            confidence maps relative to the images (after input scaling). This is used</span>
<span class="sd">            for adjusting the peak coordinates to the image grid. This will be inferred</span>
<span class="sd">            from the model shapes if not provided.</span>
<span class="sd">        peak_threshold: Minimum confidence map value to consider a global peak as valid.</span>
<span class="sd">        refinement: If `None`, returns the grid-aligned peaks with no refinement. If</span>
<span class="sd">            `&quot;integral&quot;`, peaks will be refined with integral regression. If `&quot;local&quot;`,</span>
<span class="sd">            peaks will be refined with quarter pixel local gradient offset. This has no</span>
<span class="sd">            effect if the model has an offset regression head.</span>
<span class="sd">        integral_patch_size: Size of patches to crop around each rough peak for integral</span>
<span class="sd">            refinement as an integer scalar.</span>
<span class="sd">        return_confmaps: If `True`, the confidence maps will be returned together with</span>
<span class="sd">            the predicted peaks. This will result in slower inference times since the</span>
<span class="sd">            data must be copied off of the GPU, but is useful for visualizing the raw</span>
<span class="sd">            output of the model.</span>
<span class="sd">        confmaps_ind: Index of the output tensor of the model corresponding to</span>
<span class="sd">            confidence maps. If `None` (the default), this will be detected</span>
<span class="sd">            automatically by searching for the first tensor that contains</span>
<span class="sd">            `&quot;CentroidConfmapsHead&quot;` in its name.</span>
<span class="sd">        offsets_ind: Index of the output tensor of the model corresponding to</span>
<span class="sd">            offset regression maps. If `None` (the default), this will be detected</span>
<span class="sd">            automatically by searching for the first tensor that contains</span>
<span class="sd">            `&quot;OffsetRefinementHead&quot;` in its name. If the head is not present, the method</span>
<span class="sd">            specified in the `refinement` attribute will be used.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">keras_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
        <span class="n">crop_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">input_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">pad_to_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">output_stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">refinement</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span>
        <span class="n">integral_patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">return_confmaps</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">confmaps_ind</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">offsets_ind</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">keras_model</span><span class="o">=</span><span class="n">keras_model</span><span class="p">,</span>
            <span class="n">input_scale</span><span class="o">=</span><span class="n">input_scale</span><span class="p">,</span>
            <span class="n">pad_to_stride</span><span class="o">=</span><span class="n">pad_to_stride</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span> <span class="o">=</span> <span class="n">crop_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="o">=</span> <span class="n">confmaps_ind</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="o">=</span> <span class="n">offsets_ind</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="o">=</span> <span class="n">find_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="s2">&quot;CentroidConfmapsHead&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Index of the confidence maps output tensor must be specified if not &quot;</span>
                <span class="s2">&quot;named &#39;CentroidConfmapsHead&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="o">=</span> <span class="n">find_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="s2">&quot;OffsetRefinementHead&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">output_stride</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Attempt to automatically infer the output stride.</span>
            <span class="n">output_stride</span> <span class="o">=</span> <span class="n">get_model_output_stride</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_stride</span> <span class="o">=</span> <span class="n">output_stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span> <span class="o">=</span> <span class="n">peak_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refinement</span> <span class="o">=</span> <span class="n">refinement</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span> <span class="o">=</span> <span class="n">integral_patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_confmaps</span> <span class="o">=</span> <span class="n">return_confmaps</span>

<div class="viewcode-block" id="CentroidCrop.call"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.CentroidCrop.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict centroid confidence maps and crop around peaks.</span>

<span class="sd">        This layer can be chained with a `FindInstancePeaks` layer to create a top-down</span>
<span class="sd">        inference function from full images.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: Full frame images as a `tf.Tensor` of shape</span>
<span class="sd">                `(samples, height, width, channels)` or a dictionary with key:</span>
<span class="sd">                `&quot;image&quot;`: Full frame images in the same format as above.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary of outputs grouped by sample with keys:</span>

<span class="sd">            `&quot;crops&quot;`: Cropped images of shape</span>
<span class="sd">                `(samples, ?, crop_size, crop_size, channels)`.</span>
<span class="sd">            `&quot;crop_offsets&quot;`: Coordinates of the top-left of the crops as `(x, y)`</span>
<span class="sd">                offsets of shape `(samples, ?, 2)` for adjusting the predicted peak</span>
<span class="sd">                coordinates.</span>
<span class="sd">            `&quot;centroids&quot;`: The predicted centroids of shape `(samples, ?, 2)`.</span>
<span class="sd">            `&quot;centroid_vals&quot;: The centroid confidence values of shape `(samples, ?)`.</span>

<span class="sd">            If the `return_confmaps` attribute is set to `True`, the output will also</span>
<span class="sd">            contain a key named `&quot;centroid_confmaps&quot;` containing a `tf.RaggedTensor` of</span>
<span class="sd">            shape `(samples, ?, output_height, output_width, 1)` containing the</span>
<span class="sd">            confidence maps predicted by the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="c1"># Pull out image from example dictionary.</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Assume inputs are image tensors.</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="c1"># Store full images for cropping.</span>
        <span class="n">full_imgs</span> <span class="o">=</span> <span class="n">imgs</span>

        <span class="c1"># Preprocess inputs (scaling, padding, colorspace, int to float).</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>

        <span class="c1"># Predict confidence maps.</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
        <span class="n">offsets</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">cms</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">offsets</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cms</span> <span class="o">=</span> <span class="n">out</span>

        <span class="c1"># Find centroids peaks.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Use deterministic refinement.</span>
            <span class="p">(</span>
                <span class="n">centroid_points</span><span class="p">,</span>
                <span class="n">centroid_vals</span><span class="p">,</span>
                <span class="n">crop_sample_inds</span><span class="p">,</span>
                <span class="n">_</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">peak_finding</span><span class="o">.</span><span class="n">find_local_peaks</span><span class="p">(</span>
                <span class="n">cms</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span><span class="p">,</span>
                <span class="n">refinement</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">refinement</span><span class="p">,</span>
                <span class="n">integral_patch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Use learned offsets.</span>
            <span class="p">(</span>
                <span class="n">centroid_points</span><span class="p">,</span>
                <span class="n">centroid_vals</span><span class="p">,</span>
                <span class="n">crop_sample_inds</span><span class="p">,</span>
                <span class="n">_</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">peak_finding</span><span class="o">.</span><span class="n">find_local_peaks_with_offsets</span><span class="p">(</span>
                <span class="n">cms</span><span class="p">,</span>
                <span class="n">offsets</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Adjust for stride and scale.</span>
        <span class="n">centroid_points</span> <span class="o">=</span> <span class="n">centroid_points</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_stride</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="c1"># Note: We add 0.5 here to offset TensorFlow&#39;s weird image resizing. This</span>
            <span class="c1"># may not always(?) be the most correct approach.</span>
            <span class="c1"># See: https://github.com/tensorflow/tensorflow/issues/6720</span>
            <span class="n">centroid_points</span> <span class="o">=</span> <span class="p">(</span><span class="n">centroid_points</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span>

        <span class="c1"># Store crop offsets.</span>
        <span class="n">crop_offsets</span> <span class="o">=</span> <span class="n">centroid_points</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">n_peaks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">centroid_points</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">n_peaks</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Crop instances around centroids.</span>
            <span class="n">bboxes</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">instance_cropping</span><span class="o">.</span><span class="n">make_centered_bboxes</span><span class="p">(</span>
                <span class="n">centroid_points</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span>
            <span class="p">)</span>
            <span class="n">crops</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">peak_finding</span><span class="o">.</span><span class="n">crop_bboxes</span><span class="p">(</span>
                <span class="n">full_imgs</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">crop_sample_inds</span>
            <span class="p">)</span>

            <span class="c1"># Reshape to (n_peaks, crop_height, crop_width, channels)</span>
            <span class="n">crops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="n">crops</span><span class="p">,</span> <span class="p">[</span><span class="n">n_peaks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">,</span> <span class="n">full_imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># No peaks found, so just create a placeholder stack.</span>
            <span class="n">crops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">[</span><span class="n">n_peaks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">,</span> <span class="n">full_imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]],</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">full_imgs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Group crops by sample (samples, ?, ...).</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">imgs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">centroids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">centroid_points</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">samples</span>
        <span class="p">)</span>
        <span class="n">crops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">crops</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">samples</span>
        <span class="p">)</span>
        <span class="n">crop_offsets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">crop_offsets</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">samples</span>
        <span class="p">)</span>
        <span class="n">centroid_vals</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">centroid_vals</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">samples</span>
        <span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">centroids</span><span class="o">=</span><span class="n">centroids</span><span class="p">,</span>
            <span class="n">centroid_vals</span><span class="o">=</span><span class="n">centroid_vals</span><span class="p">,</span>
            <span class="n">crops</span><span class="o">=</span><span class="n">crops</span><span class="p">,</span>
            <span class="n">crop_offsets</span><span class="o">=</span><span class="n">crop_offsets</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_confmaps</span><span class="p">:</span>
            <span class="c1"># Return confidence maps with outputs.</span>
            <span class="n">cms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
                <span class="n">cms</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">samples</span>
            <span class="p">)</span>
            <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;centroid_confmaps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cms</span>
        <span class="k">return</span> <span class="n">outputs</span></div></div>


<div class="viewcode-block" id="FindInstancePeaks"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.FindInstancePeaks">[docs]</a><span class="k">class</span> <span class="nc">FindInstancePeaks</span><span class="p">(</span><span class="n">InferenceLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Keras layer that predicts instance peaks from images using a trained model.</span>

<span class="sd">    This layer encapsulates all of the inference operations required for generating</span>
<span class="sd">    predictions from a centered instance confidence map model. This includes</span>
<span class="sd">    preprocessing, model forward pass, peak finding and coordinate adjustment.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        keras_model: A `tf.keras.Model` that accepts rank-4 images as input and predicts</span>
<span class="sd">            rank-4 confidence maps as output. This should be a model that is trained on</span>
<span class="sd">            centered instance confidence maps.</span>
<span class="sd">        input_scale: Float indicating if the images should be resized before being</span>
<span class="sd">            passed to the model.</span>
<span class="sd">        output_stride: Output stride of the model, denoting the scale of the output</span>
<span class="sd">            confidence maps relative to the images (after input scaling). This is used</span>
<span class="sd">            for adjusting the peak coordinates to the image grid. This will be inferred</span>
<span class="sd">            from the model shapes if not provided.</span>
<span class="sd">        peak_threshold: Minimum confidence map value to consider a global peak as valid.</span>
<span class="sd">        refinement: If `None`, returns the grid-aligned peaks with no refinement. If</span>
<span class="sd">            `&quot;integral&quot;`, peaks will be refined with integral regression. If `&quot;local&quot;`,</span>
<span class="sd">            peaks will be refined with quarter pixel local gradient offset. This has no</span>
<span class="sd">            effect if the model has an offset regression head.</span>
<span class="sd">        integral_patch_size: Size of patches to crop around each rough peak for integral</span>
<span class="sd">            refinement as an integer scalar.</span>
<span class="sd">        return_confmaps: If `True`, the confidence maps will be returned together with</span>
<span class="sd">            the predicted peaks. This will result in slower inference times since the</span>
<span class="sd">            data must be copied off of the GPU, but is useful for visualizing the raw</span>
<span class="sd">            output of the model.</span>
<span class="sd">        confmaps_ind: Index of the output tensor of the model corresponding to</span>
<span class="sd">            confidence maps. If `None` (the default), this will be detected</span>
<span class="sd">            automatically by searching for the first tensor that contains</span>
<span class="sd">            `&quot;CenteredInstanceConfmapsHead&quot;` in its name.</span>
<span class="sd">        offsets_ind: Index of the output tensor of the model corresponding to</span>
<span class="sd">            offset regression maps. If `None` (the default), this will be detected</span>
<span class="sd">            automatically by searching for the first tensor that contains</span>
<span class="sd">            `&quot;OffsetRefinementHead&quot;` in its name. If the head is not present, the method</span>
<span class="sd">            specified in the `refinement` attribute will be used.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">keras_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
        <span class="n">input_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">output_stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">refinement</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span>
        <span class="n">integral_patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">return_confmaps</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">confmaps_ind</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">offsets_ind</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">keras_model</span><span class="o">=</span><span class="n">keras_model</span><span class="p">,</span> <span class="n">input_scale</span><span class="o">=</span><span class="n">input_scale</span><span class="p">,</span> <span class="n">pad_to_stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span> <span class="o">=</span> <span class="n">peak_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refinement</span> <span class="o">=</span> <span class="n">refinement</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span> <span class="o">=</span> <span class="n">integral_patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_confmaps</span> <span class="o">=</span> <span class="n">return_confmaps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="o">=</span> <span class="n">confmaps_ind</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="o">=</span> <span class="n">offsets_ind</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="o">=</span> <span class="n">find_head</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="s2">&quot;CenteredInstanceConfmapsHead&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Index of the confidence maps output tensor must be specified if not &quot;</span>
                <span class="s2">&quot;named &#39;CenteredInstanceConfmapsHead&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="o">=</span> <span class="n">find_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="s2">&quot;OffsetRefinementHead&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">output_stride</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Attempt to automatically infer the output stride.</span>
            <span class="n">output_stride</span> <span class="o">=</span> <span class="n">get_model_output_stride</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_stride</span> <span class="o">=</span> <span class="n">output_stride</span>

<div class="viewcode-block" id="FindInstancePeaks.call"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.FindInstancePeaks.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Predict confidence maps and infer peak coordinates.</span>

<span class="sd">        This layer can be chained with a `CentroidCrop` layer to create a top-down</span>
<span class="sd">        inference function from full images.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: Instance-centered images as a `tf.Tensor` of shape</span>
<span class="sd">                `(samples, height, width, channels)` or `tf.RaggedTensor` of shape</span>
<span class="sd">                `(samples, ?, height, width, channels)` where images are grouped by</span>
<span class="sd">                sample and may contain a variable number of crops, or a dictionary with</span>
<span class="sd">                keys:</span>
<span class="sd">                `&quot;crops&quot;`: Cropped images in either format above.</span>
<span class="sd">                `&quot;crop_offsets&quot;`: (Optional) Coordinates of the top-left of the crops as</span>
<span class="sd">                    `(x, y)` offsets of shape `(samples, ?, 2)` for adjusting the</span>
<span class="sd">                    predicted peak coordinates. No adjustment is performed if not</span>
<span class="sd">                    provided.</span>
<span class="sd">                `&quot;centroids&quot;`: (Optional) If provided, will be passed through to the</span>
<span class="sd">                    output.</span>
<span class="sd">                `&quot;centroid_vals&quot;`: (Optional) If provided, will be passed through to the</span>
<span class="sd">                    output.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary of outputs with keys:</span>

<span class="sd">            `&quot;instance_peaks&quot;`: The predicted peaks for each instance in the batch as a</span>
<span class="sd">                `tf.RaggedTensor` of shape `(samples, ?, nodes, 2)`.</span>
<span class="sd">            `&quot;instance_peak_vals&quot;`: The value of the confidence maps at the predicted</span>
<span class="sd">                peaks for each instance in the batch as a `tf.RaggedTensor` of shape</span>
<span class="sd">                `(samples, ?, nodes)`.</span>

<span class="sd">            If provided (e.g., from an input `CentroidCrop` layer), the centroids that</span>
<span class="sd">            generated the crops will also be included in the keys `&quot;centroids&quot;` and</span>
<span class="sd">            `&quot;centroid_vals&quot;`.</span>

<span class="sd">            If the `return_confmaps` attribute is set to `True`, the output will also</span>
<span class="sd">            contain a key named `&quot;instance_confmaps&quot;` containing a `tf.RaggedTensor` of</span>
<span class="sd">            shape `(samples, ?, output_height, output_width, nodes)` containing the</span>
<span class="sd">            confidence maps predicted by the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">crops</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;crops&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Tensor input provided. We&#39;ll infer the extra fields in the expected input</span>
            <span class="c1"># dictionary.</span>
            <span class="n">crops</span> <span class="o">=</span> <span class="n">inputs</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">crops</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">):</span>
            <span class="n">crops</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;crops&quot;</span><span class="p">]</span>  <span class="c1"># (samples, ?, height, width, channels)</span>

            <span class="c1"># Flatten crops into (n_peaks, height, width, channels)</span>
            <span class="n">crop_sample_inds</span> <span class="o">=</span> <span class="n">crops</span><span class="o">.</span><span class="n">value_rowids</span><span class="p">()</span>  <span class="c1"># (n_peaks,)</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="n">crops</span><span class="o">.</span><span class="n">nrows</span><span class="p">()</span>
            <span class="n">crops</span> <span class="o">=</span> <span class="n">crops</span><span class="o">.</span><span class="n">merge_dims</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;crop_sample_inds&quot;</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
                <span class="c1"># Crops provided as a regular tensor, use the metadata are in the input.</span>
                <span class="n">samples</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;samples&quot;</span><span class="p">]</span>
                <span class="n">crop_sample_inds</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;crop_sample_inds&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Assuming crops is (samples, height, width, channels).</span>
                <span class="n">samples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">crops</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">crop_sample_inds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="c1"># Preprocess inputs (scaling, padding, colorspace, int to float).</span>
        <span class="n">crops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">crops</span><span class="p">)</span>

        <span class="c1"># Network forward pass.</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">(</span><span class="n">crops</span><span class="p">)</span>

        <span class="c1"># Sort outputs.</span>
        <span class="n">offsets</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">cms</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">offsets</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Assume confidence maps if single output.</span>
            <span class="n">cms</span> <span class="o">=</span> <span class="n">out</span>

        <span class="c1"># Find peaks.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Use deterministic refinement.</span>
            <span class="n">peak_points</span><span class="p">,</span> <span class="n">peak_vals</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">peak_finding</span><span class="o">.</span><span class="n">find_global_peaks</span><span class="p">(</span>
                <span class="n">cms</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span><span class="p">,</span>
                <span class="n">refinement</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">refinement</span><span class="p">,</span>
                <span class="n">integral_patch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Use learned offsets.</span>
            <span class="p">(</span>
                <span class="n">peak_points</span><span class="p">,</span>
                <span class="n">peak_vals</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">peak_finding</span><span class="o">.</span><span class="n">find_global_peaks_with_offsets</span><span class="p">(</span>
                <span class="n">cms</span><span class="p">,</span>
                <span class="n">offsets</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Adjust for stride and scale.</span>
        <span class="n">peak_points</span> <span class="o">=</span> <span class="n">peak_points</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_stride</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="c1"># Note: We add 0.5 here to offset TensorFlow&#39;s weird image resizing. This</span>
            <span class="c1"># may not always(?) be the most correct approach.</span>
            <span class="c1"># See: https://github.com/tensorflow/tensorflow/issues/6720</span>
            <span class="n">peak_points</span> <span class="o">=</span> <span class="p">(</span><span class="n">peak_points</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span>

        <span class="c1"># Adjust for crop offsets if provided.</span>
        <span class="k">if</span> <span class="s2">&quot;crop_offsets&quot;</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
            <span class="c1"># Flatten (samples, ?, 2) -&gt; (n_peaks, 2).</span>
            <span class="n">crop_offsets</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;crop_offsets&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">merge_dims</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">peak_points</span> <span class="o">=</span> <span class="n">peak_points</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">crop_offsets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Group peaks by sample (samples, ?, nodes, 2).</span>
        <span class="n">peaks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">peak_points</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">samples</span>
        <span class="p">)</span>
        <span class="n">peak_vals</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">peak_vals</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">samples</span>
        <span class="p">)</span>

        <span class="c1"># Build outputs.</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;instance_peaks&quot;</span><span class="p">:</span> <span class="n">peaks</span><span class="p">,</span> <span class="s2">&quot;instance_peak_vals&quot;</span><span class="p">:</span> <span class="n">peak_vals</span><span class="p">}</span>
        <span class="k">if</span> <span class="s2">&quot;centroids&quot;</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;centroids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;centroids&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s2">&quot;centroids&quot;</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;centroid_vals&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;centroid_vals&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_confmaps</span><span class="p">:</span>
            <span class="n">cms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
                <span class="n">cms</span><span class="p">,</span> <span class="n">crop_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">samples</span>
            <span class="p">)</span>
            <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;instance_confmaps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cms</span>
        <span class="k">return</span> <span class="n">outputs</span></div></div>


<div class="viewcode-block" id="TopDownInferenceModel"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.TopDownInferenceModel">[docs]</a><span class="k">class</span> <span class="nc">TopDownInferenceModel</span><span class="p">(</span><span class="n">InferenceModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Top-down instance prediction model.</span>

<span class="sd">    This model encapsulates the top-down approach where instances are first detected by</span>
<span class="sd">    local peak detection of an anchor point and then cropped. These instance-centered</span>
<span class="sd">    crops are then passed to an instance peak detector which is trained to detect all</span>
<span class="sd">    remaining body parts for the instance that is centered within the crop.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        centroid_crop: A centroid cropping layer. This can be either `CentroidCrop` or</span>
<span class="sd">            `CentroidCropGroundTruth`. This layer takes the full image as input and</span>
<span class="sd">            outputs a set of centroids and cropped boxes.</span>
<span class="sd">        instance_peaks: A instance peak detection layer. This can be either</span>
<span class="sd">            `FindInstancePeaks` or `FindInstancePeaksGroundTruth`. This layer takes as</span>
<span class="sd">            input the output of the centroid cropper and outputs the detected peaks for</span>
<span class="sd">            the instances within each crop.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">centroid_crop</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">CentroidCrop</span><span class="p">,</span> <span class="n">CentroidCropGroundTruth</span><span class="p">],</span>
        <span class="n">instance_peaks</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">FindInstancePeaks</span><span class="p">,</span> <span class="n">FindInstancePeaksGroundTruth</span><span class="p">],</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">centroid_crop</span> <span class="o">=</span> <span class="n">centroid_crop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">instance_peaks</span> <span class="o">=</span> <span class="n">instance_peaks</span>

<div class="viewcode-block" id="TopDownInferenceModel.call"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.TopDownInferenceModel.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">example</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Predict instances for one batch of images.</span>

<span class="sd">        Args:</span>
<span class="sd">            example: This may be either a single batch of images as a 4-D tensor of</span>
<span class="sd">                shape `(batch_size, height, width, channels)`, or a dictionary</span>
<span class="sd">                containing the image batch in the `&quot;images&quot;` key. If using a ground</span>
<span class="sd">                truth model for either centroid cropping or instance peaks, the full</span>
<span class="sd">                example from a `Pipeline` is required for providing the metadata.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The predicted instances as a dictionary of tensors with keys:</span>

<span class="sd">            `&quot;centroids&quot;: (batch_size, n_instances, 2)`: Instance centroids.</span>
<span class="sd">            `&quot;centroid_vals&quot;: (batch_size, n_instances)`: Instance centroid confidence</span>
<span class="sd">                values.</span>
<span class="sd">            `&quot;instance_peaks&quot;: (batch_size, n_instances, n_nodes, 2)`: Instance skeleton</span>
<span class="sd">                points.</span>
<span class="sd">            `&quot;instance_peak_vals&quot;: (batch_size, n_instances, n_nodes)`: Confidence</span>
<span class="sd">                values for the instance skeleton points.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">example</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">example</span><span class="p">)</span>

        <span class="n">crop_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">centroid_crop</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">instance_peaks</span><span class="p">,</span> <span class="n">FindInstancePeaksGroundTruth</span><span class="p">):</span>
            <span class="n">peaks_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">instance_peaks</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">crop_output</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">peaks_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">instance_peaks</span><span class="p">(</span><span class="n">crop_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">peaks_output</span></div></div>


<div class="viewcode-block" id="TopDownPredictor"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.TopDownPredictor">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TopDownPredictor</span><span class="p">(</span><span class="n">Predictor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Top-down multi-instance predictor.</span>

<span class="sd">    This high-level class handles initialization, preprocessing and tracking using a</span>
<span class="sd">    trained top-down multi-instance SLEAP model.</span>

<span class="sd">    This should be initialized using the `from_trained_models()` constructor or the</span>
<span class="sd">    high-level API (`sleap.load_model`).</span>

<span class="sd">    Attributes:</span>
<span class="sd">        centroid_config: The `sleap.nn.config.TrainingJobConfig` containing the metadata</span>
<span class="sd">            for the trained centroid model. If `None`, ground truth centroids will be</span>
<span class="sd">            used if available from the data source.</span>
<span class="sd">        centroid_model: A `sleap.nn.model.Model` instance created from the trained</span>
<span class="sd">            centroid model. If `None`, ground truth centroids will be used if available</span>
<span class="sd">            from the data source.</span>
<span class="sd">        confmap_config: The `sleap.nn.config.TrainingJobConfig` containing the metadata</span>
<span class="sd">            for the trained centered instance model. If `None`, ground truth instances</span>
<span class="sd">            will be used if available from the data source.</span>
<span class="sd">        confmap_model: A `sleap.nn.model.Model` instance created from the trained</span>
<span class="sd">            centered-instance model. If `None`, ground truth instances will be used if</span>
<span class="sd">            available from the data source.</span>
<span class="sd">        inference_model: A `sleap.nn.inference.TopDownInferenceModel` that wraps a</span>
<span class="sd">            trained `tf.keras.Model` to implement preprocessing, centroid detection,</span>
<span class="sd">            cropping and peak finding.</span>
<span class="sd">        pipeline: A `sleap.nn.data.Pipeline` that loads the data and batches input data.</span>
<span class="sd">            This will be updated dynamically if new data sources are used.</span>
<span class="sd">        tracker: A `sleap.nn.tracking.Tracker` that will be called to associate</span>
<span class="sd">            detections over time. Predicted instances will not be assigned to tracks if</span>
<span class="sd">            if this is `None`.</span>
<span class="sd">        batch_size: The default batch size to use when loading data for inference.</span>
<span class="sd">            Higher values increase inference speed at the cost of higher memory usage.</span>
<span class="sd">        peak_threshold: Minimum confidence map value to consider a local peak as valid.</span>
<span class="sd">        integral_refinement: If `True`, peaks will be refined with integral regression.</span>
<span class="sd">            If `False`, `&quot;local&quot;`, peaks will be refined with quarter pixel local</span>
<span class="sd">            gradient offset. This has no effect if the model has an offset regression</span>
<span class="sd">            head.</span>
<span class="sd">        integral_patch_size: Size of patches to crop around each rough peak for integral</span>
<span class="sd">            refinement as an integer scalar.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">centroid_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TrainingJobConfig</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">centroid_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Model</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">confmap_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TrainingJobConfig</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">confmap_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Model</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">inference_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TopDownInferenceModel</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">pipeline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">tracker</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tracker</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span>
    <span class="n">integral_refinement</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">integral_patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>

    <span class="k">def</span> <span class="nf">_initialize_inference_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the inference model from the trained models and configuration.&quot;&quot;&quot;</span>
        <span class="n">use_gt_centroid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">centroid_config</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="n">use_gt_confmap</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmap_config</span> <span class="ow">is</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">use_gt_centroid</span><span class="p">:</span>
            <span class="n">centroid_crop_layer</span> <span class="o">=</span> <span class="n">CentroidCropGroundTruth</span><span class="p">(</span>
                <span class="n">crop_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">confmap_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">instance_cropping</span><span class="o">.</span><span class="n">crop_size</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">use_gt_confmap</span><span class="p">:</span>
                <span class="n">crop_size</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">crop_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmap_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">instance_cropping</span><span class="o">.</span><span class="n">crop_size</span>
            <span class="n">centroid_crop_layer</span> <span class="o">=</span> <span class="n">CentroidCrop</span><span class="p">(</span>
                <span class="n">keras_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">centroid_model</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span>
                <span class="n">crop_size</span><span class="o">=</span><span class="n">crop_size</span><span class="p">,</span>
                <span class="n">input_scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">centroid_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">input_scaling</span><span class="p">,</span>
                <span class="n">pad_to_stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">centroid_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">pad_to_stride</span><span class="p">,</span>
                <span class="n">output_stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">centroid_config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">heads</span><span class="o">.</span><span class="n">centroid</span><span class="o">.</span><span class="n">output_stride</span><span class="p">,</span>
                <span class="n">peak_threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span><span class="p">,</span>
                <span class="n">refinement</span><span class="o">=</span><span class="s2">&quot;integral&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">integral_refinement</span> <span class="k">else</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span>
                <span class="n">integral_patch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span><span class="p">,</span>
                <span class="n">return_confmaps</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">use_gt_confmap</span><span class="p">:</span>
            <span class="n">instance_peaks_layer</span> <span class="o">=</span> <span class="n">FindInstancePeaksGroundTruth</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmap_config</span>
            <span class="n">instance_peaks_layer</span> <span class="o">=</span> <span class="n">FindInstancePeaks</span><span class="p">(</span>
                <span class="n">keras_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">confmap_model</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span>
                <span class="n">input_scale</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">input_scaling</span><span class="p">,</span>
                <span class="n">peak_threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span><span class="p">,</span>
                <span class="n">output_stride</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">heads</span><span class="o">.</span><span class="n">centered_instance</span><span class="o">.</span><span class="n">output_stride</span><span class="p">,</span>
                <span class="n">refinement</span><span class="o">=</span><span class="s2">&quot;integral&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">integral_refinement</span> <span class="k">else</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span>
                <span class="n">integral_patch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span><span class="p">,</span>
                <span class="n">return_confmaps</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">inference_model</span> <span class="o">=</span> <span class="n">TopDownInferenceModel</span><span class="p">(</span>
            <span class="n">centroid_crop</span><span class="o">=</span><span class="n">centroid_crop_layer</span><span class="p">,</span> <span class="n">instance_peaks</span><span class="o">=</span><span class="n">instance_peaks_layer</span>
        <span class="p">)</span>

<div class="viewcode-block" id="TopDownPredictor.from_trained_models"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.TopDownPredictor.from_trained_models">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_trained_models</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">centroid_model_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">confmap_model_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">integral_refinement</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">integral_patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;TopDownPredictor&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create predictor from saved models.</span>

<span class="sd">        Args:</span>
<span class="sd">            centroid_model_path: Path to a centroid model folder or training job JSON</span>
<span class="sd">                file inside a model folder. This folder should contain</span>
<span class="sd">                `training_config.json` and `best_model.h5` files for a trained model.</span>
<span class="sd">            confmap_model_path: Path to a centered instance model folder or training job</span>
<span class="sd">                JSON file inside a model folder. This folder should contain</span>
<span class="sd">                `training_config.json` and `best_model.h5` files for a trained model.</span>
<span class="sd">            batch_size: The default batch size to use when loading data for inference.</span>
<span class="sd">                Higher values increase inference speed at the cost of higher memory</span>
<span class="sd">                usage.</span>
<span class="sd">            peak_threshold: Minimum confidence map value to consider a local peak as</span>
<span class="sd">                valid.</span>
<span class="sd">            integral_refinement: If `True`, peaks will be refined with integral</span>
<span class="sd">                regression. If `False`, `&quot;local&quot;`, peaks will be refined with quarter</span>
<span class="sd">                pixel local gradient offset. This has no effect if the model has an</span>
<span class="sd">                offset regression head.</span>
<span class="sd">            integral_patch_size: Size of patches to crop around each rough peak for</span>
<span class="sd">                integral refinement as an integer scalar.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An instance of `TopDownPredictor` with the loaded models.</span>

<span class="sd">            One of the two models can be left as `None` to perform inference with ground</span>
<span class="sd">            truth data. This will only work with `LabelsReader` as the provider.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">centroid_model_path</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">confmap_model_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Either the centroid or topdown confidence map model must be provided.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">centroid_model_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Load centroid model.</span>
            <span class="n">centroid_config</span> <span class="o">=</span> <span class="n">TrainingJobConfig</span><span class="o">.</span><span class="n">load_json</span><span class="p">(</span><span class="n">centroid_model_path</span><span class="p">)</span>
            <span class="n">centroid_keras_model_path</span> <span class="o">=</span> <span class="n">get_keras_model_path</span><span class="p">(</span><span class="n">centroid_model_path</span><span class="p">)</span>
            <span class="n">centroid_model</span> <span class="o">=</span> <span class="n">Model</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">centroid_config</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
            <span class="n">centroid_model</span><span class="o">.</span><span class="n">keras_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span>
                <span class="n">centroid_keras_model_path</span><span class="p">,</span> <span class="nb">compile</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">centroid_config</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">centroid_model</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">confmap_model_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Load confmap model.</span>
            <span class="n">confmap_config</span> <span class="o">=</span> <span class="n">TrainingJobConfig</span><span class="o">.</span><span class="n">load_json</span><span class="p">(</span><span class="n">confmap_model_path</span><span class="p">)</span>
            <span class="n">confmap_keras_model_path</span> <span class="o">=</span> <span class="n">get_keras_model_path</span><span class="p">(</span><span class="n">confmap_model_path</span><span class="p">)</span>
            <span class="n">confmap_model</span> <span class="o">=</span> <span class="n">Model</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">confmap_config</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
            <span class="n">confmap_model</span><span class="o">.</span><span class="n">keras_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span>
                <span class="n">confmap_keras_model_path</span><span class="p">,</span> <span class="nb">compile</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">confmap_config</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">confmap_model</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">obj</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">centroid_config</span><span class="o">=</span><span class="n">centroid_config</span><span class="p">,</span>
            <span class="n">centroid_model</span><span class="o">=</span><span class="n">centroid_model</span><span class="p">,</span>
            <span class="n">confmap_config</span><span class="o">=</span><span class="n">confmap_config</span><span class="p">,</span>
            <span class="n">confmap_model</span><span class="o">=</span><span class="n">confmap_model</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">peak_threshold</span><span class="o">=</span><span class="n">peak_threshold</span><span class="p">,</span>
            <span class="n">integral_refinement</span><span class="o">=</span><span class="n">integral_refinement</span><span class="p">,</span>
            <span class="n">integral_patch_size</span><span class="o">=</span><span class="n">integral_patch_size</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">obj</span><span class="o">.</span><span class="n">_initialize_inference_model</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">obj</span></div>

<div class="viewcode-block" id="TopDownPredictor.make_pipeline"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.TopDownPredictor.make_pipeline">[docs]</a>    <span class="k">def</span> <span class="nf">make_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Provider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Pipeline</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Make a data loading pipeline.</span>

<span class="sd">        Args:</span>
<span class="sd">            data_provider: If not `None`, the pipeline will be created with an instance</span>
<span class="sd">                of a `sleap.pipelines.Provider`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The created `sleap.pipelines.Pipeline` with batching and prefetching.</span>

<span class="sd">        Notes:</span>
<span class="sd">            This method also updates the class attribute for the pipeline and will be</span>
<span class="sd">            called automatically when predicting on data from a new source.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">data_provider</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pipeline</span><span class="o">.</span><span class="n">providers</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_provider</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">centroid_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">anchor_part</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmap_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">instance_cropping</span><span class="o">.</span><span class="n">center_on_part</span>
            <span class="n">pipeline</span> <span class="o">+=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">InstanceCentroidFinder</span><span class="p">(</span>
                <span class="n">center_on_anchor_part</span><span class="o">=</span><span class="n">anchor_part</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">anchor_part_names</span><span class="o">=</span><span class="n">anchor_part</span><span class="p">,</span>
                <span class="n">skeletons</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">confmap_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">skeletons</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">pipeline</span> <span class="o">+=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">Batcher</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">unrag</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">pipeline</span> <span class="o">+=</span> <span class="n">Prefetcher</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">pipeline</span>

        <span class="k">return</span> <span class="n">pipeline</span></div>

    <span class="k">def</span> <span class="nf">_make_labeled_frames_from_generator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]],</span> <span class="n">data_provider</span><span class="p">:</span> <span class="n">Provider</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">sleap</span><span class="o">.</span><span class="n">LabeledFrame</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Create labeled frames from a generator that yields inference results.</span>

<span class="sd">        This method converts pure arrays into SLEAP-specific data structures and runs</span>
<span class="sd">        them through the tracker if it is specified.</span>

<span class="sd">        Args:</span>
<span class="sd">            generator: A generator that returns dictionaries with inference results.</span>
<span class="sd">                This should return dictionaries with keys `&quot;image&quot;`, `&quot;video_ind&quot;`,</span>
<span class="sd">                `&quot;frame_ind&quot;`, `&quot;instance_peaks&quot;`, `&quot;instance_peak_vals&quot;`, and</span>
<span class="sd">                `&quot;centroid_vals&quot;`. This can be created using the `_predict_generator()`</span>
<span class="sd">                method.</span>
<span class="sd">            data_provider: The `sleap.pipelines.Provider` that the predictions are being</span>
<span class="sd">                created from. This is used to retrieve the `sleap.Video` instance</span>
<span class="sd">                associated with each inference result.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of `sleap.LabeledFrame`s with `sleap.PredictedInstance`s created from</span>
<span class="sd">            arrays returned from the inference result generator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmap_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">skeleton</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmap_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">skeletons</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">skeleton</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">centroid_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">skeletons</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Loop over batches.</span>
        <span class="n">predicted_frames</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>

            <span class="k">if</span> <span class="s2">&quot;n_valid&quot;</span> <span class="ow">in</span> <span class="n">ex</span><span class="p">:</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peaks&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">x</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peaks&quot;</span><span class="p">],</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;n_valid&quot;</span><span class="p">])</span>
                <span class="p">]</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peak_vals&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">x</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peak_vals&quot;</span><span class="p">],</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;n_valid&quot;</span><span class="p">])</span>
                <span class="p">]</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;centroids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">x</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s2">&quot;centroids&quot;</span><span class="p">],</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;n_valid&quot;</span><span class="p">])</span>
                <span class="p">]</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;centroid_vals&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">x</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s2">&quot;centroid_vals&quot;</span><span class="p">],</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;n_valid&quot;</span><span class="p">])</span>
                <span class="p">]</span>

            <span class="c1"># Loop over frames.</span>
            <span class="k">for</span> <span class="n">image</span><span class="p">,</span> <span class="n">video_ind</span><span class="p">,</span> <span class="n">frame_ind</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">confidences</span><span class="p">,</span> <span class="n">scores</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;video_ind&quot;</span><span class="p">],</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;frame_ind&quot;</span><span class="p">],</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peaks&quot;</span><span class="p">],</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peak_vals&quot;</span><span class="p">],</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;centroid_vals&quot;</span><span class="p">],</span>
            <span class="p">):</span>

                <span class="c1"># Loop over instances.</span>
                <span class="n">predicted_instances</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">pts</span><span class="p">,</span> <span class="n">confs</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">confidences</span><span class="p">,</span> <span class="n">scores</span><span class="p">):</span>
                    <span class="n">predicted_instances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">sleap</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">PredictedInstance</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span>
                            <span class="n">points</span><span class="o">=</span><span class="n">pts</span><span class="p">,</span>
                            <span class="n">point_confidences</span><span class="o">=</span><span class="n">confs</span><span class="p">,</span>
                            <span class="n">instance_score</span><span class="o">=</span><span class="n">score</span><span class="p">,</span>
                            <span class="n">skeleton</span><span class="o">=</span><span class="n">skeleton</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span><span class="p">:</span>
                    <span class="c1"># Set tracks for predicted instances in this frame.</span>
                    <span class="n">predicted_instances</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
                        <span class="n">untracked_instances</span><span class="o">=</span><span class="n">predicted_instances</span><span class="p">,</span> <span class="n">img</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">frame_ind</span>
                    <span class="p">)</span>

                <span class="n">predicted_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">sleap</span><span class="o">.</span><span class="n">LabeledFrame</span><span class="p">(</span>
                        <span class="n">video</span><span class="o">=</span><span class="n">data_provider</span><span class="o">.</span><span class="n">videos</span><span class="p">[</span><span class="n">video_ind</span><span class="p">],</span>
                        <span class="n">frame_idx</span><span class="o">=</span><span class="n">frame_ind</span><span class="p">,</span>
                        <span class="n">instances</span><span class="o">=</span><span class="n">predicted_instances</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span><span class="o">.</span><span class="n">final_pass</span><span class="p">(</span><span class="n">predicted_frames</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">predicted_frames</span></div>


<div class="viewcode-block" id="BottomUpInferenceLayer"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.BottomUpInferenceLayer">[docs]</a><span class="k">class</span> <span class="nc">BottomUpInferenceLayer</span><span class="p">(</span><span class="n">InferenceLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Keras layer that predicts instances from images using a trained model.</span>

<span class="sd">    This layer encapsulates all of the inference operations required for generating</span>
<span class="sd">    predictions from a centered instance confidence map model. This includes</span>
<span class="sd">    preprocessing, model forward pass, peak finding and coordinate adjustment.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        keras_model: A `tf.keras.Model` that accepts rank-4 images as input and predicts</span>
<span class="sd">            rank-4 confidence maps and part affinity fields as output.</span>
<span class="sd">        paf_scorer: A `sleap.nn.paf_grouping.PAFScorer` instance configured to group</span>
<span class="sd">            instances based on peaks and PAFs produced by the model.</span>
<span class="sd">        input_scale: Float indicating if the images should be resized before being</span>
<span class="sd">            passed to the model.</span>
<span class="sd">        cm_output_stride: Output stride of the model, denoting the scale of the output</span>
<span class="sd">            confidence maps relative to the images (after input scaling). This is used</span>
<span class="sd">            for adjusting the peak coordinates to the image grid. This will be inferred</span>
<span class="sd">            from the model shapes if not provided.</span>
<span class="sd">        paf_output_stride: Output stride of the model, denoting the scale of the output</span>
<span class="sd">            part affinity fields relative to the images (after input scaling). This is</span>
<span class="sd">            used for adjusting the peak coordinates to the PAF grid. This will be</span>
<span class="sd">            inferred from the model shapes if not provided.</span>
<span class="sd">        peak_threshold: Minimum confidence map value to consider a global peak as valid.</span>
<span class="sd">        refinement: If `None`, returns the grid-aligned peaks with no refinement. If</span>
<span class="sd">            `&quot;integral&quot;`, peaks will be refined with integral regression. If `&quot;local&quot;`,</span>
<span class="sd">            peaks will be refined with quarter pixel local gradient offset. This has no</span>
<span class="sd">            effect if the model has an offset regression head.</span>
<span class="sd">        integral_patch_size: Size of patches to crop around each rough peak for integral</span>
<span class="sd">            refinement as an integer scalar.</span>
<span class="sd">        return_confmaps: If `True`, the confidence maps will be returned together with</span>
<span class="sd">            the predicted instances. This will result in slower inference times since</span>
<span class="sd">            the data must be copied off of the GPU, but is useful for visualizing the</span>
<span class="sd">            raw output of the model.</span>
<span class="sd">        return_pafs: If `True`, the part affinity fields will be returned together with</span>
<span class="sd">            the predicted instances. This will result in slower inference times since</span>
<span class="sd">            the data must be copied off of the GPU, but is useful for visualizing the</span>
<span class="sd">            raw output of the model.</span>
<span class="sd">        confmaps_ind: Index of the output tensor of the model corresponding to</span>
<span class="sd">            confidence maps. If `None` (the default), this will be detected</span>
<span class="sd">            automatically by searching for the first tensor that contains</span>
<span class="sd">            `&quot;MultiInstanceConfmapsHead&quot;` in its name.</span>
<span class="sd">        pafs_ind: Index of the output tensor of the model corresponding to part affinity</span>
<span class="sd">            fields. If `None` (the default), this will be detected automatically by</span>
<span class="sd">            searching for the first tensor that contains `&quot;PartAffinityFieldsHead&quot;` in</span>
<span class="sd">            its name.</span>
<span class="sd">        offsets_ind: Index of the output tensor of the model corresponding to</span>
<span class="sd">            offset regression maps. If `None` (the default), this will be detected</span>
<span class="sd">            automatically by searching for the first tensor that contains</span>
<span class="sd">            `&quot;OffsetRefinementHead&quot;` in its name. If the head is not present, the method</span>
<span class="sd">            specified in the `refinement` attribute will be used.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">keras_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
        <span class="n">paf_scorer</span><span class="p">:</span> <span class="n">PAFScorer</span><span class="p">,</span>
        <span class="n">input_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">pad_to_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">cm_output_stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">paf_output_stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">refinement</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span>
        <span class="n">integral_patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">return_confmaps</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">return_pafs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">confmaps_ind</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pafs_ind</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">offsets_ind</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">keras_model</span><span class="o">=</span><span class="n">keras_model</span><span class="p">,</span>
            <span class="n">input_scale</span><span class="o">=</span><span class="n">input_scale</span><span class="p">,</span>
            <span class="n">pad_to_stride</span><span class="o">=</span><span class="n">pad_to_stride</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">paf_scorer</span> <span class="o">=</span> <span class="n">paf_scorer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="o">=</span> <span class="n">confmaps_ind</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pafs_ind</span> <span class="o">=</span> <span class="n">pafs_ind</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="o">=</span> <span class="n">offsets_ind</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="o">=</span> <span class="n">find_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="s2">&quot;MultiInstanceConfmapsHead&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Index of the confidence maps output tensor must be specified if not &quot;</span>
                <span class="s2">&quot;named &#39;MultiInstanceConfmapsHead&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pafs_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pafs_ind</span> <span class="o">=</span> <span class="n">find_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="s2">&quot;PartAffinityFieldsHead&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pafs_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Index of the part affinity fields output tensor must be specified if &quot;</span>
                <span class="s2">&quot;not named &#39;PartAffinityFieldsHead&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="o">=</span> <span class="n">find_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="s2">&quot;OffsetRefinementHead&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cm_output_stride</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Attempt to automatically infer the output stride.</span>
            <span class="n">cm_output_stride</span> <span class="o">=</span> <span class="n">get_model_output_stride</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="n">output_ind</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cm_output_stride</span> <span class="o">=</span> <span class="n">cm_output_stride</span>
        <span class="k">if</span> <span class="n">paf_output_stride</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Attempt to automatically infer the output stride.</span>
            <span class="n">paf_output_stride</span> <span class="o">=</span> <span class="n">get_model_output_stride</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span> <span class="n">output_ind</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pafs_ind</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">paf_output_stride</span> <span class="o">=</span> <span class="n">paf_output_stride</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span> <span class="o">=</span> <span class="n">peak_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refinement</span> <span class="o">=</span> <span class="n">refinement</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span> <span class="o">=</span> <span class="n">integral_patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_confmaps</span> <span class="o">=</span> <span class="n">return_confmaps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_pafs</span> <span class="o">=</span> <span class="n">return_pafs</span>

<div class="viewcode-block" id="BottomUpInferenceLayer.forward_pass"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.BottomUpInferenceLayer.forward_pass">[docs]</a>    <span class="k">def</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run preprocessing and model inference on a batch.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">data</span>

        <span class="c1"># Preprocess full images.</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>

        <span class="c1"># Model forward pass.</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cms</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span><span class="p">]</span>
            <span class="n">pafs</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pafs_ind</span><span class="p">]</span>
            <span class="n">offsets</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cms</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">confmaps_ind</span><span class="p">]</span>
            <span class="n">pafs</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pafs_ind</span><span class="p">]</span>
            <span class="n">offsets</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cms</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">cms</span> <span class="o">=</span> <span class="n">cms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pafs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">pafs</span> <span class="o">=</span> <span class="n">pafs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">cms</span><span class="p">,</span> <span class="n">pafs</span><span class="p">,</span> <span class="n">offsets</span></div>

<div class="viewcode-block" id="BottomUpInferenceLayer.find_peaks"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.BottomUpInferenceLayer.find_peaks">[docs]</a>    <span class="k">def</span> <span class="nf">find_peaks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cms</span><span class="p">,</span> <span class="n">offsets</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run peak finding on predicted confidence maps.&quot;&quot;&quot;</span>
        <span class="c1"># Find local peaks.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets_ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Use deterministic refinement.</span>
            <span class="p">(</span>
                <span class="n">peaks</span><span class="p">,</span>
                <span class="n">peak_vals</span><span class="p">,</span>
                <span class="n">peak_sample_inds</span><span class="p">,</span>
                <span class="n">peak_channel_inds</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">peak_finding</span><span class="o">.</span><span class="n">find_local_peaks</span><span class="p">(</span>
                <span class="n">cms</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span><span class="p">,</span>
                <span class="n">refinement</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">refinement</span><span class="p">,</span>
                <span class="n">integral_patch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Use learned offsets.</span>
            <span class="p">(</span>
                <span class="n">peaks</span><span class="p">,</span>
                <span class="n">peak_vals</span><span class="p">,</span>
                <span class="n">peak_sample_inds</span><span class="p">,</span>
                <span class="n">peak_channel_inds</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">peak_finding</span><span class="o">.</span><span class="n">find_local_peaks_with_offsets</span><span class="p">(</span>
                <span class="n">cms</span><span class="p">,</span>
                <span class="n">offsets</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Adjust for confidence map output stride.</span>
        <span class="n">peaks</span> <span class="o">=</span> <span class="n">peaks</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cm_output_stride</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># Group peaks by sample.</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">cms</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">peaks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">peaks</span><span class="p">,</span> <span class="n">peak_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">n_samples</span>
        <span class="p">)</span>
        <span class="n">peak_vals</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">peak_vals</span><span class="p">,</span> <span class="n">peak_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">n_samples</span>
        <span class="p">)</span>
        <span class="n">peak_channel_inds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">peak_channel_inds</span><span class="p">,</span> <span class="n">peak_sample_inds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">n_samples</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">peaks</span><span class="p">,</span> <span class="n">peak_vals</span><span class="p">,</span> <span class="n">peak_channel_inds</span></div>

<div class="viewcode-block" id="BottomUpInferenceLayer.call"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.BottomUpInferenceLayer.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict instances for one batch of images.</span>

<span class="sd">        Args:</span>
<span class="sd">            data: This may be either a single batch of images as a 4-D tensor of shape</span>
<span class="sd">            `(batch_size, height, width, channels)`, or a dictionary containing the</span>
<span class="sd">            image batch in the `&quot;images&quot;` key.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The predicted instances as a dictionary of tensors with keys:</span>

<span class="sd">            `&quot;instance_peaks&quot;: (batch_size, n_instances, n_nodes, 2)`: Instance skeleton</span>
<span class="sd">            points.</span>

<span class="sd">            `&quot;instance_peak_vals&quot;: (batch_size, n_instances, n_nodes)`: Confidence</span>
<span class="sd">            values for the instance skeleton points.</span>

<span class="sd">            `&quot;instance_scores&quot;: (batch_size, n_instances)`: PAF matching score for each</span>
<span class="sd">            instance.</span>

<span class="sd">            If `BottomUpInferenceLayer.return_confmaps` is `True`, the predicted</span>
<span class="sd">            confidence maps will be returned in the `&quot;confmaps&quot;` key.</span>

<span class="sd">            If `BottomUpInferenceLayer.return_pafs` is `True`, the predicted PAFs will</span>
<span class="sd">            be returned in the `&quot;part_affinity_fields&quot;` key.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cms</span><span class="p">,</span> <span class="n">pafs</span><span class="p">,</span> <span class="n">offsets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_pass</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">peaks</span><span class="p">,</span> <span class="n">peak_vals</span><span class="p">,</span> <span class="n">peak_channel_inds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_peaks</span><span class="p">(</span><span class="n">cms</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span>
        <span class="p">(</span>
            <span class="n">predicted_instances</span><span class="p">,</span>
            <span class="n">predicted_peak_scores</span><span class="p">,</span>
            <span class="n">predicted_instance_scores</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">paf_scorer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">pafs</span><span class="p">,</span> <span class="n">peaks</span><span class="p">,</span> <span class="n">peak_vals</span><span class="p">,</span> <span class="n">peak_channel_inds</span><span class="p">)</span>

        <span class="c1"># Adjust for input scaling.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="c1"># Note: We add 0.5 here to offset TensorFlow&#39;s weird image resizing. This</span>
            <span class="c1"># may not always(?) be the most correct approach.</span>
            <span class="c1"># See: https://github.com/tensorflow/tensorflow/issues/6720</span>
            <span class="n">predicted_instances</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_instances</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_scale</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span>

        <span class="c1"># Build outputs and return.</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;instance_peaks&quot;</span><span class="p">:</span> <span class="n">predicted_instances</span><span class="p">,</span>
            <span class="s2">&quot;instance_peak_vals&quot;</span><span class="p">:</span> <span class="n">predicted_peak_scores</span><span class="p">,</span>
            <span class="s2">&quot;instance_scores&quot;</span><span class="p">:</span> <span class="n">predicted_instance_scores</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_confmaps</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s2">&quot;confmaps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cms</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_pafs</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s2">&quot;part_affinity_fields&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pafs</span>
        <span class="k">return</span> <span class="n">out</span></div></div>


<div class="viewcode-block" id="BottomUpInferenceModel"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.BottomUpInferenceModel">[docs]</a><span class="k">class</span> <span class="nc">BottomUpInferenceModel</span><span class="p">(</span><span class="n">InferenceModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Bottom-up instance prediction model.</span>

<span class="sd">    This model encapsulates the bottom-up approach where points are first detected by</span>
<span class="sd">    local peak detection and then grouped into instances by connectivity scoring using</span>
<span class="sd">    part affinity fields.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        bottomup_layer: A `BottomUpInferenceLayer`. This layer takes as input a full</span>
<span class="sd">            image and outputs the predicted instances.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bottomup_layer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bottomup_layer</span> <span class="o">=</span> <span class="n">bottomup_layer</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">inference_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottomup_layer</span>

<div class="viewcode-block" id="BottomUpInferenceModel.call"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.BottomUpInferenceModel.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">example</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict instances for one batch of images.</span>

<span class="sd">        Args:</span>
<span class="sd">            example: This may be either a single batch of images as a 4-D tensor of</span>
<span class="sd">                shape `(batch_size, height, width, channels)`, or a dictionary</span>
<span class="sd">                containing the image batch in the `&quot;images&quot;` key.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The predicted instances as a dictionary of tensors with keys:</span>

<span class="sd">            `&quot;instance_peaks&quot;: (batch_size, n_instances, n_nodes, 2)`: Instance skeleton</span>
<span class="sd">                points.</span>
<span class="sd">            `&quot;instance_peak_vals&quot;: (batch_size, n_instances, n_nodes)`: Confidence</span>
<span class="sd">                values for the instance skeleton points.</span>
<span class="sd">            `&quot;instance_scores&quot;: (batch_size, n_instances)`: PAF matching score for each</span>
<span class="sd">                instance.</span>

<span class="sd">            If `BottomUpInferenceModel.bottomup_layer.return_confmaps` is `True`, the</span>
<span class="sd">            predicted confidence maps will be returned in the `&quot;confmaps&quot;` key.</span>

<span class="sd">            If `BottomUpInferenceModel.bottomup_layer.return_pafs` is `True`, the</span>
<span class="sd">            predicted PAFs will be returned in the `&quot;part_affinity_fields&quot;` key.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">example</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">example</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottomup_layer</span><span class="p">(</span><span class="n">example</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="BottomUpPredictor"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.BottomUpPredictor">[docs]</a><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">BottomUpPredictor</span><span class="p">(</span><span class="n">Predictor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Bottom-up multi-instance predictor.</span>

<span class="sd">    This high-level class handles initialization, preprocessing and tracking using a</span>
<span class="sd">    trained bottom-up multi-instance SLEAP model.</span>

<span class="sd">    This should be initialized using the `from_trained_models()` constructor or the</span>
<span class="sd">    high-level API (`sleap.load_model`).</span>

<span class="sd">    Attributes:</span>
<span class="sd">        bottomup_config: The `sleap.nn.config.TrainingJobConfig` containing the metadata</span>
<span class="sd">            for the trained bottomup model.</span>
<span class="sd">        bottomup_model: A `sleap.nn.model.Model` instance created from the trained</span>
<span class="sd">            bottomup model. If `None`, ground truth centroids will be used if available</span>
<span class="sd">            from the data source.</span>
<span class="sd">        inference_model: A `sleap.nn.inference.BottomUpInferenceModel` that wraps a</span>
<span class="sd">            trained `tf.keras.Model` to implement preprocessing, centroid detection,</span>
<span class="sd">            cropping and peak finding.</span>
<span class="sd">        pipeline: A `sleap.nn.data.Pipeline` that loads the data and batches input data.</span>
<span class="sd">            This will be updated dynamically if new data sources are used.</span>
<span class="sd">        tracker: A `sleap.nn.tracking.Tracker` that will be called to associate</span>
<span class="sd">            detections over time. Predicted instances will not be assigned to tracks if</span>
<span class="sd">            if this is `None`.</span>
<span class="sd">        batch_size: The default batch size to use when loading data for inference.</span>
<span class="sd">            Higher values increase inference speed at the cost of higher memory usage.</span>
<span class="sd">        peak_threshold: Minimum confidence map value to consider a local peak as valid.</span>
<span class="sd">        integral_refinement: If `True`, peaks will be refined with integral regression.</span>
<span class="sd">            If `False`, `&quot;local&quot;`, peaks will be refined with quarter pixel local</span>
<span class="sd">            gradient offset. This has no effect if the model has an offset regression</span>
<span class="sd">            head.</span>
<span class="sd">        integral_patch_size: Size of patches to crop around each rough peak for integral</span>
<span class="sd">            refinement as an integer scalar.</span>
<span class="sd">        max_edge_length_ratio: The maximum expected length of a connected pair of points</span>
<span class="sd">            in relative image units. Candidate connections above this length will be</span>
<span class="sd">            penalized during matching.</span>
<span class="sd">        paf_line_points: Number of points to sample along the line integral.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">bottomup_config</span><span class="p">:</span> <span class="n">TrainingJobConfig</span>
    <span class="n">bottomup_model</span><span class="p">:</span> <span class="n">Model</span>
    <span class="n">inference_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BottomUpInferenceModel</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">pipeline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">tracker</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tracker</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">integral_refinement</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">integral_patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">max_edge_length_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">paf_line_points</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="k">def</span> <span class="nf">_initialize_inference_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the inference model from the trained model and configuration.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_model</span> <span class="o">=</span> <span class="n">BottomUpInferenceModel</span><span class="p">(</span>
            <span class="n">BottomUpInferenceLayer</span><span class="p">(</span>
                <span class="n">keras_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bottomup_model</span><span class="o">.</span><span class="n">keras_model</span><span class="p">,</span>
                <span class="n">paf_scorer</span><span class="o">=</span><span class="n">PAFScorer</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">bottomup_config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">heads</span><span class="o">.</span><span class="n">multi_instance</span><span class="p">,</span>
                    <span class="n">max_edge_length_ratio</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_edge_length_ratio</span><span class="p">,</span>
                    <span class="n">n_points</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">paf_line_points</span><span class="p">,</span>
                    <span class="n">min_instance_peaks</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">input_scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bottomup_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">input_scaling</span><span class="p">,</span>
                <span class="n">pad_to_stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bottomup_model</span><span class="o">.</span><span class="n">maximum_stride</span><span class="p">,</span>
                <span class="n">peak_threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">peak_threshold</span><span class="p">,</span>
                <span class="n">refinement</span><span class="o">=</span><span class="s2">&quot;integral&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">integral_refinement</span> <span class="k">else</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span>
                <span class="n">integral_patch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">integral_patch_size</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

<div class="viewcode-block" id="BottomUpPredictor.from_trained_models"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.BottomUpPredictor.from_trained_models">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_trained_models</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">model_path</span><span class="p">:</span> <span class="n">Text</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">integral_refinement</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">integral_patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;BottomUpPredictor&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create predictor from a saved model.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_path: Path to a bottom-up model folder or training job JSON file</span>
<span class="sd">                inside a model folder. This folder should contain `training_config.json`</span>
<span class="sd">                and `best_model.h5` files for a trained model.</span>
<span class="sd">            batch_size: The default batch size to use when loading data for inference.</span>
<span class="sd">                Higher values increase inference speed at the cost of higher memory</span>
<span class="sd">                usage.</span>
<span class="sd">            peak_threshold: Minimum confidence map value to consider a local peak as</span>
<span class="sd">                valid.</span>
<span class="sd">            integral_refinement: If `True`, peaks will be refined with integral</span>
<span class="sd">                regression. If `False`, `&quot;local&quot;`, peaks will be refined with quarter</span>
<span class="sd">                pixel local gradient offset. This has no effect if the model has an</span>
<span class="sd">                offset regression head.</span>
<span class="sd">            integral_patch_size: Size of patches to crop around each rough peak for</span>
<span class="sd">                integral refinement as an integer scalar.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An instance of `BottomUpPredictor` with the loaded model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Load bottomup model.</span>
        <span class="n">bottomup_config</span> <span class="o">=</span> <span class="n">TrainingJobConfig</span><span class="o">.</span><span class="n">load_json</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        <span class="n">bottomup_keras_model_path</span> <span class="o">=</span> <span class="n">get_keras_model_path</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        <span class="n">bottomup_model</span> <span class="o">=</span> <span class="n">Model</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">bottomup_config</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">bottomup_model</span><span class="o">.</span><span class="n">keras_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span>
            <span class="n">bottomup_keras_model_path</span><span class="p">,</span> <span class="nb">compile</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">bottomup_config</span><span class="o">=</span><span class="n">bottomup_config</span><span class="p">,</span>
            <span class="n">bottomup_model</span><span class="o">=</span><span class="n">bottomup_model</span><span class="p">,</span>
            <span class="n">peak_threshold</span><span class="o">=</span><span class="n">peak_threshold</span><span class="p">,</span>
            <span class="n">integral_refinement</span><span class="o">=</span><span class="n">integral_refinement</span><span class="p">,</span>
            <span class="n">integral_patch_size</span><span class="o">=</span><span class="n">integral_patch_size</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">obj</span><span class="o">.</span><span class="n">_initialize_inference_model</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">obj</span></div>

    <span class="k">def</span> <span class="nf">_make_labeled_frames_from_generator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]],</span> <span class="n">data_provider</span><span class="p">:</span> <span class="n">Provider</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">sleap</span><span class="o">.</span><span class="n">LabeledFrame</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Create labeled frames from a generator that yields inference results.</span>

<span class="sd">        This method converts pure arrays into SLEAP-specific data structures and runs</span>
<span class="sd">        them through the tracker if it is specified.</span>

<span class="sd">        Args:</span>
<span class="sd">            generator: A generator that returns dictionaries with inference results.</span>
<span class="sd">                This should return dictionaries with keys `&quot;image&quot;`, `&quot;video_ind&quot;`,</span>
<span class="sd">                `&quot;frame_ind&quot;`, `&quot;instance_peaks&quot;`, `&quot;instance_peak_vals&quot;`, and</span>
<span class="sd">                `&quot;instance_scores&quot;`. This can be created using the</span>
<span class="sd">                `_predict_generator()` method.</span>
<span class="sd">            data_provider: The `sleap.pipelines.Provider` that the predictions are being</span>
<span class="sd">                created from. This is used to retrieve the `sleap.Video` instance</span>
<span class="sd">                associated with each inference result.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of `sleap.LabeledFrame`s with `sleap.PredictedInstance`s created from</span>
<span class="sd">            arrays returned from the inference result generator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">skeleton</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottomup_config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">skeletons</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Loop over batches.</span>
        <span class="n">predicted_frames</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>

            <span class="k">if</span> <span class="s2">&quot;n_valid&quot;</span> <span class="ow">in</span> <span class="n">ex</span><span class="p">:</span>
                <span class="c1"># Crop possibly variable length results.</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peaks&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">x</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peaks&quot;</span><span class="p">],</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;n_valid&quot;</span><span class="p">])</span>
                <span class="p">]</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peak_vals&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">x</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peak_vals&quot;</span><span class="p">],</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;n_valid&quot;</span><span class="p">])</span>
                <span class="p">]</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_scores&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">x</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_scores&quot;</span><span class="p">],</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;n_valid&quot;</span><span class="p">])</span>
                <span class="p">]</span>

            <span class="c1"># Loop over frames.</span>
            <span class="k">for</span> <span class="n">image</span><span class="p">,</span> <span class="n">video_ind</span><span class="p">,</span> <span class="n">frame_ind</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">confidences</span><span class="p">,</span> <span class="n">scores</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;video_ind&quot;</span><span class="p">],</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;frame_ind&quot;</span><span class="p">],</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peaks&quot;</span><span class="p">],</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_peak_vals&quot;</span><span class="p">],</span>
                <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;instance_scores&quot;</span><span class="p">],</span>
            <span class="p">):</span>

                <span class="c1"># Loop over instances.</span>
                <span class="n">predicted_instances</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">pts</span><span class="p">,</span> <span class="n">confs</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">confidences</span><span class="p">,</span> <span class="n">scores</span><span class="p">):</span>
                    <span class="n">predicted_instances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">sleap</span><span class="o">.</span><span class="n">instance</span><span class="o">.</span><span class="n">PredictedInstance</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span>
                            <span class="n">points</span><span class="o">=</span><span class="n">pts</span><span class="p">,</span>
                            <span class="n">point_confidences</span><span class="o">=</span><span class="n">confs</span><span class="p">,</span>
                            <span class="n">instance_score</span><span class="o">=</span><span class="n">score</span><span class="p">,</span>
                            <span class="n">skeleton</span><span class="o">=</span><span class="n">skeleton</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span><span class="p">:</span>
                    <span class="c1"># Set tracks for predicted instances in this frame.</span>
                    <span class="n">predicted_instances</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
                        <span class="n">untracked_instances</span><span class="o">=</span><span class="n">predicted_instances</span><span class="p">,</span> <span class="n">img</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">frame_ind</span>
                    <span class="p">)</span>

                <span class="n">predicted_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">sleap</span><span class="o">.</span><span class="n">LabeledFrame</span><span class="p">(</span>
                        <span class="n">video</span><span class="o">=</span><span class="n">data_provider</span><span class="o">.</span><span class="n">videos</span><span class="p">[</span><span class="n">video_ind</span><span class="p">],</span>
                        <span class="n">frame_idx</span><span class="o">=</span><span class="n">frame_ind</span><span class="p">,</span>
                        <span class="n">instances</span><span class="o">=</span><span class="n">predicted_instances</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span><span class="o">.</span><span class="n">final_pass</span><span class="p">(</span><span class="n">predicted_frames</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">predicted_frames</span></div>


<div class="viewcode-block" id="load_model"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.load_model">[docs]</a><span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span>
    <span class="n">model_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">peak_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
    <span class="n">refinement</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;integral&quot;</span><span class="p">,</span>
    <span class="n">tracker</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tracker_window</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="n">tracker_max_instances</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">disable_gpu_preallocation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">progress_reporting</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;rich&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Predictor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Load a trained SLEAP model.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_path: Path to model or list of path to models that were trained by SLEAP.</span>
<span class="sd">            These should be the directories that contain `training_job.json` and</span>
<span class="sd">            `best_model.h5`.</span>
<span class="sd">        batch_size: Number of frames to predict at a time. Larger values result in</span>
<span class="sd">            faster inference speeds, but require more memory.</span>
<span class="sd">        peak_threshold: Minimum confidence map value to consider a peak as valid.</span>
<span class="sd">        refinement: If `&quot;integral&quot;`, peak locations will be refined with integral</span>
<span class="sd">            regression. If `&quot;local&quot;`, peaks will be refined with quarter pixel local</span>
<span class="sd">            gradient offset. This has no effect if the model has an offset regression</span>
<span class="sd">            head.</span>
<span class="sd">        tracker: Name of the tracker to use with the inference model. Must be one of</span>
<span class="sd">            `&quot;simple&quot;` or `&quot;flow&quot;`. If `None`, no identity tracking across frames will</span>
<span class="sd">            be performed.</span>
<span class="sd">        tracker_window: Number of frames of history to use when tracking. No effect when</span>
<span class="sd">            `tracker` is `None`.</span>
<span class="sd">        tracker_max_instances: If not `None`, discard instances beyond this count when</span>
<span class="sd">            tracking. No effect when `tracker` is `None`.</span>
<span class="sd">        disable_gpu_preallocation: If `True` (the default), initialize the GPU and</span>
<span class="sd">            disable preallocation of memory. This is necessary to prevent freezing on</span>
<span class="sd">            some systems with low GPU memory and has negligible impact on performance.</span>
<span class="sd">            If `False`, no GPU initialization is performed. No effect if running in</span>
<span class="sd">            CPU-only mode.</span>
<span class="sd">        progress_reporting: Mode of inference progress reporting. If `&quot;rich&quot;` (the</span>
<span class="sd">            default), an updating progress bar is displayed in the console or notebook.</span>
<span class="sd">            If `&quot;json&quot;`, a JSON-serialized message is printed out which can be captured</span>
<span class="sd">            for programmatic progress monitoring. If `&quot;none&quot;`, nothing is displayed</span>
<span class="sd">            during inference -- this is recommended when running on clusters or headless</span>
<span class="sd">            machines where the output is captured to a log file.</span>

<span class="sd">    Returns:</span>
<span class="sd">        An instance of a `Predictor` based on which model type was detected.</span>

<span class="sd">        If this is a top-down model, paths to the centroids model as well as the</span>
<span class="sd">        centered instance model must be provided. A `TopDownPredictor` instance will be</span>
<span class="sd">        returned.</span>

<span class="sd">        If this is a bottom-up model, a `BottomUpPredictor` will be returned.</span>

<span class="sd">        If this is a single-instance model, a `SingleInstancePredictor` will be</span>
<span class="sd">        returned.</span>

<span class="sd">        If a `tracker` is specified, the predictor will also run identity tracking over</span>
<span class="sd">        time.</span>

<span class="sd">    See also: TopDownPredictor, BottomUpPredictor, SingleInstancePredictor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">model_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_path</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model_paths</span> <span class="o">=</span> <span class="n">model_path</span>

    <span class="c1"># Uncompress ZIP packaged models.</span>
    <span class="n">tmp_dirs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">model_path</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model_paths</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">model_path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.zip&quot;</span><span class="p">):</span>
            <span class="c1"># Create temp dir on demand.</span>
            <span class="n">tmp_dir</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span>
            <span class="n">tmp_dirs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_dir</span><span class="p">)</span>

            <span class="c1"># Remove the temp dir when program exits in case something goes wrong.</span>
            <span class="n">atexit</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">,</span> <span class="n">tmp_dir</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># Extract and replace in the list.</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">unpack_archive</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">extract_dir</span><span class="o">=</span><span class="n">tmp_dir</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="n">model_paths</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_dir</span><span class="o">.</span><span class="n">name</span>

    <span class="k">if</span> <span class="n">disable_gpu_preallocation</span><span class="p">:</span>
        <span class="n">sleap</span><span class="o">.</span><span class="n">disable_preallocation</span><span class="p">()</span>

    <span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="o">.</span><span class="n">from_model_paths</span><span class="p">(</span>
        <span class="n">model_paths</span><span class="p">,</span>
        <span class="n">peak_threshold</span><span class="o">=</span><span class="n">peak_threshold</span><span class="p">,</span>
        <span class="n">integral_refinement</span><span class="o">=</span><span class="n">refinement</span> <span class="o">==</span> <span class="s2">&quot;integral&quot;</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">predictor</span><span class="o">.</span><span class="n">verbosity</span> <span class="o">=</span> <span class="n">progress_reporting</span>
    <span class="k">if</span> <span class="n">tracker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">predictor</span><span class="o">.</span><span class="n">tracker</span> <span class="o">=</span> <span class="n">Tracker</span><span class="o">.</span><span class="n">make_tracker_by_name</span><span class="p">(</span>
            <span class="n">tracker</span><span class="o">=</span><span class="n">tracker</span><span class="p">,</span>
            <span class="n">track_window</span><span class="o">=</span><span class="n">tracker_window</span><span class="p">,</span>
            <span class="n">post_connect_single_breaks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">clean_instance_count</span><span class="o">=</span><span class="n">tracker_max_instances</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Remove temp dirs.</span>
    <span class="k">for</span> <span class="n">tmp_dir</span> <span class="ow">in</span> <span class="n">tmp_dirs</span><span class="p">:</span>
        <span class="n">tmp_dir</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">predictor</span></div>


<span class="k">def</span> <span class="nf">_make_cli_parser</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create argument parser for CLI.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The `argparse.ArgumentParser` that defines the CLI options.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;data_path&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;?&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Path to data to predict on. This can be a labels (.slp) file or any &quot;</span>
            <span class="s2">&quot;supported video format.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;-m&quot;</span><span class="p">,</span>
        <span class="s2">&quot;--model&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;append&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Path to trained model directory (with training_config.json). &quot;</span>
            <span class="s2">&quot;Multiple models can be specified, each preceded by --model.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--frames&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">sleap</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">frame_list</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;List of frames to predict when running on a video. Can be specified as a &quot;</span>
            <span class="s2">&quot;comma separated list (e.g. 1,2,3) or a range separated by hyphen (e.g., &quot;</span>
            <span class="s2">&quot;1-3, for 1,2,3). If not provided, defaults to predicting on the entire &quot;</span>
            <span class="s2">&quot;video.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--only-labeled-frames&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Only run inference on user labeled frames when running on labels dataset. &quot;</span>
            <span class="s2">&quot;This is useful for generating predictions to compare against ground truth.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--only-suggested-frames&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Only run inference on unlabeled suggested frames when running on labels &quot;</span>
            <span class="s2">&quot;dataset. This is useful for generating predictions for initialization &quot;</span>
            <span class="s2">&quot;during labeling.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;-o&quot;</span><span class="p">,</span>
        <span class="s2">&quot;--output&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;The output filename to use for the predicted data. If not provided, &quot;</span>
            <span class="s2">&quot;defaults to &#39;[data_path].predictions.slp&#39;.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-empty-frames&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Clear any empty frames that did not have any detected instances before &quot;</span>
            <span class="s2">&quot;saving to output.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--verbosity&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="s2">&quot;rich&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">],</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;rich&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Verbosity of inference progress reporting. &#39;none&#39; does not output &quot;</span>
            <span class="s2">&quot;anything during inference, &#39;rich&#39; displays an updating progress bar, &quot;</span>
            <span class="s2">&quot;and &#39;json&#39; outputs the progress as a JSON encoded response to the &quot;</span>
            <span class="s2">&quot;console.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--video.dataset&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The dataset for HDF5 videos.&quot;</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--video.input_format&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;channels_last&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The input_format for HDF5 videos.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">device_group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_mutually_exclusive_group</span><span class="p">(</span><span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">device_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--cpu&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Run inference only on CPU. If not specified, will use available GPU.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">device_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--first-gpu&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Run inference on the first GPU, if available.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">device_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--last-gpu&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Run inference on the last GPU, if available.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">device_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--gpu&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Run inference on the i-th GPU specified.&quot;</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--peak_threshold&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Minimum confidence map value to consider a peak as valid.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--batch_size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Number of frames to predict at a time. Larger values result in faster &quot;</span>
            <span class="s2">&quot;inference speeds, but require more memory.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># Deprecated legacy args. These will still be parsed for backward compatibility but</span>
    <span class="c1"># are hidden from the CLI help.</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--labels&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--single.peak_threshold&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--topdown.peak_threshold&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--bottomup.peak_threshold&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--single.batch_size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--topdown.batch_size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--bottomup.batch_size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">SUPPRESS</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Add tracker args.</span>
    <span class="n">Tracker</span><span class="o">.</span><span class="n">add_cli_parser_args</span><span class="p">(</span><span class="n">parser</span><span class="p">,</span> <span class="n">arg_scope</span><span class="o">=</span><span class="s2">&quot;tracking&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_make_provider_from_cli</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Provider</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Make data provider from parsed CLI args.</span>

<span class="sd">    Args:</span>
<span class="sd">        args: Parsed CLI namespace.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tuple of `(provider, data_path)` with the data `Provider` and path to the data</span>
<span class="sd">        that was specified in the args.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Figure out which input path to use.</span>
    <span class="n">labels_path</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">labels_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">data_path</span> <span class="o">=</span> <span class="n">labels_path</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">data_path</span>

    <span class="k">if</span> <span class="n">data_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must specify a path to a video or a labels dataset.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">data_path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.slp&quot;</span><span class="p">):</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">Labels</span><span class="o">.</span><span class="n">load_file</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">only_labeled_frames</span><span class="p">:</span>
            <span class="n">provider</span> <span class="o">=</span> <span class="n">LabelsReader</span><span class="o">.</span><span class="n">from_user_labeled_frames</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">only_suggested_frames</span><span class="p">:</span>
            <span class="n">provider</span> <span class="o">=</span> <span class="n">LabelsReader</span><span class="o">.</span><span class="n">from_unlabeled_suggestions</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">provider</span> <span class="o">=</span> <span class="n">LabelsReader</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># TODO: Clean this up.</span>
        <span class="n">video_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">=</span><span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;video.dataset&quot;</span><span class="p">),</span>
            <span class="n">input_format</span><span class="o">=</span><span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;video.input_format&quot;</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">provider</span> <span class="o">=</span> <span class="n">VideoReader</span><span class="o">.</span><span class="n">from_filepath</span><span class="p">(</span>
            <span class="n">filename</span><span class="o">=</span><span class="n">data_path</span><span class="p">,</span> <span class="n">example_indices</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">frames</span><span class="p">,</span> <span class="o">**</span><span class="n">video_kwargs</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">provider</span><span class="p">,</span> <span class="n">data_path</span>


<span class="k">def</span> <span class="nf">_make_predictor_from_cli</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Predictor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Make predictor from parsed CLI args.</span>

<span class="sd">    Args:</span>
<span class="sd">        args: Parsed CLI namespace.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The `Predictor` created from loaded models.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">peak_threshold</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">deprecated_arg</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="s2">&quot;single.peak_threshold&quot;</span><span class="p">,</span>
        <span class="s2">&quot;topdown.peak_threshold&quot;</span><span class="p">,</span>
        <span class="s2">&quot;bottomup.peak_threshold&quot;</span><span class="p">,</span>
    <span class="p">]:</span>
        <span class="n">val</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">deprecated_arg</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">peak_threshold</span> <span class="o">=</span> <span class="n">val</span>
    <span class="k">if</span> <span class="n">peak_threshold</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">peak_threshold</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">peak_threshold</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">deprecated_arg</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="s2">&quot;single.batch_size&quot;</span><span class="p">,</span>
        <span class="s2">&quot;topdown.batch_size&quot;</span><span class="p">,</span>
        <span class="s2">&quot;bottomup.batch_size&quot;</span><span class="p">,</span>
    <span class="p">]:</span>
        <span class="n">val</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">deprecated_arg</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">val</span>
    <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>

    <span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="o">.</span><span class="n">from_model_paths</span><span class="p">(</span>
        <span class="n">args</span><span class="o">.</span><span class="n">models</span><span class="p">,</span>
        <span class="n">peak_threshold</span><span class="o">=</span><span class="n">peak_threshold</span><span class="p">,</span>
        <span class="n">integral_refinement</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">predictor</span><span class="o">.</span><span class="n">verbosity</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">verbosity</span>
    <span class="k">return</span> <span class="n">predictor</span>


<span class="k">def</span> <span class="nf">_make_tracker_from_cli</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tracker</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Make tracker from parsed CLI arguments.</span>

<span class="sd">    Args:</span>
<span class="sd">        args: Parsed CLI namespace.</span>

<span class="sd">    Returns:</span>
<span class="sd">        An instance of `Tracker` or `None` if tracking method was not specified.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">policy_args</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">make_scoped_dictionary</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">),</span> <span class="n">exclude_nones</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;tracking&quot;</span> <span class="ow">in</span> <span class="n">policy_args</span><span class="p">:</span>
        <span class="n">tracker</span> <span class="o">=</span> <span class="n">Tracker</span><span class="o">.</span><span class="n">make_tracker_by_name</span><span class="p">(</span><span class="o">**</span><span class="n">policy_args</span><span class="p">[</span><span class="s2">&quot;tracking&quot;</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">tracker</span>
    <span class="k">return</span> <span class="kc">None</span>


<div class="viewcode-block" id="main"><a class="viewcode-back" href="../../../_autosummary/sleap.nn.inference.html#sleap.nn.inference.main">[docs]</a><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Entrypoint for `sleap-track` CLI for running inference.&quot;&quot;&quot;</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="n">start_timestamp</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Started inference at:&quot;</span><span class="p">,</span> <span class="n">start_timestamp</span><span class="p">)</span>

    <span class="c1"># Setup CLI.</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_make_cli_parser</span><span class="p">()</span>

    <span class="c1"># Parse inputs.</span>
    <span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>

    <span class="n">args_msg</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Args:&quot;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;frames&quot;</span> <span class="ow">and</span> <span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">args_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  frames: </span><span class="si">{</span><span class="nb">min</span><span class="p">(</span><span class="n">val</span><span class="p">)</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="nb">max</span><span class="p">(</span><span class="n">val</span><span class="p">)</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">args_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args_msg</span><span class="p">))</span>

    <span class="c1"># Setup devices.</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">cpu</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">system</span><span class="o">.</span><span class="n">is_gpu_system</span><span class="p">():</span>
        <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">system</span><span class="o">.</span><span class="n">use_cpu_only</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">first_gpu</span><span class="p">:</span>
            <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">system</span><span class="o">.</span><span class="n">use_first_gpu</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">last_gpu</span><span class="p">:</span>
            <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">system</span><span class="o">.</span><span class="n">use_last_gpu</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">system</span><span class="o">.</span><span class="n">use_gpu</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
    <span class="n">sleap</span><span class="o">.</span><span class="n">disable_preallocation</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Versions:&quot;</span><span class="p">)</span>
    <span class="n">sleap</span><span class="o">.</span><span class="n">versions</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;System:&quot;</span><span class="p">)</span>
    <span class="n">sleap</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">system</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">()</span>

    <span class="c1"># Setup data loader.</span>
    <span class="n">provider</span><span class="p">,</span> <span class="n">data_path</span> <span class="o">=</span> <span class="n">_make_provider_from_cli</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

    <span class="c1"># Setup models.</span>
    <span class="n">predictor</span> <span class="o">=</span> <span class="n">_make_predictor_from_cli</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

    <span class="c1"># Setup tracker.</span>
    <span class="n">tracker</span> <span class="o">=</span> <span class="n">_make_tracker_from_cli</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="n">predictor</span><span class="o">.</span><span class="n">tracker</span> <span class="o">=</span> <span class="n">tracker</span>

    <span class="c1"># Run inference!</span>
    <span class="n">labels_pr</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">provider</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">no_empty_frames</span><span class="p">:</span>
        <span class="c1"># Clear empty frames if specified.</span>
        <span class="n">labels_pr</span><span class="o">.</span><span class="n">remove_empty_frames</span><span class="p">()</span>

    <span class="n">finish_timestamp</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">())</span>
    <span class="n">total_elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Finished inference at:&quot;</span><span class="p">,</span> <span class="n">finish_timestamp</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total runtime: </span><span class="si">{</span><span class="n">total_elapsed</span><span class="si">}</span><span class="s2"> secs&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted frames: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">labels_pr</span><span class="p">)</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">provider</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">output_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">output</span>
    <span class="k">if</span> <span class="n">output_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output_path</span> <span class="o">=</span> <span class="n">data_path</span> <span class="o">+</span> <span class="s2">&quot;.predictions.slp&quot;</span>

    <span class="c1"># Add provenance metadata to predictions.</span>
    <span class="n">labels_pr</span><span class="o">.</span><span class="n">provenance</span><span class="p">[</span><span class="s2">&quot;sleap_version&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sleap</span><span class="o">.</span><span class="n">__version__</span>
    <span class="n">labels_pr</span><span class="o">.</span><span class="n">provenance</span><span class="p">[</span><span class="s2">&quot;platform&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">platform</span><span class="p">()</span>
    <span class="n">labels_pr</span><span class="o">.</span><span class="n">provenance</span><span class="p">[</span><span class="s2">&quot;data_path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_path</span>
    <span class="n">labels_pr</span><span class="o">.</span><span class="n">provenance</span><span class="p">[</span><span class="s2">&quot;model_paths&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">model_paths</span>
    <span class="n">labels_pr</span><span class="o">.</span><span class="n">provenance</span><span class="p">[</span><span class="s2">&quot;output_path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_path</span>
    <span class="n">labels_pr</span><span class="o">.</span><span class="n">provenance</span><span class="p">[</span><span class="s2">&quot;predictor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">predictor</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="n">labels_pr</span><span class="o">.</span><span class="n">provenance</span><span class="p">[</span><span class="s2">&quot;total_elapsed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">total_elapsed</span>
    <span class="n">labels_pr</span><span class="o">.</span><span class="n">provenance</span><span class="p">[</span><span class="s2">&quot;start_timestamp&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">start_timestamp</span>
    <span class="n">labels_pr</span><span class="o">.</span><span class="n">provenance</span><span class="p">[</span><span class="s2">&quot;finish_timestamp&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">finish_timestamp</span>

    <span class="c1"># Save results.</span>
    <span class="n">labels_pr</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saved output:&quot;</span><span class="p">,</span> <span class="n">output_path</span><span class="p">)</span></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">SLEAP</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../guides/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guides/index.html">Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guides/reference.html">Feature Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">API</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019–2020, Murthy Lab @ Princeton.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.4.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>