
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Training &#8212; SLEAP  documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Inference" href="inference.html" />
    <link rel="prev" title="sleap.io.video" href="video.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="training">
<h1>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-sleap.nn.training">
<span id="sleap-nn-training"></span><h2>sleap.nn.training<a class="headerlink" href="#module-sleap.nn.training" title="Permalink to this headline">¶</a></h2>
<p>SLEAP model training.</p>
<dl class="class">
<dt id="sleap.nn.training.NodeLoss">
<em class="property">class </em><code class="sig-prename descclassname">sleap.nn.training.</code><code class="sig-name descname">NodeLoss</code><span class="sig-paren">(</span><em class="sig-param">node_ind</em>, <em class="sig-param">name='node_loss'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/training.html#NodeLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.training.NodeLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute node-specific loss.</p>
<p>Useful for monitoring the MSE for specific body parts (channels).</p>
<dl class="attribute">
<dt id="sleap.nn.training.NodeLoss.node_ind">
<code class="sig-name descname">node_ind</code><a class="headerlink" href="#sleap.nn.training.NodeLoss.node_ind" title="Permalink to this definition">¶</a></dt>
<dd><p>Index of channel to compute MSE for.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.training.NodeLoss.name">
<code class="sig-name descname">name</code><a class="headerlink" href="#sleap.nn.training.NodeLoss.name" title="Permalink to this definition">¶</a></dt>
<dd><p>Name of the loss tensor.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.training.NodeLoss.result">
<code class="sig-name descname">result</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/training.html#NodeLoss.result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.training.NodeLoss.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes and returns the metric value tensor.</p>
<p>Result computation is an idempotent operation that simply calculates the
metric value using the state variables.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.training.NodeLoss.update_state">
<code class="sig-name descname">update_state</code><span class="sig-paren">(</span><em class="sig-param">y_gt</em>, <em class="sig-param">y_pr</em>, <em class="sig-param">sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/training.html#NodeLoss.update_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.training.NodeLoss.update_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Accumulates statistics for the metric.</p>
<p>Note: This function is executed as a graph function in graph mode.
This means:</p>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Operations on the same resource are executed in textual order.
This should make it easier to do things like add the updated
value of a variable to another, for example.</p></li>
<li><p>You don’t need to worry about collecting the update ops to execute.
All update ops added to the graph by this function will be executed.</p></li>
</ol>
<p>As a result, code should generally work the same way with graph or
eager execution.</p>
</div></blockquote>
<p>Please use <cite>tf.config.experimental_run_functions_eagerly(True)</cite> to execute
this function eagerly for debugging or profiling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – </p></li>
<li><p><strong>**kwargs</strong> – A mini-batch of inputs to the Metric.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="sleap.nn.training.OHKMLoss">
<em class="property">class </em><code class="sig-prename descclassname">sleap.nn.training.</code><code class="sig-name descname">OHKMLoss</code><span class="sig-paren">(</span><em class="sig-param">K=2</em>, <em class="sig-param">weight=5</em>, <em class="sig-param">name='ohkm'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/training.html#OHKMLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.training.OHKMLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Online hard keypoint mining loss.</p>
<p>This loss serves to dynamically reweight the MSE of the top-K worst channels in each
batch. This is useful when fine tuning a model to improve performance on a hard
part to optimize for (e.g., small, hard to see, often not visible).</p>
<p>Note: This works with any type of channel, so it can work for PAFs as well.</p>
<dl class="attribute">
<dt id="sleap.nn.training.OHKMLoss.K">
<code class="sig-name descname">K</code><a class="headerlink" href="#sleap.nn.training.OHKMLoss.K" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of worst performing channels to compute loss for.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.training.OHKMLoss.weight">
<code class="sig-name descname">weight</code><a class="headerlink" href="#sleap.nn.training.OHKMLoss.weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Scalar factor to multiply with the MSE for the top-K worst channels.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.training.OHKMLoss.name">
<code class="sig-name descname">name</code><a class="headerlink" href="#sleap.nn.training.OHKMLoss.name" title="Permalink to this definition">¶</a></dt>
<dd><p>Name of the loss tensor.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="sleap.nn.training.main">
<code class="sig-prename descclassname">sleap.nn.training.</code><code class="sig-name descname">main</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/training.html#main"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.training.main" title="Permalink to this definition">¶</a></dt>
<dd><p>CLI for training.</p>
</dd></dl>

</div>
<div class="section" id="module-sleap.nn.architectures.hourglass">
<span id="sleap-nn-architectures"></span><h2>sleap.nn.architectures<a class="headerlink" href="#module-sleap.nn.architectures.hourglass" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="sleap.nn.architectures.hourglass.StackedHourglass">
<em class="property">class </em><code class="sig-prename descclassname">sleap.nn.architectures.hourglass.</code><code class="sig-name descname">StackedHourglass</code><span class="sig-paren">(</span><em class="sig-param">num_stacks: int = 3</em>, <em class="sig-param">num_filters: int = 32</em>, <em class="sig-param">depth: int = 3</em>, <em class="sig-param">batch_norm: bool = True</em>, <em class="sig-param">intermediate_inputs: bool = True</em>, <em class="sig-param">upsampling_layers: bool = True</em>, <em class="sig-param">interp: str = 'bilinear'</em>, <em class="sig-param">initial_stride: int = 1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/hourglass.html#StackedHourglass"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.hourglass.StackedHourglass" title="Permalink to this definition">¶</a></dt>
<dd><p>Stacked hourglass block.</p>
<p>This function builds and connects multiple hourglass blocks. See <cite>hourglass</cite> for
more specifics on the implementation.</p>
<p>Individual hourglasses can be customized by providing an iterable of hyperparameters
for each of the arguments of the function (except <cite>num_output_channels</cite>). If scalars
are provided, all hourglasses will share the same hyperparameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. If the number of channels
are not the same as <cite>num_filters</cite>, an additional residual block is
applied to this input.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
<li><p><strong>num_filters</strong> – The number feature channels of the block. These features are
used throughout the hourglass and will be passed on to the next block
and need not match the <cite>num_output_channels</cite>. Must be divisible by 2.</p></li>
<li><p><strong>depth</strong> – The number of pooling steps applied to the input. The input must
be a tensor with <cite>2^depth</cite> height and width to allow for symmetric
pooling and upsampling with skip connections.</p></li>
<li><p><strong>batch_norm</strong> – Apply batch normalization after each convolution</p></li>
<li><p><strong>intermediate_inputs</strong> – Re-introduce the input tensor <cite>x_in</cite> after each hourglass
by concatenating with intermediate outputs</p></li>
<li><p><strong>upsampling_layers</strong> – Use upsampling instead of transposed convolutions.</p></li>
<li><p><strong>interp</strong> – Method to use for interpolation when upsampling smaller features.</p></li>
<li><p><strong>initial_stride</strong> – Stride of first convolution to use for reducing input resolution.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="sleap.nn.architectures.hourglass.StackedHourglass.output">
<code class="sig-name descname">output</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/hourglass.html#StackedHourglass.output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.hourglass.StackedHourglass.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a tensorflow graph for the backbone and return the output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width</p></li>
<li><p><strong>are divisible by `2^down_blocks.</strong> (<em>that</em>) – </p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These</p></li>
<li><p><strong>the final output tensors on which intermediate supervision may be</strong> (<em>are</em>) – </p></li>
<li><p><strong>applied.</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tf.Tensor of the output of the block of with <cite>num_output_channels</cite> channels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.hourglass.hourglass_block">
<code class="sig-prename descclassname">sleap.nn.architectures.hourglass.</code><code class="sig-name descname">hourglass_block</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em>, <em class="sig-param">num_filters</em>, <em class="sig-param">depth=3</em>, <em class="sig-param">batch_norm=True</em>, <em class="sig-param">upsampling_layers=True</em>, <em class="sig-param">interp='bilinear'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/hourglass.html#hourglass_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.hourglass.hourglass_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a single hourglass block.</p>
<p>This function builds an hourglass block from residual blocks and max pooling.</p>
<p>The hourglass is defined as a set of <cite>depth</cite> residual blocks followed by 2-strided
max pooling for downsampling, then an intermediate residual block, followed by
<cite>depth</cite> blocks of upsampling -&gt; skip Add -&gt; residual blocks.</p>
<p>The output tensors are then produced by linear activation with 1x1 convs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have <cite>num_filters</cite>
channels since the hourglass adds a residual to this input.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
<li><p><strong>num_filters</strong> – The number feature channels of the block. These features are
used throughout the hourglass and will be passed on to the next block
and need not match the <cite>num_output_channels</cite>. Must be divisible by 2.</p></li>
<li><p><strong>depth</strong> – The number of pooling steps applied to the input. The input must
be a tensor with <cite>2^depth</cite> height and width to allow for symmetric
pooling and upsampling with skip connections.</p></li>
<li><p><strong>batch_norm</strong> – Apply batch normalization after each convolution</p></li>
<li><p><strong>upsampling_layers</strong> – Use upsampling instead of transposed convolutions.</p></li>
<li><p><strong>interp</strong> – Method to use for interpolation when upsampling smaller features.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>tf.Tensor of the features output by the block with <cite>num_filters</cite></dt><dd><p>channels. This tensor can be passed on to the next hourglass or
ignored if this is the last hourglass.</p>
</dd>
<dt>x_out: tf.Tensor of the output of the block of the same width and height</dt><dd><p>as the input with <cite>num_output_channels</cite> channels.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.hourglass.stacked_hourglass">
<code class="sig-prename descclassname">sleap.nn.architectures.hourglass.</code><code class="sig-name descname">stacked_hourglass</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em>, <em class="sig-param">num_stacks=3</em>, <em class="sig-param">num_filters=32</em>, <em class="sig-param">depth=3</em>, <em class="sig-param">batch_norm=True</em>, <em class="sig-param">intermediate_inputs=True</em>, <em class="sig-param">upsampling_layers=True</em>, <em class="sig-param">interp='bilinear'</em>, <em class="sig-param">initial_stride=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/hourglass.html#stacked_hourglass"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.hourglass.stacked_hourglass" title="Permalink to this definition">¶</a></dt>
<dd><p>Stacked hourglass block.</p>
<p>This function builds and connects multiple hourglass blocks. See <cite>hourglass</cite> for
more specifics on the implementation.</p>
<p>Individual hourglasses can be customized by providing an iterable of hyperparameters
for each of the arguments of the function (except <cite>num_output_channels</cite>). If scalars
are provided, all hourglasses will share the same hyperparameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. If the number of channels
are not the same as <cite>num_filters</cite>, an additional residual block is
applied to this input.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
<li><p><strong>num_filters</strong> – The number feature channels of the block. These features are
used throughout the hourglass and will be passed on to the next block
and need not match the <cite>num_output_channels</cite>. Must be divisible by 2.</p></li>
<li><p><strong>depth</strong> – The number of pooling steps applied to the input. The input must
be a tensor with <cite>2^depth</cite> height and width to allow for symmetric
pooling and upsampling with skip connections.</p></li>
<li><p><strong>batch_norm</strong> – Apply batch normalization after each convolution</p></li>
<li><p><strong>intermediate_inputs</strong> – Re-introduce the input tensor <cite>x_in</cite> after each hourglass
by concatenating with intermediate outputs</p></li>
<li><p><strong>upsampling_layers</strong> – Use upsampling instead of transposed convolutions.</p></li>
<li><p><strong>interp</strong> – Method to use for interpolation when upsampling smaller features.</p></li>
<li><p><strong>initial_stride</strong> – Stride of first convolution to use for reducing input resolution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of tf.Tensors of the output of the block of the same width and height</dt><dd><p>as the input with <cite>num_output_channels</cite> channels.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_outs</p>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-sleap.nn.architectures.densenet"></span><p>Implements wrappers for constructing (optionally pretrained) DenseNets.</p>
<p>See original paper:
<a class="reference external" href="https://arxiv.org/abs/1608.06993">https://arxiv.org/abs/1608.06993</a></p>
<dl class="class">
<dt id="sleap.nn.architectures.densenet.DenseNet121">
<em class="property">class </em><code class="sig-prename descclassname">sleap.nn.architectures.densenet.</code><code class="sig-name descname">DenseNet121</code><span class="sig-paren">(</span><em class="sig-param">upsampling_layers: bool = True</em>, <em class="sig-param">interp: str = 'bilinear'</em>, <em class="sig-param">up_blocks: int = 5</em>, <em class="sig-param">refine_conv_up: bool = False</em>, <em class="sig-param">pretrained: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/densenet.html#DenseNet121"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet121" title="Permalink to this definition">¶</a></dt>
<dd><p>DenseNet121 backbone.</p>
<p>This backbone has ~7M params.</p>
<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet121.upsampling_layers">
<code class="sig-name descname">upsampling_layers</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet121.upsampling_layers" title="Permalink to this definition">¶</a></dt>
<dd><p>Use upsampling instead of transposed convolutions.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet121.interp">
<code class="sig-name descname">interp</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet121.interp" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to use for interpolation when upsampling smaller features.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet121.up_blocks">
<code class="sig-name descname">up_blocks</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet121.up_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of upsampling steps to perform. The backbone reduces
the output scale by 1/32. If set to 5, outputs will be upsampled to the
input resolution.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet121.refine_conv_up">
<code class="sig-name descname">refine_conv_up</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet121.refine_conv_up" title="Permalink to this definition">¶</a></dt>
<dd><p>If true, applies a 1x1 conv after each upsampling step.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet121.pretrained">
<code class="sig-name descname">pretrained</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet121.pretrained" title="Permalink to this definition">¶</a></dt>
<dd><p>Load pretrained ImageNet weights for transfer learning. If
False, random weights are used for initialization.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.DenseNet121.down_blocks">
<em class="property">property </em><code class="sig-name descname">down_blocks</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet121.down_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of downsampling steps in the model.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.DenseNet121.output">
<code class="sig-name descname">output</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/densenet.html#DenseNet121.output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet121.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the layers for this backbone and return the output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width
that are divisible by <a href="#id3"><span class="problematic" id="id4">`</span></a>2^down_blocks.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tf.Tensor of the output of the block of with <cite>num_output_channels</cite> channels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.DenseNet121.output_scale">
<em class="property">property </em><code class="sig-name descname">output_scale</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet121.output_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns relative scaling factor of this backbone.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="sleap.nn.architectures.densenet.DenseNet169">
<em class="property">class </em><code class="sig-prename descclassname">sleap.nn.architectures.densenet.</code><code class="sig-name descname">DenseNet169</code><span class="sig-paren">(</span><em class="sig-param">upsampling_layers: bool = True</em>, <em class="sig-param">interp: str = 'bilinear'</em>, <em class="sig-param">up_blocks: int = 5</em>, <em class="sig-param">refine_conv_up: bool = False</em>, <em class="sig-param">pretrained: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/densenet.html#DenseNet169"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet169" title="Permalink to this definition">¶</a></dt>
<dd><p>DenseNet169 backbone.</p>
<p>This backbone has ~12.6M params.</p>
<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet169.upsampling_layers">
<code class="sig-name descname">upsampling_layers</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet169.upsampling_layers" title="Permalink to this definition">¶</a></dt>
<dd><p>Use upsampling instead of transposed convolutions.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet169.interp">
<code class="sig-name descname">interp</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet169.interp" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to use for interpolation when upsampling smaller features.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet169.up_blocks">
<code class="sig-name descname">up_blocks</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet169.up_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of upsampling steps to perform. The backbone reduces
the output scale by 1/32. If set to 5, outputs will be upsampled to the
input resolution.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet169.refine_conv_up">
<code class="sig-name descname">refine_conv_up</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet169.refine_conv_up" title="Permalink to this definition">¶</a></dt>
<dd><p>If true, applies a 1x1 conv after each upsampling step.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet169.pretrained">
<code class="sig-name descname">pretrained</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet169.pretrained" title="Permalink to this definition">¶</a></dt>
<dd><p>Load pretrained ImageNet weights for transfer learning. If
False, random weights are used for initialization.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.DenseNet169.down_blocks">
<em class="property">property </em><code class="sig-name descname">down_blocks</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet169.down_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of downsampling steps in the model.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.DenseNet169.output">
<code class="sig-name descname">output</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/densenet.html#DenseNet169.output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet169.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the layers for this backbone and return the output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width
that are divisible by <a href="#id5"><span class="problematic" id="id6">`</span></a>2^down_blocks.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tf.Tensor of the output of the block of with <cite>num_output_channels</cite> channels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.DenseNet169.output_scale">
<em class="property">property </em><code class="sig-name descname">output_scale</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet169.output_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns relative scaling factor of this backbone.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="sleap.nn.architectures.densenet.DenseNet201">
<em class="property">class </em><code class="sig-prename descclassname">sleap.nn.architectures.densenet.</code><code class="sig-name descname">DenseNet201</code><span class="sig-paren">(</span><em class="sig-param">upsampling_layers: bool = True</em>, <em class="sig-param">interp: str = 'bilinear'</em>, <em class="sig-param">up_blocks: int = 5</em>, <em class="sig-param">refine_conv_up: bool = False</em>, <em class="sig-param">pretrained: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/densenet.html#DenseNet201"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet201" title="Permalink to this definition">¶</a></dt>
<dd><p>DenseNet201 backbone.</p>
<p>This backbone has ~18.3M params.</p>
<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet201.upsampling_layers">
<code class="sig-name descname">upsampling_layers</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet201.upsampling_layers" title="Permalink to this definition">¶</a></dt>
<dd><p>Use upsampling instead of transposed convolutions.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet201.interp">
<code class="sig-name descname">interp</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet201.interp" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to use for interpolation when upsampling smaller features.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet201.up_blocks">
<code class="sig-name descname">up_blocks</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet201.up_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of upsampling steps to perform. The backbone reduces
the output scale by 1/32. If set to 5, outputs will be upsampled to the
input resolution.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet201.refine_conv_up">
<code class="sig-name descname">refine_conv_up</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet201.refine_conv_up" title="Permalink to this definition">¶</a></dt>
<dd><p>If true, applies a 1x1 conv after each upsampling step.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.DenseNet201.pretrained">
<code class="sig-name descname">pretrained</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet201.pretrained" title="Permalink to this definition">¶</a></dt>
<dd><p>Load pretrained ImageNet weights for transfer learning. If
False, random weights are used for initialization.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.DenseNet201.down_blocks">
<em class="property">property </em><code class="sig-name descname">down_blocks</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet201.down_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of downsampling steps in the model.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.DenseNet201.output">
<code class="sig-name descname">output</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/densenet.html#DenseNet201.output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet201.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the layers for this backbone and return the output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width
that are divisible by <a href="#id7"><span class="problematic" id="id8">`</span></a>2^down_blocks.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tf.Tensor of the output of the block of with <cite>num_output_channels</cite> channels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.DenseNet201.output_scale">
<em class="property">property </em><code class="sig-name descname">output_scale</code><a class="headerlink" href="#sleap.nn.architectures.densenet.DenseNet201.output_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns relative scaling factor of this backbone.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet">
<em class="property">class </em><code class="sig-prename descclassname">sleap.nn.architectures.densenet.</code><code class="sig-name descname">GeneralizedDenseNet</code><span class="sig-paren">(</span><em class="sig-param">n_dense_blocks_1: int = 3</em>, <em class="sig-param">n_dense_blocks_2: int = 6</em>, <em class="sig-param">n_dense_blocks_3: int = 12</em>, <em class="sig-param">n_dense_blocks_4: int = 8</em>, <em class="sig-param">upsampling_layers: bool = True</em>, <em class="sig-param">interp: str = 'bilinear'</em>, <em class="sig-param">up_blocks: int = 5</em>, <em class="sig-param">refine_conv_up: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/densenet.html#GeneralizedDenseNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Generalized version of the 4-block DenseNet backbone.</p>
<p>This allows for selecting the number of blocks in each dense layer, but cannot use
pretrained weights since the configuration may not have been previously used.</p>
<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet.n_dense_blocks_1">
<code class="sig-name descname">n_dense_blocks_1</code><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet.n_dense_blocks_1" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of blocks in dense layer 1.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet.n_dense_blocks_2">
<code class="sig-name descname">n_dense_blocks_2</code><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet.n_dense_blocks_2" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of blocks in dense layer 2.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet.n_dense_blocks_3">
<code class="sig-name descname">n_dense_blocks_3</code><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet.n_dense_blocks_3" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of blocks in dense layer 3.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet.n_dense_blocks_4">
<code class="sig-name descname">n_dense_blocks_4</code><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet.n_dense_blocks_4" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of blocks in dense layer 4.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet.upsampling_layers">
<code class="sig-name descname">upsampling_layers</code><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet.upsampling_layers" title="Permalink to this definition">¶</a></dt>
<dd><p>Use upsampling instead of transposed convolutions.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet.interp">
<code class="sig-name descname">interp</code><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet.interp" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to use for interpolation when upsampling smaller features.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet.up_blocks">
<code class="sig-name descname">up_blocks</code><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet.up_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of upsampling steps to perform. The backbone reduces
the output scale by 1/32. If set to 5, outputs will be upsampled to the
input resolution.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet.refine_conv_up">
<code class="sig-name descname">refine_conv_up</code><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet.refine_conv_up" title="Permalink to this definition">¶</a></dt>
<dd><p>If true, applies a 1x1 conv after each upsampling step.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet.down_blocks">
<em class="property">property </em><code class="sig-name descname">down_blocks</code><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet.down_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of downsampling steps in the model.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet.output">
<code class="sig-name descname">output</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/densenet.html#GeneralizedDenseNet.output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the layers for this backbone and return the output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width
that are divisible by <a href="#id9"><span class="problematic" id="id10">`</span></a>2^down_blocks.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tf.Tensor of the output of the block of with <cite>num_output_channels</cite> channels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.GeneralizedDenseNet.output_scale">
<em class="property">property </em><code class="sig-name descname">output_scale</code><a class="headerlink" href="#sleap.nn.architectures.densenet.GeneralizedDenseNet.output_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns relative scaling factor of this backbone.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="sleap.nn.architectures.densenet.UDenseNet">
<em class="property">class </em><code class="sig-prename descclassname">sleap.nn.architectures.densenet.</code><code class="sig-name descname">UDenseNet</code><span class="sig-paren">(</span><em class="sig-param">stem_stride: int = 1, stem_filters: int = 64, dense_blocks: List[int] = [2, 4, 6, 8], output_scale: Union[float, List[float]] = 1.0, n_heads: int = 1, head_filters: Union[int, List[int]] = 64</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/densenet.html#UDenseNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.densenet.UDenseNet" title="Permalink to this definition">¶</a></dt>
<dd><p>UDenseNet backbone, a UNet-like architecture with skip connections to heads.</p>
<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.UDenseNet.stem_stride">
<code class="sig-name descname">stem_stride</code><a class="headerlink" href="#sleap.nn.architectures.densenet.UDenseNet.stem_stride" title="Permalink to this definition">¶</a></dt>
<dd><p>Initial downsampling stride in the stem block.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.UDenseNet.stem_filters">
<code class="sig-name descname">stem_filters</code><a class="headerlink" href="#sleap.nn.architectures.densenet.UDenseNet.stem_filters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initial number of conv filters in the stem block.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.UDenseNet.dense_blocks">
<code class="sig-name descname">dense_blocks</code><a class="headerlink" href="#sleap.nn.architectures.densenet.UDenseNet.dense_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>List of integers defining the size of each dense block. Can be of
any length &gt; 0.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.UDenseNet.output_scale">
<code class="sig-name descname">output_scale</code><a class="headerlink" href="#sleap.nn.architectures.densenet.UDenseNet.output_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale of the output tensor relative to the input.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.UDenseNet.n_heads">
<code class="sig-name descname">n_heads</code><a class="headerlink" href="#sleap.nn.architectures.densenet.UDenseNet.n_heads" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of heads to produce. Intermediate heads will pass features from
every scale to the next head, starting from the first backbone with dense
blocks and transitions.</p>
</dd></dl>

<dl class="attribute">
<dt id="sleap.nn.architectures.densenet.UDenseNet.head_filters">
<code class="sig-name descname">head_filters</code><a class="headerlink" href="#sleap.nn.architectures.densenet.UDenseNet.head_filters" title="Permalink to this definition">¶</a></dt>
<dd><p>Filters to use in each head block after concatenation with
previous filters.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.UDenseNet.down_blocks">
<em class="property">property </em><code class="sig-name descname">down_blocks</code><a class="headerlink" href="#sleap.nn.architectures.densenet.UDenseNet.down_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of downsampling steps in the model.</p>
</dd></dl>

<dl class="method">
<dt id="sleap.nn.architectures.densenet.UDenseNet.output">
<code class="sig-name descname">output</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">n_output_channels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/densenet.html#UDenseNet.output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.densenet.UDenseNet.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the layers for this backbone and return the output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor.</p></li>
<li><p><strong>n_output_channels</strong> – Number of output channels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tf.keras.Model with as many outputs as the n_heads attribute for this</dt><dd><p>model.</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="module-sleap.nn.architectures.leap"></span><dl class="class">
<dt id="sleap.nn.architectures.leap.LeapCNN">
<em class="property">class </em><code class="sig-prename descclassname">sleap.nn.architectures.leap.</code><code class="sig-name descname">LeapCNN</code><span class="sig-paren">(</span><em class="sig-param">down_blocks: int = 3</em>, <em class="sig-param">up_blocks: int = 3</em>, <em class="sig-param">upsampling_layers: int = True</em>, <em class="sig-param">num_filters: int = 64</em>, <em class="sig-param">interp: str = 'bilinear'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/leap.html#LeapCNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.leap.LeapCNN" title="Permalink to this definition">¶</a></dt>
<dd><p>LEAP CNN block.</p>
<p>Implementation generalized from original paper (<a class="reference external" href="https://www.nature.com/articles/s41592-018-0234-5">Pereira et al., 2019</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width
that are divisible by <cite>2^down_blocks</cite>.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
<li><p><strong>down_blocks</strong> – The number of pooling steps applied to the input. The input
must be a tensor with <cite>2^down_blocks</cite> height and width.</p></li>
<li><p><strong>up_blocks</strong> – The number of upsampling steps applied after downsampling.</p></li>
<li><p><strong>upsampling_layers</strong> – If True, use upsampling instead of transposed convs.</p></li>
<li><p><strong>num_filters</strong> – The base number feature channels of the block. The number of
filters is doubled at each pooling step.</p></li>
<li><p><strong>interp</strong> – Method to use for interpolation when upsampling smaller features.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="sleap.nn.architectures.leap.LeapCNN.output">
<code class="sig-name descname">output</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/leap.html#LeapCNN.output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.leap.LeapCNN.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a tensorflow graph for the backbone and return the output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width</p></li>
<li><p><strong>are divisible by `2^down_blocks.</strong> (<em>that</em>) – </p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These</p></li>
<li><p><strong>the final output tensors on which intermediate supervision may be</strong> (<em>are</em>) – </p></li>
<li><p><strong>applied.</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tf.Tensor of the output of the block of with <cite>num_output_channels</cite> channels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.leap.leap_cnn">
<code class="sig-prename descclassname">sleap.nn.architectures.leap.</code><code class="sig-name descname">leap_cnn</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em>, <em class="sig-param">down_blocks=3</em>, <em class="sig-param">up_blocks=3</em>, <em class="sig-param">upsampling_layers=True</em>, <em class="sig-param">num_filters=64</em>, <em class="sig-param">interp='bilinear'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/leap.html#leap_cnn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.leap.leap_cnn" title="Permalink to this definition">¶</a></dt>
<dd><p>LEAP CNN block.</p>
<p>Implementation generalized from original paper (<a class="reference external" href="https://www.nature.com/articles/s41592-018-0234-5">Pereira et al., 2019</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width
that are divisible by <cite>2^down_blocks</cite>.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
<li><p><strong>down_blocks</strong> – The number of pooling steps applied to the input. The input
must be a tensor with <cite>2^down_blocks</cite> height and width.</p></li>
<li><p><strong>up_blocks</strong> – The number of upsampling steps applied after downsampling.</p></li>
<li><p><strong>upsampling_layers</strong> – If True, use upsampling instead of transposed convs.</p></li>
<li><p><strong>num_filters</strong> – The base number feature channels of the block. The number of
filters is doubled at each pooling step.</p></li>
<li><p><strong>interp</strong> – Method to use for interpolation when upsampling smaller features.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tf.Tensor of the output of the block of with <cite>num_output_channels</cite> channels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_out</p>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-sleap.nn.architectures.unet"></span><dl class="class">
<dt id="sleap.nn.architectures.unet.StackedUNet">
<em class="property">class </em><code class="sig-prename descclassname">sleap.nn.architectures.unet.</code><code class="sig-name descname">StackedUNet</code><span class="sig-paren">(</span><em class="sig-param">num_stacks: int = 3</em>, <em class="sig-param">depth: int = 3</em>, <em class="sig-param">convs_per_depth: int = 2</em>, <em class="sig-param">num_filters: int = 16</em>, <em class="sig-param">kernel_size: int = 5</em>, <em class="sig-param">upsampling_layers: bool = True</em>, <em class="sig-param">intermediate_inputs: bool = True</em>, <em class="sig-param">interp: str = 'bilinear'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/unet.html#StackedUNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.unet.StackedUNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Stacked U-net block.</p>
<p>See <cite>unet</cite> for more specifics on the implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width
that are divisible by <cite>2^depth</cite>.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
<li><p><strong>num_stacks</strong> – The number of blocks to stack on top of each other.</p></li>
<li><p><strong>depth</strong> – The number of pooling steps applied to the input. The input must
be a tensor with <cite>2^depth</cite> height and width to allow for symmetric
pooling and upsampling with skip connections.</p></li>
<li><p><strong>convs_per_depth</strong> – The number of convolutions applied before pooling or
after upsampling.</p></li>
<li><p><strong>num_filters</strong> – The base number feature channels of the block. The number of
filters is doubled at each pooling step.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolutional kernels for each filter.</p></li>
<li><p><strong>intermediate_inputs</strong> – Re-introduce the input tensor <cite>x_in</cite> after each block
by concatenating with intermediate outputs</p></li>
<li><p><strong>upsampling_layers</strong> – Use upsampling instead of transposed convolutions.</p></li>
<li><p><strong>interp</strong> – Method to use for interpolation when upsampling smaller features.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="sleap.nn.architectures.unet.StackedUNet.output">
<code class="sig-name descname">output</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/unet.html#StackedUNet.output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.unet.StackedUNet.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a tensorflow graph for the backbone and return the output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width</p></li>
<li><p><strong>are divisible by `2^down_blocks.</strong> (<em>that</em>) – </p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These</p></li>
<li><p><strong>the final output tensors on which intermediate supervision may be</strong> (<em>are</em>) – </p></li>
<li><p><strong>applied.</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tf.Tensor of the output of the block of with <cite>num_output_channels</cite> channels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="sleap.nn.architectures.unet.UNet">
<em class="property">class </em><code class="sig-prename descclassname">sleap.nn.architectures.unet.</code><code class="sig-name descname">UNet</code><span class="sig-paren">(</span><em class="sig-param">down_blocks: int = 3</em>, <em class="sig-param">up_blocks: int = 3</em>, <em class="sig-param">convs_per_depth: int = 2</em>, <em class="sig-param">num_filters: int = 16</em>, <em class="sig-param">kernel_size: int = 5</em>, <em class="sig-param">upsampling_layers: bool = True</em>, <em class="sig-param">interp: str = 'bilinear'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/unet.html#UNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.unet.UNet" title="Permalink to this definition">¶</a></dt>
<dd><p>U-net block.</p>
<p>Implementation based off of <a class="reference external" href="https://github.com/CSBDeep/CSBDeep/blob/master/csbdeep/internals/nets.py">CARE</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width
that are divisible by <cite>2^depth</cite>.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
<li><p><strong>down_blocks</strong> – The number of pooling steps applied to the input. The input
must be a tensor with <cite>2^depth</cite> height and width to allow for
symmetric pooling and upsampling with skip connections.</p></li>
<li><p><strong>up_blocks</strong> – The number of upsampling steps applied after downsampling.</p></li>
<li><p><strong>convs_per_depth</strong> – The number of convolutions applied before pooling or
after upsampling.</p></li>
<li><p><strong>num_filters</strong> – The base number feature channels of the block. The number of
filters is doubled at each pooling step.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolutional kernels for each filter.</p></li>
<li><p><strong>upsampling_layers</strong> – Use upsampling instead of transposed convolutions.</p></li>
<li><p><strong>interp</strong> – Method to use for interpolation when upsampling smaller features.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="sleap.nn.architectures.unet.UNet.output">
<code class="sig-name descname">output</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/unet.html#UNet.output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.unet.UNet.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a tensorflow graph for the backbone and return the output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width</p></li>
<li><p><strong>are divisible by `2^down_blocks.</strong> (<em>that</em>) – </p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These</p></li>
<li><p><strong>the final output tensors on which intermediate supervision may be</strong> (<em>are</em>) – </p></li>
<li><p><strong>applied.</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tf.Tensor of the output of the block of with <cite>num_output_channels</cite> channels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.unet.stacked_unet">
<code class="sig-prename descclassname">sleap.nn.architectures.unet.</code><code class="sig-name descname">stacked_unet</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em>, <em class="sig-param">num_stacks=3</em>, <em class="sig-param">depth=3</em>, <em class="sig-param">convs_per_depth=2</em>, <em class="sig-param">num_filters=16</em>, <em class="sig-param">kernel_size=5</em>, <em class="sig-param">upsampling_layers=True</em>, <em class="sig-param">intermediate_inputs=True</em>, <em class="sig-param">interp='bilinear'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/unet.html#stacked_unet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.unet.stacked_unet" title="Permalink to this definition">¶</a></dt>
<dd><p>Stacked U-net block.</p>
<p>See <cite>unet</cite> for more specifics on the implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width
that are divisible by <cite>2^depth</cite>.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
<li><p><strong>num_stacks</strong> – The number of blocks to stack on top of each other.</p></li>
<li><p><strong>depth</strong> – The number of pooling steps applied to the input. The input must
be a tensor with <cite>2^depth</cite> height and width to allow for symmetric
pooling and upsampling with skip connections.</p></li>
<li><p><strong>convs_per_depth</strong> – The number of convolutions applied before pooling or
after upsampling.</p></li>
<li><p><strong>num_filters</strong> – The base number feature channels of the block. The number of
filters is doubled at each pooling step.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolutional kernels for each filter.</p></li>
<li><p><strong>intermediate_inputs</strong> – Re-introduce the input tensor <cite>x_in</cite> after each block
by concatenating with intermediate outputs</p></li>
<li><p><strong>upsampling_layers</strong> – Use upsampling instead of transposed convolutions.</p></li>
<li><p><strong>interp</strong> – Method to use for interpolation when upsampling smaller features.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>tf.Tensor of the output of the block of the same width and height</dt><dd><p>as the input with <cite>num_output_channels</cite> channels.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_outs</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.unet.unet">
<code class="sig-prename descclassname">sleap.nn.architectures.unet.</code><code class="sig-name descname">unet</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_output_channels</em>, <em class="sig-param">down_blocks=3</em>, <em class="sig-param">up_blocks=3</em>, <em class="sig-param">convs_per_depth=2</em>, <em class="sig-param">num_filters=16</em>, <em class="sig-param">kernel_size=5</em>, <em class="sig-param">upsampling_layers=True</em>, <em class="sig-param">interp='bilinear'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/unet.html#unet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.unet.unet" title="Permalink to this definition">¶</a></dt>
<dd><p>U-net block.</p>
<p>Implementation based off of <a class="reference external" href="https://github.com/CSBDeep/CSBDeep/blob/master/csbdeep/internals/nets.py">CARE</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer. Must have height and width
that are divisible by <cite>2^depth</cite>.</p></li>
<li><p><strong>num_output_channels</strong> – The number of output channels of the block. These
are the final output tensors on which intermediate supervision may be
applied.</p></li>
<li><p><strong>down_blocks</strong> – The number of pooling steps applied to the input. The input
must be a tensor with <cite>2^depth</cite> height and width to allow for
symmetric pooling and upsampling with skip connections.</p></li>
<li><p><strong>up_blocks</strong> – The number of upsampling steps applied after downsampling.</p></li>
<li><p><strong>convs_per_depth</strong> – The number of convolutions applied before pooling or
after upsampling.</p></li>
<li><p><strong>num_filters</strong> – The base number feature channels of the block. The number of
filters is doubled at each pooling step.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolutional kernels for each filter.</p></li>
<li><p><strong>upsampling_layers</strong> – Use upsampling instead of transposed convolutions.</p></li>
<li><p><strong>interp</strong> – Method to use for interpolation when upsampling smaller features.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>tf.Tensor of the output of the block of the same width and height</dt><dd><p>as the input with <cite>num_output_channels</cite> channels.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_out</p>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-sleap.nn.architectures.common"></span><dl class="function">
<dt id="sleap.nn.architectures.common.conv">
<code class="sig-prename descclassname">sleap.nn.architectures.common.</code><code class="sig-name descname">conv</code><span class="sig-paren">(</span><em class="sig-param">num_filters</em>, <em class="sig-param">kernel_size=(3</em>, <em class="sig-param">3)</em>, <em class="sig-param">activation='relu'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/common.html#conv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.common.conv" title="Permalink to this definition">¶</a></dt>
<dd><p>Convenience presets for Conv2D.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_filters</strong> – Number of output filters (channels)</p></li>
<li><p><strong>kernel_size</strong> – Size of convolution kernel</p></li>
<li><p><strong>activation</strong> – Activation function applied to output</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments passed on to keras.layers.Conv2D</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>keras.layers.Conv2D instance built with presets</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.common.conv1">
<code class="sig-prename descclassname">sleap.nn.architectures.common.</code><code class="sig-name descname">conv1</code><span class="sig-paren">(</span><em class="sig-param">num_filters</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/common.html#conv1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.common.conv1" title="Permalink to this definition">¶</a></dt>
<dd><p>Convenience presets for 1x1 Conv2D.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_filters</strong> – Number of output filters (channels)</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments passed on to keras.layers.Conv2D</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>keras.layers.Conv2D instance built with presets</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.common.conv3">
<code class="sig-prename descclassname">sleap.nn.architectures.common.</code><code class="sig-name descname">conv3</code><span class="sig-paren">(</span><em class="sig-param">num_filters</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/common.html#conv3"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.common.conv3" title="Permalink to this definition">¶</a></dt>
<dd><p>Convenience presets for 3x3 Conv2D.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_filters</strong> – Number of output filters (channels)</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments passed on to keras.layers.Conv2D</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>keras.layers.Conv2D instance built with presets</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.common.expand_to_n">
<code class="sig-prename descclassname">sleap.nn.architectures.common.</code><code class="sig-name descname">expand_to_n</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">n</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/common.html#expand_to_n"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.common.expand_to_n" title="Permalink to this definition">¶</a></dt>
<dd><p>Expands an object <cite>x</cite> to <cite>n</cite> elements if scalar.</p>
<p>This is a utility function that wraps np.tile functionality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Scalar of any type</p></li>
<li><p><strong>n</strong> – Number of repetitions</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tiled version of <cite>x</cite> with __len__ == <cite>n</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.common.residual_block">
<code class="sig-prename descclassname">sleap.nn.architectures.common.</code><code class="sig-name descname">residual_block</code><span class="sig-paren">(</span><em class="sig-param">x_in</em>, <em class="sig-param">num_filters=None</em>, <em class="sig-param">batch_norm=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/common.html#residual_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.common.residual_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Residual bottleneck block.</p>
<p>This function builds a residual block that is used at every step of stacked
hourglass construction. Note that the layers are actually instantiated and
connected.</p>
<p>The bottleneck is constructed by applying a 1x1 conv with <cite>num_filters / 2</cite>
channels, a 3x3 conv with <cite>num_filters / 2</cite> channels, and a 1x1 conv with
<cite>num_filters</cite>. The output of this last conv is skip-connected with the input
via an Add layer (the residual).</p>
<p>If the input <cite>x_in</cite> has a different number of channels as <cite>num_filters</cite>, an
additional 1x1 conv is applied to the input whose output will be used for the
skip connection.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_in</strong> – Input 4-D tf.Tensor or instantiated layer</p></li>
<li><p><strong>num_filters</strong> – The number output channels of the block. If not specified,
defaults to the same number of channels as the input tensor. Must be
divisible by 2 since the bottleneck halves the number of filters in
the intermediate convs.</p></li>
<li><p><strong>batch_norm</strong> – Apply batch normalization after each convolution</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>tf.Tensor of the output of the block of the same width and height</dt><dd><p>as the input with <cite>num_filters</cite> channels.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x_out</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.common.scale_input">
<code class="sig-prename descclassname">sleap.nn.architectures.common.</code><code class="sig-name descname">scale_input</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/common.html#scale_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.common.scale_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Rescale input to [-1, 1].</p>
</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.common.tile_channels">
<code class="sig-prename descclassname">sleap.nn.architectures.common.</code><code class="sig-name descname">tile_channels</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/sleap/nn/architectures/common.html#tile_channels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.common.tile_channels" title="Permalink to this definition">¶</a></dt>
<dd><p>Tiles single channel to 3 channel.</p>
</dd></dl>

<dl class="function">
<dt id="sleap.nn.architectures.common.upsampled_average_block">
<code class="sig-prename descclassname">sleap.nn.architectures.common.</code><code class="sig-name descname">upsampled_average_block</code><span class="sig-paren">(</span><em class="sig-param">tensors: List[tensorflow.python.framework.ops.Tensor], target_size: int = None, interp: str = 'bilinear'</em><span class="sig-paren">)</span> &#x2192; tensorflow.python.framework.ops.Tensor<a class="reference internal" href="_modules/sleap/nn/architectures/common.html#upsampled_average_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sleap.nn.architectures.common.upsampled_average_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Upsamples tensors to a common size and reduce by averaging.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensors</strong> – A list of tensors of possibly different heights/widths, but the same
number of channels.</p></li>
<li><p><strong>target_size</strong> – Size that the tensors be upsampled to. If None, this is set to the
size of the largest tensor in the list.</p></li>
<li><p><strong>interp</strong> – Interpolation method (“nearest” or “bilinear”).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A single tensor with the target size that is the average of all of the input
tensors.</p>
</dd>
</dl>
</dd></dl>

</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">SLEAP</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial-part2.html">Tutorial, Part 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="howtos.html">How-Tos</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">Feature Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="api.html">API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="skeleton.html">sleap.skeleton</a></li>
<li class="toctree-l2"><a class="reference internal" href="instance.html">sleap.instance</a></li>
<li class="toctree-l2"><a class="reference internal" href="dataset.html">sleap.io.dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="video.html">sleap.io.video</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="inference.html">Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="gui.html">GUI</a></li>
<li class="toctree-l2"><a class="reference internal" href="misc.html">Misc</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="api.html">Developer API</a><ul>
      <li>Previous: <a href="video.html" title="previous chapter">sleap.io.video</a></li>
      <li>Next: <a href="inference.html" title="next chapter">Inference</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Murthy Lab @ Princeton.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.4.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/training.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>