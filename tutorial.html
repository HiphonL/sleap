
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Tutorial &#8212; SLEAP  documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Frequently Asked Questions" href="faq.html" />
    <link rel="prev" title="Installation" href="installation.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="tutorial">
<h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h1>
<p>Before you can use SLEAP, you’ll need to install it. Follow the
instructions at <a class="reference internal" href="installation.html#installation"><span class="std std-ref">Installation</span></a> to install SLEAP and
start the GUI app.</p>
<p>There are three main stages of using SLEAP:</p>
<ol class="arabic simple">
<li><p>Creating a project, opening a movie and defining the skeleton;</p></li>
<li><p>Labeling and learning, labeling of video frames assisted by network
predictions;</p></li>
<li><p>Prediction and proofreading, final network predictions of body-part
positions and proofreading of track identities in full videos.</p></li>
</ol>
<div class="section" id="stage-1-creating-a-project">
<h2>Stage 1: Creating a project<a class="headerlink" href="#stage-1-creating-a-project" title="Permalink to this headline">¶</a></h2>
<p>When you first start SLEAP you’ll see an open dialog. Since you don’t
yet have a project to open, click “<strong>Cancel</strong>” and you’ll be left with a
new, empty project.</p>
<div class="section" id="opening-a-video">
<h3>Opening a video<a class="headerlink" href="#opening-a-video" title="Permalink to this headline">¶</a></h3>
<p>Add a <strong>video</strong> by clicking the “<strong>Add Video</strong>” button in the “Videos” panel
on the right side of the main window.</p>
<p><img alt="image0" src="docs/_static/add-video.gif" /></p>
<p>You’ll then be able to select one or more video files and click “<strong>Open</strong>”.
SLEAP currently supports mp4, avi, and h5 files. For mp4 and avi files,
you’ll be asked whether to import the video as grayscale. For h5 files,
you’ll be asked the dataset and whether the video is stored with
channels first or last.</p>
<p><img alt="image1" src="docs/_static/video-options.gif" /></p>
</div>
<div class="section" id="creating-the-skeleton">
<h3>Creating the Skeleton<a class="headerlink" href="#creating-the-skeleton" title="Permalink to this headline">¶</a></h3>
<p>Create a new <strong>skeleton</strong> using the “Skeleton” panel on the right side
of the main window.</p>
<p>Use the “<strong>New Node</strong>” button to add a node (i.e., joint or body part).
Double-click the node name to rename it (hit enter after you type the
new name). Repeat until you have created all your nodes. You then need
to connect the nodes with edges. Directly to the left of the “Add edge”
button you’ll see two drop-down menus. Use these to select a pair of
nodes, and then click “<strong>Add Edge</strong>”. Repeat until you’ve entered all the
edges.</p>
<p><img alt="image2" src="docs/_static/add-skeleton.gif" /></p>
</div>
</div>
<div class="section" id="stage-2-labeling-and-learning">
<h2>Stage 2: Labeling and learning<a class="headerlink" href="#stage-2-labeling-and-learning" title="Permalink to this headline">¶</a></h2>
<p>We start by assembling a candidate group of images to label. You can
either pick your own frames or let the system suggest a set of frames
using the “Labeling Suggestions” panel. SLEAP can give you random or
evenly-spaced samples, or it can try to give you distinctive groups of
frames by taking the image features into account.</p>
<p>For now, let’s just get 20 random frames. Choose “sample” as the method and “random” as the sampling method, then click “<strong>Generate Suggestions</strong>”.</p>
<p><img alt="image3" src="docs/_static/suggestions.jpg" /></p>
<div class="section" id="labeling-the-first-frame">
<h3>Labeling the first frame<a class="headerlink" href="#labeling-the-first-frame" title="Permalink to this headline">¶</a></h3>
<p>Start by adding an <strong>instance</strong> of the skeleton to the current image by
clicking the “<strong>Add Instance</strong>” button in the Instances panel. The
first instance will have its points located at random. Move the points
to their appropriate positions by dragging with the mouse. Use the mouse
scroll-wheel to <strong>zoom</strong>.</p>
<p><img alt="image4" src="docs/_static/labeling.gif" /></p>
<p>You can <strong>move the entire instance</strong> by holding down the <strong>Alt</strong> key while
you click and drag the instance. You can <strong>rotate the instance</strong> by
using the scroll-wheel while holding down the <strong>Alt</strong> key.</p>
<p>For body parts that are not visible in the frame, right-click the node
(or its name) to toggle visibility. The node will appear smaller to show
that it’s marked as “not visible”. If you can determine where an
occluded node would be in the image, you may label it as “visible” in
order to train the model to predict the node even when it’s occluded.</p>
<p><img alt="image5" src="docs/_static/toggle-visibility.gif" /></p>
</div>
<div class="section" id="saving">
<h3>Saving<a class="headerlink" href="#saving" title="Permalink to this headline">¶</a></h3>
<p>Since this is a new project, you’ll need to select a location and name
the first time you save. SLEAP will ask you to save before closing any
project that has been changed to avoid losing any work. Note: There is
not yet an “undo” feature built into SLEAP. If you want to make
temporary changes to a project, use the “<strong>Save As…</strong>” command first to save
a copy of your project.</p>
</div>
<div class="section" id="labeling-more-frames">
<h3>Labeling more frames<a class="headerlink" href="#labeling-more-frames" title="Permalink to this headline">¶</a></h3>
<p>After labeling the first frame saving the project, it’s time to label
more frames. Nodes positions will be copied from the instances in the
prior labeled frame to increase labeling speed. Since you generated a list
of suggested frames, you can go to the next frame in the labeling set by clicking “<strong>Next</strong>” under the list of suggested frames.</p>
<p>You can also always pick a frame to label by using the seekbar under
the video.</p>
<p>Try adding an instance by <strong>right-clicking</strong> on the location of the animal in the video. You’ll see a pop-up menu with options for how we determine the initial node placement. Feel free to try the different options.</p>
<p>There’s no need to be consistent about which animal you label with which
instance for the case of multiple animals. For instance, suppose you
have a male and a female. It’s fine to label the male with the blue
instance in some frames and the orange instance in others. Tracking (and
track proofreading) is the final stage in the workflow and occurs after
predicting body part locations.</p>
<p>When you label a frame, it’s best if you can label all the instances of
your animal in the frame. Otherwise, the models may learn to not
identify things that look like the instances you didn’t label.</p>
</div>
<div class="section" id="prediction-assisted-labeling">
<h3>Prediction-assisted labeling<a class="headerlink" href="#prediction-assisted-labeling" title="Permalink to this headline">¶</a></h3>
<p><em>Prediction-assisted labeling</em> has two main goals. First, it speeds up the labeling
process as it is faster to correct a predicted instance which is mostly
correct than it is to add a new instance from scratch. Second, it
provides feedback about where your model does well and where it does
poorly, and this should give you a better idea of which frames will be
most useful to label.</p>
<p>To run active learning, select “<strong>Run Training…</strong>” from the “Predict”
menu. This trains new models using the frames that you’ve already
labeled in your project, and then uses these models to predict instances
in the suggested frames that you haven’t yet labeled (or on other random
frames). This process can take a while, and since it runs on your
machine, you should only try it if you have a GPU installed.</p>
<p><img alt="image6" src="docs/_static/training-dialog.jpg" /></p>
<p>By default, training uses the training settings which we’ve found to work
well on a wide range of videos. We train a “centroid” model on 1/4 scale
images and then use this to crop where we think there are instances
during inference. Another pair of models are trained on unscaled,
cropped images. The “confidence map” model is used to infer node
locations, and the “part affinity field” model is used to infer the
edges that connect nodes.</p>
<p>There are a few hyperparameters that you can control for active
learning:</p>
<ul class="simple">
<li><p><strong>Crop size</strong> ensures that the box for our crop is at least a
given size instead of using the tightest crop that will bound any
labeled instance.</p></li>
<li><p><strong>Sigma</strong> controls the size of the confidence map gaussians and part
affinity fields used for training.</p></li>
<li><p><strong>Batch Size</strong> determines how many samples are used to train the
neural network at one time. If you get an error that your GPU ran out
of memory while training, you should try a smaller batch size.</p></li>
</ul>
<p>You can visually preview the effects of these settings on the training
data by clicking the “<strong>View Training Image Inputs…</strong>” button. You’ll then
see windows with the confidence maps and part affinity fields that will
be used to train the models.</p>
<p>After setting the parameters click “<strong>Run Training and Inference</strong>”. During the
training process, you’ll see a window where you can monitor the loss.
Blue points are training loss for each batch, lines are training and
validation loss for the epochs (these won’t appear until the second
epoch has finished.) There’s a button to stop training the model when
you think is appropriate, or the training will automatically stop if the
model doesn’t improve for a certain number of epochs (15 by default)</p>
<p>First we train a model for confidence maps, part affinity fields, and
centroids, and then we run inference. The GUI doesn’t yet give you a way
to monitor the progress during inference, although it will alert you if an error occurs during inference.</p>
<p>When inference finishes, you’ll be told how many instances were
predicted. Suggested frames with predicted instances will be marked in
red on the seekbar.</p>
</div>
<div class="section" id="reviewing-and-fixing-predictions">
<h3>Reviewing and fixing predictions<a class="headerlink" href="#reviewing-and-fixing-predictions" title="Permalink to this headline">¶</a></h3>
<p>After you’ve successfully trained models and predicted some instances,
you’ll get a message that inference has finished. Every suggested
frame with predicted instances will have a distinctive mark in the
seekbar. Suggested frames which you labeled are marked in blue while
those with predicted instances are marked in red. Predicted instances
will <em>not</em> be used for future model training unless you correct the
predictions in the GUI.</p>
<p><img alt="imagefix" src="docs/_static/fixing-predictions.gif" /></p>
<p>Predicted instances in the frame are displayed in grey with yellow
nodes. To edit a prediction, you’ll need to replace it with an editable
instance. <strong>Double-click</strong> the predicted instance and it will be converted into a regular instance.</p>
<p>You can now edit the instance as before. Once you’ve added and/or
corrected more instances, you can repeat the process:
train a new model, predict on more frames, correct those predictions,
and so on. You’ll want to regularly generate new frame suggestions,
since active learning will return predictions for just these frames.</p>
</div>
</div>
<div class="section" id="stage-3-tracking-instances-across-frames">
<h2>Stage 3: Tracking instances across frames<a class="headerlink" href="#stage-3-tracking-instances-across-frames" title="Permalink to this headline">¶</a></h2>
<p>When you’re satisfied with the predictions you’re getting, you can use your models to predict on more frames by selecting
“<strong>Run Inference…</strong>” from the “Predict” menu. This will use the most
recently trained set of models.</p>
<p><img alt="image8" src="docs/_static/inference-dialog.jpg" /></p>
<div class="section" id="track-proofreading">
<h3>Track proofreading<a class="headerlink" href="#track-proofreading" title="Permalink to this headline">¶</a></h3>
<p>Once you have predicted tracks, you’ll need to proofread these to ensure
that the identities of instances across frames are correct. By default,
predicted instances all appear in grey and yellow. Select “Color
Predicted Instances” to show the tracks in color. (Note that colors in
the frame match colors in the seek-bar and colors in the “Instances”
panel.) Click an instance to see it’s track name. Double-click the track
name in the “Instances” panel to change the name.</p>
<p>There are two main types of mistakes made by the tracking code: mistaken
identities and lost identities.</p>
<p><strong>Mistaken Identities:</strong> The code may misidentify which instance goes in
which track, in which case you’ll want to “swap” the identities.</p>
<p>You can swap the identities assigned to a pair of instances by selecting
“Transpose Instance Tracks” in the “Labels” menu. If there are just two
instances in the frame, it already knows what it do. If there are more,
you’ll have to click the two instances you want to swap.</p>
<p><img alt="image9" src="docs/_static/fixing-track.gif" /></p>
<p>You can assign an instance to a different (or new) track from the “Set
Instance Track” submenu in the “Labels” menu.</p>
<p>You can select instances by typing a number between 1 and 9, by clicking
the instance in the frame, or by clicking the instance in the
“Instances” panel (on the right side of your main window). When an
instance is selected, you’ll see its track name. These track names can
be edited by double-clicking the track name in the “Instances” panel.</p>
<p>When you assign an instance to a track, this change will also be applied
to all <em>subsequent</em> frames. For instance, if you move an instance from
track 3 to track 2, then any instance in track 3 in subsequent frames
will also be moved to track 2. This lets you effectively “merge” tracks.</p>
<p><strong>Lost Identities:</strong> The code may fail to identity an instance in one
frame with any instances from previous frames. In this case, you’ll want
to find the first frame in which the new track occurs and change the
instance track to the track from previous frames. The “Next Track Spawn
Frame” command in the “Labels” menu will take you to the next frame in
which a new track is spawned.</p>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">SLEAP</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">SLEAP Package</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#stage-1-creating-a-project">Stage 1: Creating a project</a></li>
<li class="toctree-l2"><a class="reference internal" href="#stage-2-labeling-and-learning">Stage 2: Labeling and learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#stage-3-tracking-instances-across-frames">Stage 3: Tracking instances across frames</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">Feature Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Developer API</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="installation.html" title="previous chapter">Installation</a></li>
      <li>Next: <a href="faq.html" title="next chapter">Frequently Asked Questions</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Murthy Lab @ Princeton.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.2.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/tutorial.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>